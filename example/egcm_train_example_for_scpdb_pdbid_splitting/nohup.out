[22:50:05] Conflicting single bond directions around double bond at index 1.
[22:50:05]   BondStereo set to STEREONONE and single bond directions set to NONE.
Charset: NC(=O)c1[n+]2P-345lH/\S#@oBrsFI678
13937 13937 13937
Initializing model in train mode.
Input type is 'molecular descriptors'.
Applying scaling on input.
Model received 12543 train samples and 1394 validation samples.
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Latent_Input (InputLayer)       [(None, 256)]        0                                            
__________________________________________________________________________________________________
Decoder_Inputs (InputLayer)     [(None, 249, 37)]    0                                            
__________________________________________________________________________________________________
latent_to_states_model (Model)  [(None, 256), (None, 267264      Latent_Input[0][0]               
__________________________________________________________________________________________________
batch_model (Model)             (None, 249, 37)      839973      Decoder_Inputs[0][0]             
                                                                 latent_to_states_model[1][0]     
                                                                 latent_to_states_model[1][1]     
                                                                 latent_to_states_model[1][2]     
                                                                 latent_to_states_model[1][3]     
==================================================================================================
Total params: 1,107,237
Trainable params: 1,104,165
Non-trainable params: 3,072
__________________________________________________________________________________________________
None
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.

Model trained with dataset scPDB_1221_pdbid that has maxlen=245 and charset=NC(=O)c1[n+]2P-345lH/\S#@oBrsFI678 for 2000 epochs.
noise_std: 0.010000, lstm_dim: 256, dec_layers: 2, td_dense_dim: 0, batch_size: 256, codelayer_dim: 256, lr: 0.001000.
WARNING:tensorflow:From /mnt/home/myxu/soft/anaconda3/envs/ddc/lib/python3.6/site-packages/ddc_pub/ddc_v3.py:1017: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.

Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 1/4000
24/24 - 3s - loss: 1.0485 - val_loss: 2.2211 - lr: 0.0010

Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 2/4000
24/24 - 7s - loss: 0.4811 - val_loss: 0.5538 - lr: 0.0010

Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 3/4000
24/24 - 3s - loss: 0.3850 - val_loss: 0.3582 - lr: 0.0010

Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 4/4000
24/24 - 3s - loss: 0.3421 - val_loss: 0.3362 - lr: 0.0010

Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 5/4000
24/24 - 3s - loss: 0.3134 - val_loss: 0.3072 - lr: 0.0010

Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 6/4000
24/24 - 3s - loss: 0.2910 - val_loss: 0.2809 - lr: 0.0010

Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 7/4000
24/24 - 3s - loss: 0.2751 - val_loss: 0.2779 - lr: 0.0010

Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 8/4000
24/24 - 3s - loss: 0.2608 - val_loss: 0.2727 - lr: 0.0010

Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 9/4000
24/24 - 3s - loss: 0.2485 - val_loss: 0.2443 - lr: 0.0010

Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 10/4000
24/24 - 3s - loss: 0.2428 - val_loss: 0.3038 - lr: 0.0010

Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 11/4000
24/24 - 3s - loss: 0.2324 - val_loss: 0.2425 - lr: 0.0010

Epoch 00012: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 12/4000
24/24 - 3s - loss: 0.2264 - val_loss: 0.2604 - lr: 0.0010

Epoch 00013: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 13/4000
24/24 - 3s - loss: 0.2228 - val_loss: 0.2338 - lr: 0.0010

Epoch 00014: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 14/4000
24/24 - 3s - loss: 0.2146 - val_loss: 0.2242 - lr: 0.0010

Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 15/4000
24/24 - 3s - loss: 0.2120 - val_loss: 0.2128 - lr: 0.0010

Epoch 00016: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 16/4000
24/24 - 3s - loss: 0.2084 - val_loss: 0.2146 - lr: 0.0010

Epoch 00017: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 17/4000
24/24 - 3s - loss: 0.2034 - val_loss: 0.2163 - lr: 0.0010

Epoch 00018: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 18/4000
24/24 - 3s - loss: 0.1989 - val_loss: 0.2106 - lr: 0.0010

Epoch 00019: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 19/4000
24/24 - 3s - loss: 0.1936 - val_loss: 0.2133 - lr: 0.0010

Epoch 00020: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 20/4000
24/24 - 3s - loss: 0.1936 - val_loss: 0.1985 - lr: 0.0010

Epoch 00021: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 21/4000
24/24 - 3s - loss: 0.1919 - val_loss: 0.2012 - lr: 0.0010

Epoch 00022: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 22/4000
24/24 - 3s - loss: 0.1855 - val_loss: 0.2040 - lr: 0.0010

Epoch 00023: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 23/4000
24/24 - 3s - loss: 0.1873 - val_loss: 0.2118 - lr: 0.0010

Epoch 00024: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 24/4000
24/24 - 3s - loss: 0.1840 - val_loss: 0.1960 - lr: 0.0010

Epoch 00025: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 25/4000
24/24 - 3s - loss: 0.1792 - val_loss: 0.1844 - lr: 0.0010

Epoch 00026: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 26/4000
24/24 - 3s - loss: 0.1798 - val_loss: 0.1932 - lr: 0.0010

Epoch 00027: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 27/4000
24/24 - 3s - loss: 0.1814 - val_loss: 0.1912 - lr: 0.0010

Epoch 00028: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 28/4000
24/24 - 3s - loss: 0.1752 - val_loss: 0.1882 - lr: 0.0010

Epoch 00029: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 29/4000
24/24 - 3s - loss: 0.1724 - val_loss: 0.1887 - lr: 0.0010

Epoch 00030: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 30/4000
24/24 - 3s - loss: 0.1734 - val_loss: 0.1802 - lr: 0.0010

Epoch 00031: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 31/4000
24/24 - 3s - loss: 0.1716 - val_loss: 0.1933 - lr: 0.0010

Epoch 00032: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 32/4000
24/24 - 3s - loss: 0.1701 - val_loss: 0.1838 - lr: 0.0010

Epoch 00033: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 33/4000
24/24 - 3s - loss: 0.1701 - val_loss: 0.1952 - lr: 0.0010

Epoch 00034: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 34/4000
24/24 - 3s - loss: 0.1673 - val_loss: 0.1682 - lr: 0.0010

Epoch 00035: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 35/4000
24/24 - 3s - loss: 0.1670 - val_loss: 0.1921 - lr: 0.0010

Epoch 00036: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 36/4000
24/24 - 3s - loss: 0.1655 - val_loss: 0.1739 - lr: 0.0010

Epoch 00037: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 37/4000
24/24 - 3s - loss: 0.1642 - val_loss: 0.1678 - lr: 0.0010

Epoch 00038: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 38/4000
24/24 - 3s - loss: 0.1654 - val_loss: 0.1865 - lr: 0.0010

Epoch 00039: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 39/4000
24/24 - 3s - loss: 0.1600 - val_loss: 0.1721 - lr: 0.0010

Epoch 00040: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 40/4000
24/24 - 3s - loss: 0.1617 - val_loss: 0.1713 - lr: 0.0010

Epoch 00041: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 41/4000
24/24 - 3s - loss: 0.1585 - val_loss: 0.1718 - lr: 0.0010

Epoch 00042: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 42/4000
24/24 - 3s - loss: 0.1593 - val_loss: 0.1656 - lr: 0.0010

Epoch 00043: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 43/4000
24/24 - 3s - loss: 0.1583 - val_loss: 0.1711 - lr: 0.0010

Epoch 00044: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 44/4000
24/24 - 3s - loss: 0.1571 - val_loss: 0.1688 - lr: 0.0010

Epoch 00045: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 45/4000
24/24 - 3s - loss: 0.1575 - val_loss: 0.1638 - lr: 0.0010

Epoch 00046: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 46/4000
24/24 - 3s - loss: 0.1555 - val_loss: 0.1632 - lr: 0.0010

Epoch 00047: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 47/4000
24/24 - 3s - loss: 0.1537 - val_loss: 0.1741 - lr: 0.0010

Epoch 00048: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 48/4000
24/24 - 3s - loss: 0.1553 - val_loss: 0.1612 - lr: 0.0010

Epoch 00049: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 49/4000
24/24 - 3s - loss: 0.1524 - val_loss: 0.1609 - lr: 0.0010

Epoch 00050: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 50/4000
Model saved in ./model/scPDB_1221_pdbid--50--0.1586--0.0010000.
24/24 - 3s - loss: 0.1536 - val_loss: 0.1586 - lr: 0.0010

Epoch 00051: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 51/4000
24/24 - 3s - loss: 0.1502 - val_loss: 0.1594 - lr: 0.0010

Epoch 00052: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 52/4000
24/24 - 3s - loss: 0.1505 - val_loss: 0.1576 - lr: 0.0010

Epoch 00053: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 53/4000
24/24 - 3s - loss: 0.1507 - val_loss: 0.1600 - lr: 0.0010

Epoch 00054: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 54/4000
24/24 - 3s - loss: 0.1497 - val_loss: 0.1591 - lr: 0.0010

Epoch 00055: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 55/4000
24/24 - 3s - loss: 0.1486 - val_loss: 0.1614 - lr: 0.0010

Epoch 00056: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 56/4000
24/24 - 3s - loss: 0.1486 - val_loss: 0.1570 - lr: 0.0010

Epoch 00057: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 57/4000
24/24 - 3s - loss: 0.1479 - val_loss: 0.1534 - lr: 0.0010

Epoch 00058: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 58/4000
24/24 - 3s - loss: 0.1447 - val_loss: 0.1524 - lr: 0.0010

Epoch 00059: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 59/4000
24/24 - 3s - loss: 0.1473 - val_loss: 0.1566 - lr: 0.0010

Epoch 00060: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 60/4000
24/24 - 3s - loss: 0.1473 - val_loss: 0.1499 - lr: 0.0010

Epoch 00061: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 61/4000
24/24 - 3s - loss: 0.1437 - val_loss: 0.1525 - lr: 0.0010

Epoch 00062: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 62/4000
24/24 - 3s - loss: 0.1443 - val_loss: 0.1545 - lr: 0.0010

Epoch 00063: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 63/4000
24/24 - 3s - loss: 0.1443 - val_loss: 0.1498 - lr: 0.0010

Epoch 00064: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 64/4000
24/24 - 3s - loss: 0.1424 - val_loss: 0.1584 - lr: 0.0010

Epoch 00065: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 65/4000
24/24 - 3s - loss: 0.1431 - val_loss: 0.1524 - lr: 0.0010

Epoch 00066: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 66/4000
24/24 - 3s - loss: 0.1426 - val_loss: 0.1533 - lr: 0.0010

Epoch 00067: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 67/4000
24/24 - 3s - loss: 0.1423 - val_loss: 0.1482 - lr: 0.0010

Epoch 00068: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 68/4000
24/24 - 3s - loss: 0.1409 - val_loss: 0.1559 - lr: 0.0010

Epoch 00069: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 69/4000
24/24 - 3s - loss: 0.1403 - val_loss: 0.1427 - lr: 0.0010

Epoch 00070: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 70/4000
24/24 - 3s - loss: 0.1418 - val_loss: 0.1453 - lr: 0.0010

Epoch 00071: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 71/4000
24/24 - 3s - loss: 0.1396 - val_loss: 0.1534 - lr: 0.0010

Epoch 00072: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 72/4000
24/24 - 3s - loss: 0.1391 - val_loss: 0.1490 - lr: 0.0010

Epoch 00073: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 73/4000
24/24 - 3s - loss: 0.1388 - val_loss: 0.1495 - lr: 0.0010

Epoch 00074: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 74/4000
24/24 - 3s - loss: 0.1392 - val_loss: 0.1468 - lr: 0.0010

Epoch 00075: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 75/4000
24/24 - 3s - loss: 0.1384 - val_loss: 0.1477 - lr: 0.0010

Epoch 00076: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 76/4000
24/24 - 3s - loss: 0.1377 - val_loss: 0.1485 - lr: 0.0010

Epoch 00077: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 77/4000
24/24 - 3s - loss: 0.1387 - val_loss: 0.1457 - lr: 0.0010

Epoch 00078: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 78/4000
24/24 - 3s - loss: 0.1348 - val_loss: 0.1571 - lr: 0.0010

Epoch 00079: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 79/4000
24/24 - 3s - loss: 0.1361 - val_loss: 0.1430 - lr: 0.0010

Epoch 00080: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 80/4000
24/24 - 3s - loss: 0.1366 - val_loss: 0.1473 - lr: 0.0010

Epoch 00081: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 81/4000
24/24 - 3s - loss: 0.1358 - val_loss: 0.1449 - lr: 0.0010

Epoch 00082: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 82/4000
24/24 - 3s - loss: 0.1348 - val_loss: 0.1444 - lr: 0.0010

Epoch 00083: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 83/4000
24/24 - 3s - loss: 0.1353 - val_loss: 0.1551 - lr: 0.0010

Epoch 00084: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 84/4000
24/24 - 3s - loss: 0.1340 - val_loss: 0.1446 - lr: 0.0010

Epoch 00085: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 85/4000
24/24 - 3s - loss: 0.1343 - val_loss: 0.1408 - lr: 0.0010

Epoch 00086: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 86/4000
24/24 - 3s - loss: 0.1343 - val_loss: 0.1395 - lr: 0.0010

Epoch 00087: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 87/4000
24/24 - 3s - loss: 0.1330 - val_loss: 0.1452 - lr: 0.0010

Epoch 00088: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 88/4000
24/24 - 3s - loss: 0.1327 - val_loss: 0.1368 - lr: 0.0010

Epoch 00089: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 89/4000
24/24 - 3s - loss: 0.1307 - val_loss: 0.1428 - lr: 0.0010

Epoch 00090: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 90/4000
24/24 - 3s - loss: 0.1341 - val_loss: 0.1428 - lr: 0.0010

Epoch 00091: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 91/4000
24/24 - 3s - loss: 0.1312 - val_loss: 0.1385 - lr: 0.0010

Epoch 00092: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 92/4000
24/24 - 3s - loss: 0.1316 - val_loss: 0.1469 - lr: 0.0010

Epoch 00093: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 93/4000
24/24 - 3s - loss: 0.1331 - val_loss: 0.1401 - lr: 0.0010

Epoch 00094: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 94/4000
24/24 - 3s - loss: 0.1310 - val_loss: 0.1482 - lr: 0.0010

Epoch 00095: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 95/4000
24/24 - 3s - loss: 0.1304 - val_loss: 0.1385 - lr: 0.0010

Epoch 00096: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 96/4000
24/24 - 3s - loss: 0.1311 - val_loss: 0.1401 - lr: 0.0010

Epoch 00097: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 97/4000
24/24 - 3s - loss: 0.1289 - val_loss: 0.1388 - lr: 0.0010

Epoch 00098: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 98/4000
24/24 - 3s - loss: 0.1304 - val_loss: 0.1425 - lr: 0.0010

Epoch 00099: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 99/4000
24/24 - 3s - loss: 0.1298 - val_loss: 0.1399 - lr: 0.0010

Epoch 00100: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 100/4000
Model saved in ./model/scPDB_1221_pdbid--100--0.1405--0.0010000.
24/24 - 3s - loss: 0.1289 - val_loss: 0.1405 - lr: 0.0010

Epoch 00101: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 101/4000
24/24 - 3s - loss: 0.1286 - val_loss: 0.1321 - lr: 0.0010

Epoch 00102: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 102/4000
24/24 - 3s - loss: 0.1285 - val_loss: 0.1428 - lr: 0.0010

Epoch 00103: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 103/4000
24/24 - 3s - loss: 0.1281 - val_loss: 0.1402 - lr: 0.0010

Epoch 00104: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 104/4000
24/24 - 3s - loss: 0.1288 - val_loss: 0.1428 - lr: 0.0010

Epoch 00105: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 105/4000
24/24 - 3s - loss: 0.1280 - val_loss: 0.1392 - lr: 0.0010

Epoch 00106: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 106/4000
24/24 - 3s - loss: 0.1268 - val_loss: 0.1349 - lr: 0.0010

Epoch 00107: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 107/4000
24/24 - 3s - loss: 0.1271 - val_loss: 0.1380 - lr: 0.0010

Epoch 00108: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 108/4000
24/24 - 3s - loss: 0.1271 - val_loss: 0.1415 - lr: 0.0010

Epoch 00109: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 109/4000
24/24 - 3s - loss: 0.1256 - val_loss: 0.1347 - lr: 0.0010

Epoch 00110: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 110/4000
24/24 - 3s - loss: 0.1264 - val_loss: 0.1362 - lr: 0.0010

Epoch 00111: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 111/4000
24/24 - 3s - loss: 0.1261 - val_loss: 0.1363 - lr: 0.0010

Epoch 00112: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 112/4000
24/24 - 3s - loss: 0.1266 - val_loss: 0.1381 - lr: 0.0010

Epoch 00113: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 113/4000
24/24 - 3s - loss: 0.1246 - val_loss: 0.1391 - lr: 0.0010

Epoch 00114: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 114/4000
24/24 - 3s - loss: 0.1266 - val_loss: 0.1344 - lr: 0.0010

Epoch 00115: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 115/4000
24/24 - 3s - loss: 0.1251 - val_loss: 0.1347 - lr: 0.0010

Epoch 00116: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 116/4000
24/24 - 3s - loss: 0.1246 - val_loss: 0.1370 - lr: 0.0010

Epoch 00117: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 117/4000
24/24 - 3s - loss: 0.1265 - val_loss: 0.1369 - lr: 0.0010

Epoch 00118: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 118/4000
24/24 - 3s - loss: 0.1249 - val_loss: 0.1323 - lr: 0.0010

Epoch 00119: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 119/4000
24/24 - 3s - loss: 0.1250 - val_loss: 0.1332 - lr: 0.0010

Epoch 00120: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 120/4000
24/24 - 3s - loss: 0.1236 - val_loss: 0.1356 - lr: 0.0010

Epoch 00121: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 121/4000
24/24 - 3s - loss: 0.1219 - val_loss: 0.1356 - lr: 0.0010

Epoch 00122: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 122/4000
24/24 - 3s - loss: 0.1234 - val_loss: 0.1344 - lr: 0.0010

Epoch 00123: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 123/4000
24/24 - 3s - loss: 0.1224 - val_loss: 0.1347 - lr: 0.0010

Epoch 00124: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 124/4000
24/24 - 3s - loss: 0.1227 - val_loss: 0.1330 - lr: 0.0010

Epoch 00125: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 125/4000
24/24 - 3s - loss: 0.1240 - val_loss: 0.1257 - lr: 0.0010

Epoch 00126: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 126/4000
24/24 - 3s - loss: 0.1216 - val_loss: 0.1304 - lr: 0.0010

Epoch 00127: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 127/4000
24/24 - 3s - loss: 0.1221 - val_loss: 0.1381 - lr: 0.0010

Epoch 00128: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 128/4000
24/24 - 3s - loss: 0.1223 - val_loss: 0.1284 - lr: 0.0010

Epoch 00129: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 129/4000
24/24 - 3s - loss: 0.1202 - val_loss: 0.1312 - lr: 0.0010

Epoch 00130: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 130/4000
24/24 - 3s - loss: 0.1229 - val_loss: 0.1330 - lr: 0.0010

Epoch 00131: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 131/4000
24/24 - 3s - loss: 0.1199 - val_loss: 0.1301 - lr: 0.0010

Epoch 00132: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 132/4000
24/24 - 3s - loss: 0.1209 - val_loss: 0.1315 - lr: 0.0010

Epoch 00133: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 133/4000
24/24 - 3s - loss: 0.1223 - val_loss: 0.1327 - lr: 0.0010

Epoch 00134: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 134/4000
24/24 - 3s - loss: 0.1214 - val_loss: 0.1263 - lr: 0.0010

Epoch 00135: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 135/4000
24/24 - 3s - loss: 0.1192 - val_loss: 0.1290 - lr: 0.0010

Epoch 00136: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 136/4000
24/24 - 3s - loss: 0.1190 - val_loss: 0.1304 - lr: 0.0010

Epoch 00137: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 137/4000
24/24 - 3s - loss: 0.1220 - val_loss: 0.1338 - lr: 0.0010

Epoch 00138: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 138/4000
24/24 - 3s - loss: 0.1193 - val_loss: 0.1351 - lr: 0.0010

Epoch 00139: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 139/4000
24/24 - 3s - loss: 0.1204 - val_loss: 0.1281 - lr: 0.0010

Epoch 00140: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 140/4000
24/24 - 3s - loss: 0.1200 - val_loss: 0.1281 - lr: 0.0010

Epoch 00141: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 141/4000
24/24 - 3s - loss: 0.1190 - val_loss: 0.1347 - lr: 0.0010

Epoch 00142: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 142/4000
24/24 - 3s - loss: 0.1195 - val_loss: 0.1355 - lr: 0.0010

Epoch 00143: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 143/4000
24/24 - 3s - loss: 0.1172 - val_loss: 0.1331 - lr: 0.0010

Epoch 00144: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 144/4000
24/24 - 3s - loss: 0.1180 - val_loss: 0.1279 - lr: 0.0010

Epoch 00145: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 145/4000
24/24 - 3s - loss: 0.1189 - val_loss: 0.1295 - lr: 0.0010

Epoch 00146: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 146/4000
24/24 - 3s - loss: 0.1179 - val_loss: 0.1331 - lr: 0.0010

Epoch 00147: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 147/4000
24/24 - 3s - loss: 0.1179 - val_loss: 0.1300 - lr: 0.0010

Epoch 00148: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 148/4000
24/24 - 3s - loss: 0.1176 - val_loss: 0.1288 - lr: 0.0010

Epoch 00149: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 149/4000
24/24 - 3s - loss: 0.1185 - val_loss: 0.1262 - lr: 0.0010

Epoch 00150: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 150/4000
Model saved in ./model/scPDB_1221_pdbid--150--0.1363--0.0010000.
24/24 - 3s - loss: 0.1172 - val_loss: 0.1363 - lr: 0.0010

Epoch 00151: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 151/4000
24/24 - 3s - loss: 0.1169 - val_loss: 0.1311 - lr: 0.0010

Epoch 00152: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 152/4000
24/24 - 3s - loss: 0.1150 - val_loss: 0.1287 - lr: 0.0010

Epoch 00153: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 153/4000
24/24 - 3s - loss: 0.1179 - val_loss: 0.1273 - lr: 0.0010

Epoch 00154: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 154/4000
24/24 - 3s - loss: 0.1165 - val_loss: 0.1283 - lr: 0.0010

Epoch 00155: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 155/4000
24/24 - 3s - loss: 0.1161 - val_loss: 0.1284 - lr: 0.0010

Epoch 00156: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 156/4000
24/24 - 3s - loss: 0.1173 - val_loss: 0.1249 - lr: 0.0010

Epoch 00157: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 157/4000
24/24 - 3s - loss: 0.1155 - val_loss: 0.1282 - lr: 0.0010

Epoch 00158: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 158/4000
24/24 - 3s - loss: 0.1166 - val_loss: 0.1309 - lr: 0.0010

Epoch 00159: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 159/4000
24/24 - 3s - loss: 0.1154 - val_loss: 0.1295 - lr: 0.0010

Epoch 00160: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 160/4000
24/24 - 3s - loss: 0.1165 - val_loss: 0.1304 - lr: 0.0010

Epoch 00161: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 161/4000
24/24 - 3s - loss: 0.1148 - val_loss: 0.1256 - lr: 0.0010

Epoch 00162: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 162/4000
24/24 - 3s - loss: 0.1134 - val_loss: 0.1297 - lr: 0.0010

Epoch 00163: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 163/4000
24/24 - 3s - loss: 0.1157 - val_loss: 0.1287 - lr: 0.0010

Epoch 00164: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 164/4000
24/24 - 3s - loss: 0.1152 - val_loss: 0.1278 - lr: 0.0010

Epoch 00165: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 165/4000
24/24 - 3s - loss: 0.1141 - val_loss: 0.1295 - lr: 0.0010

Epoch 00166: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 166/4000
24/24 - 3s - loss: 0.1138 - val_loss: 0.1324 - lr: 0.0010

Epoch 00167: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 167/4000
24/24 - 3s - loss: 0.1139 - val_loss: 0.1275 - lr: 0.0010

Epoch 00168: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 168/4000
24/24 - 3s - loss: 0.1140 - val_loss: 0.1282 - lr: 0.0010

Epoch 00169: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 169/4000
24/24 - 3s - loss: 0.1147 - val_loss: 0.1303 - lr: 0.0010

Epoch 00170: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 170/4000
24/24 - 3s - loss: 0.1140 - val_loss: 0.1204 - lr: 0.0010

Epoch 00171: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 171/4000
24/24 - 3s - loss: 0.1130 - val_loss: 0.1312 - lr: 0.0010

Epoch 00172: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 172/4000
24/24 - 3s - loss: 0.1131 - val_loss: 0.1287 - lr: 0.0010

Epoch 00173: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 173/4000
24/24 - 3s - loss: 0.1141 - val_loss: 0.1255 - lr: 0.0010

Epoch 00174: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 174/4000
24/24 - 3s - loss: 0.1126 - val_loss: 0.1274 - lr: 0.0010

Epoch 00175: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 175/4000
24/24 - 3s - loss: 0.1133 - val_loss: 0.1249 - lr: 0.0010

Epoch 00176: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 176/4000
24/24 - 3s - loss: 0.1128 - val_loss: 0.1317 - lr: 0.0010

Epoch 00177: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 177/4000
24/24 - 3s - loss: 0.1122 - val_loss: 0.1248 - lr: 0.0010

Epoch 00178: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 178/4000
24/24 - 3s - loss: 0.1124 - val_loss: 0.1314 - lr: 0.0010

Epoch 00179: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 179/4000
24/24 - 3s - loss: 0.1116 - val_loss: 0.1234 - lr: 0.0010

Epoch 00180: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 180/4000
24/24 - 3s - loss: 0.1126 - val_loss: 0.1270 - lr: 0.0010

Epoch 00181: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 181/4000
24/24 - 3s - loss: 0.1118 - val_loss: 0.1247 - lr: 0.0010

Epoch 00182: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 182/4000
24/24 - 3s - loss: 0.1115 - val_loss: 0.1266 - lr: 0.0010

Epoch 00183: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 183/4000
24/24 - 3s - loss: 0.1117 - val_loss: 0.1288 - lr: 0.0010

Epoch 00184: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 184/4000
24/24 - 3s - loss: 0.1115 - val_loss: 0.1306 - lr: 0.0010

Epoch 00185: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 185/4000
24/24 - 3s - loss: 0.1124 - val_loss: 0.1213 - lr: 0.0010

Epoch 00186: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 186/4000
24/24 - 3s - loss: 0.1100 - val_loss: 0.1237 - lr: 0.0010

Epoch 00187: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 187/4000
24/24 - 3s - loss: 0.1113 - val_loss: 0.1238 - lr: 0.0010

Epoch 00188: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 188/4000
24/24 - 3s - loss: 0.1094 - val_loss: 0.1253 - lr: 0.0010

Epoch 00189: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 189/4000
24/24 - 3s - loss: 0.1103 - val_loss: 0.1241 - lr: 0.0010

Epoch 00190: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 190/4000
24/24 - 3s - loss: 0.1110 - val_loss: 0.1245 - lr: 0.0010

Epoch 00191: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 191/4000
24/24 - 3s - loss: 0.1116 - val_loss: 0.1301 - lr: 0.0010

Epoch 00192: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 192/4000
24/24 - 3s - loss: 0.1088 - val_loss: 0.1316 - lr: 0.0010

Epoch 00193: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 193/4000
24/24 - 3s - loss: 0.1096 - val_loss: 0.1239 - lr: 0.0010

Epoch 00194: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 194/4000
24/24 - 3s - loss: 0.1103 - val_loss: 0.1309 - lr: 0.0010

Epoch 00195: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 195/4000
24/24 - 3s - loss: 0.1086 - val_loss: 0.1258 - lr: 0.0010

Epoch 00196: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 196/4000
24/24 - 3s - loss: 0.1103 - val_loss: 0.1267 - lr: 0.0010

Epoch 00197: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 197/4000
24/24 - 3s - loss: 0.1095 - val_loss: 0.1239 - lr: 0.0010

Epoch 00198: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 198/4000
24/24 - 3s - loss: 0.1091 - val_loss: 0.1276 - lr: 0.0010

Epoch 00199: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 199/4000
24/24 - 3s - loss: 0.1078 - val_loss: 0.1258 - lr: 0.0010

Epoch 00200: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 200/4000
Model saved in ./model/scPDB_1221_pdbid--200--0.1214--0.0010000.
24/24 - 4s - loss: 0.1094 - val_loss: 0.1214 - lr: 0.0010

Epoch 00201: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 201/4000
24/24 - 3s - loss: 0.1084 - val_loss: 0.1250 - lr: 0.0010

Epoch 00202: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 202/4000
24/24 - 3s - loss: 0.1093 - val_loss: 0.1258 - lr: 0.0010

Epoch 00203: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 203/4000
24/24 - 3s - loss: 0.1080 - val_loss: 0.1281 - lr: 0.0010

Epoch 00204: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 204/4000
24/24 - 3s - loss: 0.1086 - val_loss: 0.1240 - lr: 0.0010

Epoch 00205: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 205/4000
24/24 - 3s - loss: 0.1089 - val_loss: 0.1229 - lr: 0.0010

Epoch 00206: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 206/4000
24/24 - 3s - loss: 0.1070 - val_loss: 0.1254 - lr: 0.0010

Epoch 00207: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 207/4000
24/24 - 3s - loss: 0.1068 - val_loss: 0.1238 - lr: 0.0010

Epoch 00208: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 208/4000
24/24 - 3s - loss: 0.1077 - val_loss: 0.1199 - lr: 0.0010

Epoch 00209: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 209/4000
24/24 - 3s - loss: 0.1077 - val_loss: 0.1265 - lr: 0.0010

Epoch 00210: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 210/4000
24/24 - 3s - loss: 0.1072 - val_loss: 0.1243 - lr: 0.0010

Epoch 00211: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 211/4000
24/24 - 3s - loss: 0.1071 - val_loss: 0.1229 - lr: 0.0010

Epoch 00212: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 212/4000
24/24 - 3s - loss: 0.1063 - val_loss: 0.1242 - lr: 0.0010

Epoch 00213: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 213/4000
24/24 - 3s - loss: 0.1067 - val_loss: 0.1235 - lr: 0.0010

Epoch 00214: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 214/4000
24/24 - 3s - loss: 0.1063 - val_loss: 0.1234 - lr: 0.0010

Epoch 00215: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 215/4000
24/24 - 3s - loss: 0.1072 - val_loss: 0.1266 - lr: 0.0010

Epoch 00216: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 216/4000
24/24 - 3s - loss: 0.1064 - val_loss: 0.1218 - lr: 0.0010

Epoch 00217: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 217/4000
24/24 - 3s - loss: 0.1053 - val_loss: 0.1235 - lr: 0.0010

Epoch 00218: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 218/4000
24/24 - 3s - loss: 0.1054 - val_loss: 0.1284 - lr: 0.0010

Epoch 00219: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 219/4000
24/24 - 3s - loss: 0.1070 - val_loss: 0.1231 - lr: 0.0010

Epoch 00220: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 220/4000
24/24 - 3s - loss: 0.1062 - val_loss: 0.1300 - lr: 0.0010

Epoch 00221: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 221/4000
24/24 - 3s - loss: 0.1059 - val_loss: 0.1217 - lr: 0.0010

Epoch 00222: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 222/4000
24/24 - 3s - loss: 0.1057 - val_loss: 0.1234 - lr: 0.0010

Epoch 00223: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 223/4000
24/24 - 3s - loss: 0.1055 - val_loss: 0.1260 - lr: 0.0010

Epoch 00224: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 224/4000
24/24 - 3s - loss: 0.1051 - val_loss: 0.1289 - lr: 0.0010

Epoch 00225: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 225/4000
24/24 - 3s - loss: 0.1049 - val_loss: 0.1256 - lr: 0.0010

Epoch 00226: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 226/4000
24/24 - 3s - loss: 0.1053 - val_loss: 0.1318 - lr: 0.0010

Epoch 00227: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 227/4000
24/24 - 3s - loss: 0.1050 - val_loss: 0.1195 - lr: 0.0010

Epoch 00228: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 228/4000
24/24 - 3s - loss: 0.1046 - val_loss: 0.1200 - lr: 0.0010

Epoch 00229: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 229/4000
24/24 - 3s - loss: 0.1055 - val_loss: 0.1222 - lr: 0.0010

Epoch 00230: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 230/4000
24/24 - 3s - loss: 0.1053 - val_loss: 0.1255 - lr: 0.0010

Epoch 00231: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 231/4000
24/24 - 3s - loss: 0.1032 - val_loss: 0.1253 - lr: 0.0010

Epoch 00232: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 232/4000
24/24 - 3s - loss: 0.1037 - val_loss: 0.1194 - lr: 0.0010

Epoch 00233: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 233/4000
24/24 - 3s - loss: 0.1027 - val_loss: 0.1257 - lr: 0.0010

Epoch 00234: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 234/4000
24/24 - 3s - loss: 0.1046 - val_loss: 0.1260 - lr: 0.0010

Epoch 00235: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 235/4000
24/24 - 3s - loss: 0.1028 - val_loss: 0.1229 - lr: 0.0010

Epoch 00236: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 236/4000
24/24 - 3s - loss: 0.1027 - val_loss: 0.1213 - lr: 0.0010

Epoch 00237: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 237/4000
24/24 - 3s - loss: 0.1045 - val_loss: 0.1238 - lr: 0.0010

Epoch 00238: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 238/4000
24/24 - 3s - loss: 0.1031 - val_loss: 0.1203 - lr: 0.0010

Epoch 00239: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 239/4000
24/24 - 3s - loss: 0.1031 - val_loss: 0.1274 - lr: 0.0010

Epoch 00240: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 240/4000
24/24 - 3s - loss: 0.1028 - val_loss: 0.1244 - lr: 0.0010

Epoch 00241: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 241/4000
24/24 - 3s - loss: 0.1042 - val_loss: 0.1225 - lr: 0.0010

Epoch 00242: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 242/4000
24/24 - 3s - loss: 0.1014 - val_loss: 0.1282 - lr: 0.0010

Epoch 00243: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 243/4000
24/24 - 3s - loss: 0.1039 - val_loss: 0.1227 - lr: 0.0010

Epoch 00244: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 244/4000
24/24 - 3s - loss: 0.1028 - val_loss: 0.1245 - lr: 0.0010

Epoch 00245: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 245/4000
24/24 - 3s - loss: 0.1027 - val_loss: 0.1196 - lr: 0.0010

Epoch 00246: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 246/4000
24/24 - 3s - loss: 0.1024 - val_loss: 0.1235 - lr: 0.0010

Epoch 00247: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 247/4000
24/24 - 3s - loss: 0.1022 - val_loss: 0.1262 - lr: 0.0010

Epoch 00248: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 248/4000
24/24 - 3s - loss: 0.1015 - val_loss: 0.1237 - lr: 0.0010

Epoch 00249: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 249/4000
24/24 - 3s - loss: 0.1020 - val_loss: 0.1261 - lr: 0.0010

Epoch 00250: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 250/4000
Model saved in ./model/scPDB_1221_pdbid--250--0.1206--0.0010000.
24/24 - 3s - loss: 0.1017 - val_loss: 0.1206 - lr: 0.0010

Epoch 00251: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 251/4000
24/24 - 3s - loss: 0.1018 - val_loss: 0.1232 - lr: 0.0010

Epoch 00252: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 252/4000
24/24 - 3s - loss: 0.1015 - val_loss: 0.1264 - lr: 0.0010

Epoch 00253: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 253/4000
24/24 - 3s - loss: 0.1004 - val_loss: 0.1234 - lr: 0.0010

Epoch 00254: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 254/4000
24/24 - 3s - loss: 0.1018 - val_loss: 0.1285 - lr: 0.0010

Epoch 00255: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 255/4000
24/24 - 3s - loss: 0.1018 - val_loss: 0.1267 - lr: 0.0010

Epoch 00256: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 256/4000
24/24 - 3s - loss: 0.1006 - val_loss: 0.1245 - lr: 0.0010

Epoch 00257: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 257/4000
24/24 - 3s - loss: 0.1008 - val_loss: 0.1250 - lr: 0.0010

Epoch 00258: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 258/4000
24/24 - 3s - loss: 0.1013 - val_loss: 0.1247 - lr: 0.0010

Epoch 00259: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 259/4000
24/24 - 3s - loss: 0.1003 - val_loss: 0.1256 - lr: 0.0010

Epoch 00260: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 260/4000
24/24 - 3s - loss: 0.1006 - val_loss: 0.1231 - lr: 0.0010

Epoch 00261: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 261/4000
24/24 - 3s - loss: 0.0998 - val_loss: 0.1255 - lr: 0.0010

Epoch 00262: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 262/4000
24/24 - 3s - loss: 0.1002 - val_loss: 0.1280 - lr: 0.0010

Epoch 00263: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 263/4000
24/24 - 3s - loss: 0.0998 - val_loss: 0.1254 - lr: 0.0010

Epoch 00264: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 264/4000
24/24 - 3s - loss: 0.1001 - val_loss: 0.1236 - lr: 0.0010

Epoch 00265: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 265/4000
24/24 - 3s - loss: 0.0995 - val_loss: 0.1236 - lr: 0.0010

Epoch 00266: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 266/4000
24/24 - 3s - loss: 0.0994 - val_loss: 0.1240 - lr: 0.0010

Epoch 00267: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 267/4000
24/24 - 3s - loss: 0.1001 - val_loss: 0.1261 - lr: 0.0010

Epoch 00268: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 268/4000
24/24 - 3s - loss: 0.0987 - val_loss: 0.1225 - lr: 0.0010

Epoch 00269: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 269/4000
24/24 - 3s - loss: 0.1000 - val_loss: 0.1180 - lr: 0.0010

Epoch 00270: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 270/4000
24/24 - 3s - loss: 0.1000 - val_loss: 0.1247 - lr: 0.0010

Epoch 00271: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 271/4000
24/24 - 3s - loss: 0.0988 - val_loss: 0.1190 - lr: 0.0010

Epoch 00272: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 272/4000
24/24 - 3s - loss: 0.0990 - val_loss: 0.1235 - lr: 0.0010

Epoch 00273: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 273/4000
24/24 - 3s - loss: 0.0993 - val_loss: 0.1281 - lr: 0.0010

Epoch 00274: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 274/4000
24/24 - 3s - loss: 0.0997 - val_loss: 0.1228 - lr: 0.0010

Epoch 00275: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 275/4000
24/24 - 3s - loss: 0.0991 - val_loss: 0.1204 - lr: 0.0010

Epoch 00276: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 276/4000
24/24 - 2s - loss: 0.0977 - val_loss: 0.1260 - lr: 0.0010

Epoch 00277: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 277/4000
24/24 - 3s - loss: 0.0976 - val_loss: 0.1251 - lr: 0.0010

Epoch 00278: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 278/4000
24/24 - 3s - loss: 0.0982 - val_loss: 0.1225 - lr: 0.0010

Epoch 00279: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 279/4000
24/24 - 3s - loss: 0.0980 - val_loss: 0.1261 - lr: 0.0010

Epoch 00280: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 280/4000
24/24 - 3s - loss: 0.0979 - val_loss: 0.1203 - lr: 0.0010

Epoch 00281: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 281/4000
24/24 - 3s - loss: 0.0975 - val_loss: 0.1254 - lr: 0.0010

Epoch 00282: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 282/4000
24/24 - 3s - loss: 0.0982 - val_loss: 0.1224 - lr: 0.0010

Epoch 00283: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 283/4000
24/24 - 3s - loss: 0.0970 - val_loss: 0.1270 - lr: 0.0010

Epoch 00284: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 284/4000
24/24 - 3s - loss: 0.0976 - val_loss: 0.1304 - lr: 0.0010

Epoch 00285: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 285/4000
24/24 - 3s - loss: 0.0977 - val_loss: 0.1238 - lr: 0.0010

Epoch 00286: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 286/4000
24/24 - 3s - loss: 0.0969 - val_loss: 0.1246 - lr: 0.0010

Epoch 00287: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 287/4000
24/24 - 3s - loss: 0.0971 - val_loss: 0.1266 - lr: 0.0010

Epoch 00288: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 288/4000
24/24 - 3s - loss: 0.0977 - val_loss: 0.1247 - lr: 0.0010

Epoch 00289: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 289/4000
24/24 - 3s - loss: 0.0958 - val_loss: 0.1250 - lr: 0.0010

Epoch 00290: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 290/4000
24/24 - 3s - loss: 0.0976 - val_loss: 0.1235 - lr: 0.0010

Epoch 00291: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 291/4000
24/24 - 3s - loss: 0.0971 - val_loss: 0.1239 - lr: 0.0010

Epoch 00292: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 292/4000
24/24 - 3s - loss: 0.0967 - val_loss: 0.1246 - lr: 0.0010

Epoch 00293: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 293/4000
24/24 - 3s - loss: 0.0949 - val_loss: 0.1255 - lr: 0.0010

Epoch 00294: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 294/4000
24/24 - 3s - loss: 0.0977 - val_loss: 0.1231 - lr: 0.0010

Epoch 00295: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 295/4000
24/24 - 3s - loss: 0.0972 - val_loss: 0.1265 - lr: 0.0010

Epoch 00296: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 296/4000
24/24 - 3s - loss: 0.0959 - val_loss: 0.1195 - lr: 0.0010

Epoch 00297: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 297/4000
24/24 - 3s - loss: 0.0959 - val_loss: 0.1261 - lr: 0.0010

Epoch 00298: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 298/4000
24/24 - 3s - loss: 0.0948 - val_loss: 0.1260 - lr: 0.0010

Epoch 00299: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 299/4000
24/24 - 3s - loss: 0.0954 - val_loss: 0.1257 - lr: 0.0010

Epoch 00300: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 300/4000
Model saved in ./model/scPDB_1221_pdbid--300--0.1227--0.0010000.
24/24 - 3s - loss: 0.0967 - val_loss: 0.1227 - lr: 0.0010

Epoch 00301: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 301/4000
24/24 - 3s - loss: 0.0954 - val_loss: 0.1267 - lr: 0.0010

Epoch 00302: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 302/4000
24/24 - 3s - loss: 0.0960 - val_loss: 0.1300 - lr: 0.0010

Epoch 00303: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 303/4000
24/24 - 3s - loss: 0.0947 - val_loss: 0.1232 - lr: 0.0010

Epoch 00304: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 304/4000
24/24 - 3s - loss: 0.0960 - val_loss: 0.1249 - lr: 0.0010

Epoch 00305: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 305/4000
24/24 - 3s - loss: 0.0945 - val_loss: 0.1224 - lr: 0.0010

Epoch 00306: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 306/4000
24/24 - 3s - loss: 0.0948 - val_loss: 0.1260 - lr: 0.0010

Epoch 00307: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 307/4000
24/24 - 3s - loss: 0.0948 - val_loss: 0.1182 - lr: 0.0010

Epoch 00308: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 308/4000
24/24 - 3s - loss: 0.0948 - val_loss: 0.1272 - lr: 0.0010

Epoch 00309: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 309/4000
24/24 - 3s - loss: 0.0941 - val_loss: 0.1259 - lr: 0.0010

Epoch 00310: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 310/4000
24/24 - 3s - loss: 0.0954 - val_loss: 0.1300 - lr: 0.0010

Epoch 00311: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 311/4000
24/24 - 3s - loss: 0.0939 - val_loss: 0.1230 - lr: 0.0010

Epoch 00312: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 312/4000
24/24 - 3s - loss: 0.0958 - val_loss: 0.1273 - lr: 0.0010

Epoch 00313: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 313/4000
24/24 - 3s - loss: 0.0939 - val_loss: 0.1302 - lr: 0.0010

Epoch 00314: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 314/4000
24/24 - 3s - loss: 0.0930 - val_loss: 0.1215 - lr: 0.0010

Epoch 00315: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 315/4000
24/24 - 3s - loss: 0.0947 - val_loss: 0.1318 - lr: 0.0010

Epoch 00316: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 316/4000
24/24 - 3s - loss: 0.0943 - val_loss: 0.1281 - lr: 0.0010

Epoch 00317: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 317/4000
24/24 - 3s - loss: 0.0933 - val_loss: 0.1242 - lr: 0.0010

Epoch 00318: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 318/4000
24/24 - 3s - loss: 0.0936 - val_loss: 0.1252 - lr: 0.0010

Epoch 00319: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 319/4000
24/24 - 3s - loss: 0.0958 - val_loss: 0.1260 - lr: 0.0010

Epoch 00320: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 320/4000
24/24 - 3s - loss: 0.0933 - val_loss: 0.1273 - lr: 0.0010

Epoch 00321: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 321/4000
24/24 - 3s - loss: 0.0913 - val_loss: 0.1255 - lr: 0.0010

Epoch 00322: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 322/4000
24/24 - 3s - loss: 0.0935 - val_loss: 0.1248 - lr: 0.0010

Epoch 00323: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 323/4000
24/24 - 3s - loss: 0.0934 - val_loss: 0.1261 - lr: 0.0010

Epoch 00324: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 324/4000
24/24 - 3s - loss: 0.0928 - val_loss: 0.1250 - lr: 0.0010

Epoch 00325: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 325/4000
24/24 - 3s - loss: 0.0935 - val_loss: 0.1279 - lr: 0.0010

Epoch 00326: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 326/4000
24/24 - 3s - loss: 0.0933 - val_loss: 0.1225 - lr: 0.0010

Epoch 00327: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 327/4000
24/24 - 3s - loss: 0.0923 - val_loss: 0.1257 - lr: 0.0010

Epoch 00328: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 328/4000
24/24 - 3s - loss: 0.0916 - val_loss: 0.1265 - lr: 0.0010

Epoch 00329: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 329/4000
24/24 - 3s - loss: 0.0935 - val_loss: 0.1258 - lr: 0.0010

Epoch 00330: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 330/4000
24/24 - 3s - loss: 0.0922 - val_loss: 0.1260 - lr: 0.0010

Epoch 00331: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 331/4000
24/24 - 3s - loss: 0.0929 - val_loss: 0.1254 - lr: 0.0010

Epoch 00332: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 332/4000
24/24 - 3s - loss: 0.0922 - val_loss: 0.1280 - lr: 0.0010

Epoch 00333: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 333/4000
24/24 - 3s - loss: 0.0927 - val_loss: 0.1224 - lr: 0.0010

Epoch 00334: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 334/4000
24/24 - 3s - loss: 0.0913 - val_loss: 0.1213 - lr: 0.0010

Epoch 00335: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 335/4000
24/24 - 3s - loss: 0.0920 - val_loss: 0.1271 - lr: 0.0010

Epoch 00336: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 336/4000
24/24 - 3s - loss: 0.0915 - val_loss: 0.1263 - lr: 0.0010

Epoch 00337: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 337/4000
24/24 - 3s - loss: 0.0920 - val_loss: 0.1293 - lr: 0.0010

Epoch 00338: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 338/4000
24/24 - 3s - loss: 0.0921 - val_loss: 0.1252 - lr: 0.0010

Epoch 00339: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 339/4000
24/24 - 3s - loss: 0.0920 - val_loss: 0.1220 - lr: 0.0010

Epoch 00340: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 340/4000
24/24 - 3s - loss: 0.0899 - val_loss: 0.1276 - lr: 0.0010

Epoch 00341: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 341/4000
24/24 - 3s - loss: 0.0932 - val_loss: 0.1288 - lr: 0.0010

Epoch 00342: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 342/4000
24/24 - 3s - loss: 0.0907 - val_loss: 0.1252 - lr: 0.0010

Epoch 00343: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 343/4000
24/24 - 3s - loss: 0.0917 - val_loss: 0.1269 - lr: 0.0010

Epoch 00344: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 344/4000
24/24 - 3s - loss: 0.0914 - val_loss: 0.1244 - lr: 0.0010

Epoch 00345: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 345/4000
24/24 - 3s - loss: 0.0905 - val_loss: 0.1223 - lr: 0.0010

Epoch 00346: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 346/4000
24/24 - 3s - loss: 0.0901 - val_loss: 0.1276 - lr: 0.0010

Epoch 00347: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 347/4000
24/24 - 3s - loss: 0.0920 - val_loss: 0.1263 - lr: 0.0010

Epoch 00348: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 348/4000
24/24 - 3s - loss: 0.0909 - val_loss: 0.1227 - lr: 0.0010

Epoch 00349: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 349/4000
24/24 - 3s - loss: 0.0900 - val_loss: 0.1248 - lr: 0.0010

Epoch 00350: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 350/4000
Model saved in ./model/scPDB_1221_pdbid--350--0.1271--0.0010000.
24/24 - 3s - loss: 0.0895 - val_loss: 0.1271 - lr: 0.0010

Epoch 00351: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 351/4000
24/24 - 3s - loss: 0.0903 - val_loss: 0.1273 - lr: 0.0010

Epoch 00352: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 352/4000
24/24 - 3s - loss: 0.0913 - val_loss: 0.1250 - lr: 0.0010

Epoch 00353: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 353/4000
24/24 - 3s - loss: 0.0899 - val_loss: 0.1294 - lr: 0.0010

Epoch 00354: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 354/4000
24/24 - 3s - loss: 0.0907 - val_loss: 0.1261 - lr: 0.0010

Epoch 00355: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 355/4000
24/24 - 3s - loss: 0.0892 - val_loss: 0.1295 - lr: 0.0010

Epoch 00356: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 356/4000
24/24 - 3s - loss: 0.0904 - val_loss: 0.1227 - lr: 0.0010

Epoch 00357: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 357/4000
24/24 - 3s - loss: 0.0889 - val_loss: 0.1292 - lr: 0.0010

Epoch 00358: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 358/4000
24/24 - 3s - loss: 0.0898 - val_loss: 0.1259 - lr: 0.0010

Epoch 00359: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 359/4000
24/24 - 3s - loss: 0.0896 - val_loss: 0.1247 - lr: 0.0010

Epoch 00360: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 360/4000
24/24 - 3s - loss: 0.0899 - val_loss: 0.1287 - lr: 0.0010

Epoch 00361: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 361/4000
24/24 - 3s - loss: 0.0906 - val_loss: 0.1272 - lr: 0.0010

Epoch 00362: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 362/4000
24/24 - 3s - loss: 0.0888 - val_loss: 0.1291 - lr: 0.0010

Epoch 00363: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 363/4000
24/24 - 3s - loss: 0.0901 - val_loss: 0.1300 - lr: 0.0010

Epoch 00364: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 364/4000
24/24 - 3s - loss: 0.0893 - val_loss: 0.1276 - lr: 0.0010

Epoch 00365: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 365/4000
24/24 - 3s - loss: 0.0895 - val_loss: 0.1226 - lr: 0.0010

Epoch 00366: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 366/4000
24/24 - 3s - loss: 0.0882 - val_loss: 0.1311 - lr: 0.0010

Epoch 00367: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 367/4000
24/24 - 3s - loss: 0.0894 - val_loss: 0.1303 - lr: 0.0010

Epoch 00368: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 368/4000
24/24 - 3s - loss: 0.0897 - val_loss: 0.1259 - lr: 0.0010

Epoch 00369: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 369/4000
24/24 - 3s - loss: 0.0889 - val_loss: 0.1277 - lr: 0.0010

Epoch 00370: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 370/4000
24/24 - 3s - loss: 0.0885 - val_loss: 0.1281 - lr: 0.0010

Epoch 00371: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 371/4000
24/24 - 3s - loss: 0.0889 - val_loss: 0.1281 - lr: 0.0010

Epoch 00372: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 372/4000
24/24 - 3s - loss: 0.0876 - val_loss: 0.1288 - lr: 0.0010

Epoch 00373: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 373/4000
24/24 - 3s - loss: 0.0893 - val_loss: 0.1298 - lr: 0.0010

Epoch 00374: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 374/4000
24/24 - 3s - loss: 0.0882 - val_loss: 0.1294 - lr: 0.0010

Epoch 00375: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 375/4000
24/24 - 3s - loss: 0.0881 - val_loss: 0.1229 - lr: 0.0010

Epoch 00376: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 376/4000
24/24 - 3s - loss: 0.0879 - val_loss: 0.1304 - lr: 0.0010

Epoch 00377: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 377/4000
24/24 - 3s - loss: 0.0876 - val_loss: 0.1241 - lr: 0.0010

Epoch 00378: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 378/4000
24/24 - 3s - loss: 0.0881 - val_loss: 0.1282 - lr: 0.0010

Epoch 00379: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 379/4000
24/24 - 3s - loss: 0.0871 - val_loss: 0.1287 - lr: 0.0010

Epoch 00380: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 380/4000
24/24 - 3s - loss: 0.0880 - val_loss: 0.1254 - lr: 0.0010

Epoch 00381: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 381/4000
24/24 - 3s - loss: 0.0874 - val_loss: 0.1273 - lr: 0.0010

Epoch 00382: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 382/4000
24/24 - 3s - loss: 0.0869 - val_loss: 0.1310 - lr: 0.0010

Epoch 00383: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 383/4000
24/24 - 3s - loss: 0.0875 - val_loss: 0.1300 - lr: 0.0010

Epoch 00384: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 384/4000
24/24 - 3s - loss: 0.0882 - val_loss: 0.1295 - lr: 0.0010

Epoch 00385: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 385/4000
24/24 - 3s - loss: 0.0874 - val_loss: 0.1301 - lr: 0.0010

Epoch 00386: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 386/4000
24/24 - 3s - loss: 0.0881 - val_loss: 0.1302 - lr: 0.0010

Epoch 00387: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 387/4000
24/24 - 3s - loss: 0.0870 - val_loss: 0.1311 - lr: 0.0010

Epoch 00388: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 388/4000
24/24 - 3s - loss: 0.0868 - val_loss: 0.1292 - lr: 0.0010

Epoch 00389: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 389/4000
24/24 - 3s - loss: 0.0857 - val_loss: 0.1276 - lr: 0.0010

Epoch 00390: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 390/4000
24/24 - 3s - loss: 0.0882 - val_loss: 0.1289 - lr: 0.0010

Epoch 00391: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 391/4000
24/24 - 3s - loss: 0.0871 - val_loss: 0.1318 - lr: 0.0010

Epoch 00392: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 392/4000
24/24 - 3s - loss: 0.0866 - val_loss: 0.1335 - lr: 0.0010

Epoch 00393: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 393/4000
24/24 - 3s - loss: 0.0854 - val_loss: 0.1245 - lr: 0.0010

Epoch 00394: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 394/4000
24/24 - 3s - loss: 0.0877 - val_loss: 0.1311 - lr: 0.0010

Epoch 00395: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 395/4000
24/24 - 3s - loss: 0.0862 - val_loss: 0.1249 - lr: 0.0010

Epoch 00396: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 396/4000
24/24 - 3s - loss: 0.0872 - val_loss: 0.1277 - lr: 0.0010

Epoch 00397: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 397/4000
24/24 - 3s - loss: 0.0863 - val_loss: 0.1288 - lr: 0.0010

Epoch 00398: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 398/4000
24/24 - 3s - loss: 0.0869 - val_loss: 0.1320 - lr: 0.0010

Epoch 00399: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 399/4000
24/24 - 3s - loss: 0.0861 - val_loss: 0.1297 - lr: 0.0010

Epoch 00400: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
Epoch 400/4000
Model saved in ./model/scPDB_1221_pdbid--400--0.1270--0.0010000.
24/24 - 3s - loss: 0.0858 - val_loss: 0.1270 - lr: 0.0010

Epoch 00401: LearningRateScheduler reducing learning rate to 0.001.
Epoch 401/4000
24/24 - 3s - loss: 0.0863 - val_loss: 0.1277 - lr: 0.0010

Epoch 00402: LearningRateScheduler reducing learning rate to 0.0009956919592956843.
Epoch 402/4000
24/24 - 3s - loss: 0.0857 - val_loss: 0.1310 - lr: 9.9569e-04

Epoch 00403: LearningRateScheduler reducing learning rate to 0.0009914024778060787.
Epoch 403/4000
24/24 - 3s - loss: 0.0849 - val_loss: 0.1281 - lr: 9.9140e-04

Epoch 00404: LearningRateScheduler reducing learning rate to 0.0009871314755773306.
Epoch 404/4000
24/24 - 3s - loss: 0.0861 - val_loss: 0.1317 - lr: 9.8713e-04

Epoch 00405: LearningRateScheduler reducing learning rate to 0.0009828788730000323.
Epoch 405/4000
24/24 - 3s - loss: 0.0851 - val_loss: 0.1262 - lr: 9.8288e-04

Epoch 00406: LearningRateScheduler reducing learning rate to 0.0009786445908077362.
Epoch 406/4000
24/24 - 3s - loss: 0.0860 - val_loss: 0.1295 - lr: 9.7864e-04

Epoch 00407: LearningRateScheduler reducing learning rate to 0.000974428550075478.
Epoch 407/4000
24/24 - 3s - loss: 0.0845 - val_loss: 0.1315 - lr: 9.7443e-04

Epoch 00408: LearningRateScheduler reducing learning rate to 0.0009702306722183054.
Epoch 408/4000
24/24 - 3s - loss: 0.0858 - val_loss: 0.1297 - lr: 9.7023e-04

Epoch 00409: LearningRateScheduler reducing learning rate to 0.0009660508789898133.
Epoch 409/4000
24/24 - 3s - loss: 0.0854 - val_loss: 0.1344 - lr: 9.6605e-04

Epoch 00410: LearningRateScheduler reducing learning rate to 0.0009618890924806854.
Epoch 410/4000
24/24 - 3s - loss: 0.0854 - val_loss: 0.1269 - lr: 9.6189e-04

Epoch 00411: LearningRateScheduler reducing learning rate to 0.0009577452351172412.
Epoch 411/4000
24/24 - 3s - loss: 0.0845 - val_loss: 0.1341 - lr: 9.5775e-04

Epoch 00412: LearningRateScheduler reducing learning rate to 0.0009536192296599917.
Epoch 412/4000
24/24 - 3s - loss: 0.0845 - val_loss: 0.1291 - lr: 9.5362e-04

Epoch 00413: LearningRateScheduler reducing learning rate to 0.0009495109992021982.
Epoch 413/4000
24/24 - 3s - loss: 0.0843 - val_loss: 0.1302 - lr: 9.4951e-04

Epoch 00414: LearningRateScheduler reducing learning rate to 0.0009454204671684397.
Epoch 414/4000
24/24 - 3s - loss: 0.0849 - val_loss: 0.1339 - lr: 9.4542e-04

Epoch 00415: LearningRateScheduler reducing learning rate to 0.0009413475573131849.
Epoch 415/4000
24/24 - 3s - loss: 0.0850 - val_loss: 0.1324 - lr: 9.4135e-04

Epoch 00416: LearningRateScheduler reducing learning rate to 0.0009372921937193714.
Epoch 416/4000
24/24 - 3s - loss: 0.0851 - val_loss: 0.1259 - lr: 9.3729e-04

Epoch 00417: LearningRateScheduler reducing learning rate to 0.000933254300796991.
Epoch 417/4000
24/24 - 3s - loss: 0.0827 - val_loss: 0.1317 - lr: 9.3325e-04

Epoch 00418: LearningRateScheduler reducing learning rate to 0.0009292338032816799.
Epoch 418/4000
24/24 - 3s - loss: 0.0849 - val_loss: 0.1296 - lr: 9.2923e-04

Epoch 00419: LearningRateScheduler reducing learning rate to 0.0009252306262333164.
Epoch 419/4000
24/24 - 3s - loss: 0.0840 - val_loss: 0.1273 - lr: 9.2523e-04

Epoch 00420: LearningRateScheduler reducing learning rate to 0.0009212446950346237.
Epoch 420/4000
24/24 - 3s - loss: 0.0841 - val_loss: 0.1353 - lr: 9.2124e-04

Epoch 00421: LearningRateScheduler reducing learning rate to 0.0009172759353897796.
Epoch 421/4000
24/24 - 3s - loss: 0.0834 - val_loss: 0.1291 - lr: 9.1728e-04

Epoch 00422: LearningRateScheduler reducing learning rate to 0.0009133242733230312.
Epoch 422/4000
24/24 - 3s - loss: 0.0841 - val_loss: 0.1294 - lr: 9.1332e-04

Epoch 00423: LearningRateScheduler reducing learning rate to 0.0009093896351773159.
Epoch 423/4000
24/24 - 3s - loss: 0.0835 - val_loss: 0.1323 - lr: 9.0939e-04

Epoch 00424: LearningRateScheduler reducing learning rate to 0.0009054719476128893.
Epoch 424/4000
24/24 - 3s - loss: 0.0844 - val_loss: 0.1340 - lr: 9.0547e-04

Epoch 00425: LearningRateScheduler reducing learning rate to 0.0009015711376059569.
Epoch 425/4000
24/24 - 3s - loss: 0.0825 - val_loss: 0.1300 - lr: 9.0157e-04

Epoch 00426: LearningRateScheduler reducing learning rate to 0.0008976871324473143.
Epoch 426/4000
24/24 - 3s - loss: 0.0832 - val_loss: 0.1343 - lr: 8.9769e-04

Epoch 00427: LearningRateScheduler reducing learning rate to 0.0008938198597409907.
Epoch 427/4000
24/24 - 3s - loss: 0.0826 - val_loss: 0.1308 - lr: 8.9382e-04

Epoch 00428: LearningRateScheduler reducing learning rate to 0.0008899692474029008.
Epoch 428/4000
24/24 - 3s - loss: 0.0828 - val_loss: 0.1284 - lr: 8.8997e-04

Epoch 00429: LearningRateScheduler reducing learning rate to 0.0008861352236594998.
Epoch 429/4000
24/24 - 3s - loss: 0.0837 - val_loss: 0.1315 - lr: 8.8614e-04

Epoch 00430: LearningRateScheduler reducing learning rate to 0.0008823177170464468.
Epoch 430/4000
24/24 - 3s - loss: 0.0833 - val_loss: 0.1271 - lr: 8.8232e-04

Epoch 00431: LearningRateScheduler reducing learning rate to 0.0008785166564072717.
Epoch 431/4000
24/24 - 3s - loss: 0.0823 - val_loss: 0.1304 - lr: 8.7852e-04

Epoch 00432: LearningRateScheduler reducing learning rate to 0.0008747319708920499.
Epoch 432/4000
24/24 - 3s - loss: 0.0823 - val_loss: 0.1307 - lr: 8.7473e-04

Epoch 00433: LearningRateScheduler reducing learning rate to 0.0008709635899560806.
Epoch 433/4000
24/24 - 3s - loss: 0.0825 - val_loss: 0.1314 - lr: 8.7096e-04

Epoch 00434: LearningRateScheduler reducing learning rate to 0.000867211443358573.
Epoch 434/4000
24/24 - 3s - loss: 0.0840 - val_loss: 0.1319 - lr: 8.6721e-04

Epoch 00435: LearningRateScheduler reducing learning rate to 0.0008634754611613358.
Epoch 435/4000
24/24 - 3s - loss: 0.0811 - val_loss: 0.1307 - lr: 8.6348e-04

Epoch 00436: LearningRateScheduler reducing learning rate to 0.000859755573727475.
Epoch 436/4000
24/24 - 3s - loss: 0.0823 - val_loss: 0.1359 - lr: 8.5976e-04

Epoch 00437: LearningRateScheduler reducing learning rate to 0.0008560517117200947.
Epoch 437/4000
24/24 - 3s - loss: 0.0827 - val_loss: 0.1295 - lr: 8.5605e-04

Epoch 00438: LearningRateScheduler reducing learning rate to 0.0008523638061010054.
Epoch 438/4000
24/24 - 3s - loss: 0.0826 - val_loss: 0.1313 - lr: 8.5236e-04

Epoch 00439: LearningRateScheduler reducing learning rate to 0.0008486917881294368.
Epoch 439/4000
24/24 - 3s - loss: 0.0811 - val_loss: 0.1366 - lr: 8.4869e-04

Epoch 00440: LearningRateScheduler reducing learning rate to 0.0008450355893607567.
Epoch 440/4000
24/24 - 3s - loss: 0.0817 - val_loss: 0.1310 - lr: 8.4504e-04

Epoch 00441: LearningRateScheduler reducing learning rate to 0.0008413951416451951.
Epoch 441/4000
24/24 - 3s - loss: 0.0819 - val_loss: 0.1318 - lr: 8.4140e-04

Epoch 00442: LearningRateScheduler reducing learning rate to 0.0008377703771265742.
Epoch 442/4000
24/24 - 3s - loss: 0.0808 - val_loss: 0.1303 - lr: 8.3777e-04

Epoch 00443: LearningRateScheduler reducing learning rate to 0.0008341612282410429.
Epoch 443/4000
24/24 - 3s - loss: 0.0824 - val_loss: 0.1331 - lr: 8.3416e-04

Epoch 00444: LearningRateScheduler reducing learning rate to 0.0008305676277158185.
Epoch 444/4000
24/24 - 3s - loss: 0.0816 - val_loss: 0.1307 - lr: 8.3057e-04

Epoch 00445: LearningRateScheduler reducing learning rate to 0.0008269895085679318.
Epoch 445/4000
24/24 - 3s - loss: 0.0818 - val_loss: 0.1333 - lr: 8.2699e-04

Epoch 00446: LearningRateScheduler reducing learning rate to 0.0008234268041029791.
Epoch 446/4000
24/24 - 3s - loss: 0.0813 - val_loss: 0.1341 - lr: 8.2343e-04

Epoch 00447: LearningRateScheduler reducing learning rate to 0.0008198794479138788.
Epoch 447/4000
24/24 - 3s - loss: 0.0811 - val_loss: 0.1281 - lr: 8.1988e-04

Epoch 00448: LearningRateScheduler reducing learning rate to 0.000816347373879634.
Epoch 448/4000
24/24 - 3s - loss: 0.0808 - val_loss: 0.1312 - lr: 8.1635e-04

Epoch 00449: LearningRateScheduler reducing learning rate to 0.0008128305161640992.
Epoch 449/4000
24/24 - 3s - loss: 0.0818 - val_loss: 0.1308 - lr: 8.1283e-04

Epoch 00450: LearningRateScheduler reducing learning rate to 0.0008093288092147543.
Epoch 450/4000
Model saved in ./model/scPDB_1221_pdbid--450--0.1317--0.0008093.
24/24 - 3s - loss: 0.0814 - val_loss: 0.1317 - lr: 8.0933e-04

Epoch 00451: LearningRateScheduler reducing learning rate to 0.0008058421877614818.
Epoch 451/4000
24/24 - 3s - loss: 0.0815 - val_loss: 0.1341 - lr: 8.0584e-04

Epoch 00452: LearningRateScheduler reducing learning rate to 0.0008023705868153506.
Epoch 452/4000
24/24 - 3s - loss: 0.0816 - val_loss: 0.1365 - lr: 8.0237e-04

Epoch 00453: LearningRateScheduler reducing learning rate to 0.0007989139416674043.
Epoch 453/4000
24/24 - 3s - loss: 0.0806 - val_loss: 0.1344 - lr: 7.9891e-04

Epoch 00454: LearningRateScheduler reducing learning rate to 0.0007954721878874558.
Epoch 454/4000
24/24 - 3s - loss: 0.0794 - val_loss: 0.1314 - lr: 7.9547e-04

Epoch 00455: LearningRateScheduler reducing learning rate to 0.0007920452613228855.
Epoch 455/4000
24/24 - 3s - loss: 0.0816 - val_loss: 0.1339 - lr: 7.9205e-04

Epoch 00456: LearningRateScheduler reducing learning rate to 0.0007886330980974462.
Epoch 456/4000
24/24 - 3s - loss: 0.0801 - val_loss: 0.1330 - lr: 7.8863e-04

Epoch 00457: LearningRateScheduler reducing learning rate to 0.0007852356346100718.
Epoch 457/4000
24/24 - 3s - loss: 0.0801 - val_loss: 0.1270 - lr: 7.8524e-04

Epoch 00458: LearningRateScheduler reducing learning rate to 0.0007818528075336923.
Epoch 458/4000
24/24 - 3s - loss: 0.0810 - val_loss: 0.1393 - lr: 7.8185e-04

Epoch 00459: LearningRateScheduler reducing learning rate to 0.0007784845538140537.
Epoch 459/4000
24/24 - 3s - loss: 0.0796 - val_loss: 0.1350 - lr: 7.7848e-04

Epoch 00460: LearningRateScheduler reducing learning rate to 0.0007751308106685417.
Epoch 460/4000
24/24 - 3s - loss: 0.0801 - val_loss: 0.1304 - lr: 7.7513e-04

Epoch 00461: LearningRateScheduler reducing learning rate to 0.0007717915155850124.
Epoch 461/4000
24/24 - 3s - loss: 0.0805 - val_loss: 0.1354 - lr: 7.7179e-04

Epoch 00462: LearningRateScheduler reducing learning rate to 0.0007684666063206267.
Epoch 462/4000
24/24 - 3s - loss: 0.0795 - val_loss: 0.1361 - lr: 7.6847e-04

Epoch 00463: LearningRateScheduler reducing learning rate to 0.00076515602090069.
Epoch 463/4000
24/24 - 3s - loss: 0.0803 - val_loss: 0.1329 - lr: 7.6516e-04

Epoch 00464: LearningRateScheduler reducing learning rate to 0.0007618596976174977.
Epoch 464/4000
24/24 - 3s - loss: 0.0799 - val_loss: 0.1356 - lr: 7.6186e-04

Epoch 00465: LearningRateScheduler reducing learning rate to 0.0007585775750291837.
Epoch 465/4000
24/24 - 3s - loss: 0.0796 - val_loss: 0.1327 - lr: 7.5858e-04

Epoch 00466: LearningRateScheduler reducing learning rate to 0.000755309591958577.
Epoch 466/4000
24/24 - 3s - loss: 0.0806 - val_loss: 0.1353 - lr: 7.5531e-04

Epoch 00467: LearningRateScheduler reducing learning rate to 0.0007520556874920593.
Epoch 467/4000
24/24 - 3s - loss: 0.0793 - val_loss: 0.1364 - lr: 7.5206e-04

Epoch 00468: LearningRateScheduler reducing learning rate to 0.0007488158009784314.
Epoch 468/4000
24/24 - 3s - loss: 0.0793 - val_loss: 0.1292 - lr: 7.4882e-04

Epoch 00469: LearningRateScheduler reducing learning rate to 0.0007455898720277815.
Epoch 469/4000
24/24 - 3s - loss: 0.0792 - val_loss: 0.1361 - lr: 7.4559e-04

Epoch 00470: LearningRateScheduler reducing learning rate to 0.0007423778405103603.
Epoch 470/4000
24/24 - 3s - loss: 0.0797 - val_loss: 0.1367 - lr: 7.4238e-04

Epoch 00471: LearningRateScheduler reducing learning rate to 0.0007391796465554596.
Epoch 471/4000
24/24 - 3s - loss: 0.0796 - val_loss: 0.1366 - lr: 7.3918e-04

Epoch 00472: LearningRateScheduler reducing learning rate to 0.0007359952305502971.
Epoch 472/4000
24/24 - 3s - loss: 0.0787 - val_loss: 0.1352 - lr: 7.3600e-04

Epoch 00473: LearningRateScheduler reducing learning rate to 0.0007328245331389041.
Epoch 473/4000
24/24 - 3s - loss: 0.0799 - val_loss: 0.1393 - lr: 7.3282e-04

Epoch 00474: LearningRateScheduler reducing learning rate to 0.0007296674952210205.
Epoch 474/4000
24/24 - 3s - loss: 0.0786 - val_loss: 0.1300 - lr: 7.2967e-04

Epoch 00475: LearningRateScheduler reducing learning rate to 0.0007265240579509923.
Epoch 475/4000
24/24 - 3s - loss: 0.0795 - val_loss: 0.1384 - lr: 7.2652e-04

Epoch 00476: LearningRateScheduler reducing learning rate to 0.0007233941627366748.
Epoch 476/4000
24/24 - 3s - loss: 0.0786 - val_loss: 0.1393 - lr: 7.2339e-04

Epoch 00477: LearningRateScheduler reducing learning rate to 0.0007202777512383407.
Epoch 477/4000
24/24 - 3s - loss: 0.0784 - val_loss: 0.1319 - lr: 7.2028e-04

Epoch 00478: LearningRateScheduler reducing learning rate to 0.0007171747653675931.
Epoch 478/4000
24/24 - 3s - loss: 0.0788 - val_loss: 0.1330 - lr: 7.1717e-04

Epoch 00479: LearningRateScheduler reducing learning rate to 0.0007140851472862814.
Epoch 479/4000
24/24 - 3s - loss: 0.0791 - val_loss: 0.1360 - lr: 7.1409e-04

Epoch 00480: LearningRateScheduler reducing learning rate to 0.0007110088394054247.
Epoch 480/4000
24/24 - 3s - loss: 0.0780 - val_loss: 0.1358 - lr: 7.1101e-04

Epoch 00481: LearningRateScheduler reducing learning rate to 0.0007079457843841379.
Epoch 481/4000
24/24 - 3s - loss: 0.0776 - val_loss: 0.1334 - lr: 7.0795e-04

Epoch 00482: LearningRateScheduler reducing learning rate to 0.0007048959251285623.
Epoch 482/4000
24/24 - 3s - loss: 0.0793 - val_loss: 0.1352 - lr: 7.0490e-04

Epoch 00483: LearningRateScheduler reducing learning rate to 0.0007018592047908023.
Epoch 483/4000
24/24 - 3s - loss: 0.0776 - val_loss: 0.1349 - lr: 7.0186e-04

Epoch 00484: LearningRateScheduler reducing learning rate to 0.0006988355667678647.
Epoch 484/4000
24/24 - 3s - loss: 0.0790 - val_loss: 0.1378 - lr: 6.9884e-04

Epoch 00485: LearningRateScheduler reducing learning rate to 0.0006958249547006053.
Epoch 485/4000
24/24 - 3s - loss: 0.0781 - val_loss: 0.1381 - lr: 6.9582e-04

Epoch 00486: LearningRateScheduler reducing learning rate to 0.0006928273124726763.
Epoch 486/4000
24/24 - 3s - loss: 0.0780 - val_loss: 0.1363 - lr: 6.9283e-04

Epoch 00487: LearningRateScheduler reducing learning rate to 0.0006898425842094824.
Epoch 487/4000
24/24 - 3s - loss: 0.0771 - val_loss: 0.1391 - lr: 6.8984e-04

Epoch 00488: LearningRateScheduler reducing learning rate to 0.0006868707142771377.
Epoch 488/4000
24/24 - 3s - loss: 0.0788 - val_loss: 0.1326 - lr: 6.8687e-04

Epoch 00489: LearningRateScheduler reducing learning rate to 0.0006839116472814293.
Epoch 489/4000
24/24 - 3s - loss: 0.0769 - val_loss: 0.1384 - lr: 6.8391e-04

Epoch 00490: LearningRateScheduler reducing learning rate to 0.0006809653280667854.
Epoch 490/4000
24/24 - 3s - loss: 0.0789 - val_loss: 0.1350 - lr: 6.8097e-04

Epoch 00491: LearningRateScheduler reducing learning rate to 0.0006780317017152459.
Epoch 491/4000
24/24 - 3s - loss: 0.0777 - val_loss: 0.1443 - lr: 6.7803e-04

Epoch 00492: LearningRateScheduler reducing learning rate to 0.0006751107135454402.
Epoch 492/4000
24/24 - 3s - loss: 0.0776 - val_loss: 0.1352 - lr: 6.7511e-04

Epoch 00493: LearningRateScheduler reducing learning rate to 0.0006722023091115667.
Epoch 493/4000
24/24 - 3s - loss: 0.0769 - val_loss: 0.1351 - lr: 6.7220e-04

Epoch 00494: LearningRateScheduler reducing learning rate to 0.0006693064342023792.
Epoch 494/4000
24/24 - 3s - loss: 0.0787 - val_loss: 0.1410 - lr: 6.6931e-04

Epoch 00495: LearningRateScheduler reducing learning rate to 0.0006664230348401749.
Epoch 495/4000
24/24 - 3s - loss: 0.0780 - val_loss: 0.1347 - lr: 6.6642e-04

Epoch 00496: LearningRateScheduler reducing learning rate to 0.0006635520572797897.
Epoch 496/4000
24/24 - 3s - loss: 0.0772 - val_loss: 0.1438 - lr: 6.6355e-04

Epoch 00497: LearningRateScheduler reducing learning rate to 0.000660693448007596.
Epoch 497/4000
24/24 - 3s - loss: 0.0771 - val_loss: 0.1282 - lr: 6.6069e-04

Epoch 00498: LearningRateScheduler reducing learning rate to 0.0006578471537405045.
Epoch 498/4000
24/24 - 3s - loss: 0.0775 - val_loss: 0.1409 - lr: 6.5785e-04

Epoch 00499: LearningRateScheduler reducing learning rate to 0.0006550131214249723.
Epoch 499/4000
24/24 - 3s - loss: 0.0767 - val_loss: 0.1375 - lr: 6.5501e-04

Epoch 00500: LearningRateScheduler reducing learning rate to 0.0006521912982360125.
Epoch 500/4000
Model saved in ./model/scPDB_1221_pdbid--500--0.1378--0.0006522.
24/24 - 3s - loss: 0.0772 - val_loss: 0.1378 - lr: 6.5219e-04

Epoch 00501: LearningRateScheduler reducing learning rate to 0.0006493816315762113.
Epoch 501/4000
24/24 - 3s - loss: 0.0764 - val_loss: 0.1364 - lr: 6.4938e-04

Epoch 00502: LearningRateScheduler reducing learning rate to 0.0006465840690747461.
Epoch 502/4000
24/24 - 3s - loss: 0.0773 - val_loss: 0.1392 - lr: 6.4658e-04

Epoch 00503: LearningRateScheduler reducing learning rate to 0.00064379855858641.
Epoch 503/4000
24/24 - 3s - loss: 0.0766 - val_loss: 0.1304 - lr: 6.4380e-04

Epoch 00504: LearningRateScheduler reducing learning rate to 0.0006410250481906399.
Epoch 504/4000
24/24 - 3s - loss: 0.0767 - val_loss: 0.1382 - lr: 6.4103e-04

Epoch 00505: LearningRateScheduler reducing learning rate to 0.0006382634861905487.
Epoch 505/4000
24/24 - 3s - loss: 0.0770 - val_loss: 0.1387 - lr: 6.3826e-04

Epoch 00506: LearningRateScheduler reducing learning rate to 0.0006355138211119613.
Epoch 506/4000
24/24 - 3s - loss: 0.0768 - val_loss: 0.1387 - lr: 6.3551e-04

Epoch 00507: LearningRateScheduler reducing learning rate to 0.0006327760017024557.
Epoch 507/4000
24/24 - 3s - loss: 0.0764 - val_loss: 0.1394 - lr: 6.3278e-04

Epoch 00508: LearningRateScheduler reducing learning rate to 0.0006300499769304075.
Epoch 508/4000
24/24 - 3s - loss: 0.0767 - val_loss: 0.1399 - lr: 6.3005e-04

Epoch 00509: LearningRateScheduler reducing learning rate to 0.000627335695984038.
Epoch 509/4000
24/24 - 3s - loss: 0.0768 - val_loss: 0.1341 - lr: 6.2734e-04

Epoch 00510: LearningRateScheduler reducing learning rate to 0.0006246331082704686.
Epoch 510/4000
24/24 - 3s - loss: 0.0765 - val_loss: 0.1403 - lr: 6.2463e-04

Epoch 00511: LearningRateScheduler reducing learning rate to 0.0006219421634147762.
Epoch 511/4000
24/24 - 3s - loss: 0.0764 - val_loss: 0.1388 - lr: 6.2194e-04

Epoch 00512: LearningRateScheduler reducing learning rate to 0.0006192628112590551.
Epoch 512/4000
24/24 - 3s - loss: 0.0773 - val_loss: 0.1361 - lr: 6.1926e-04

Epoch 00513: LearningRateScheduler reducing learning rate to 0.000616595001861482.
Epoch 513/4000
24/24 - 3s - loss: 0.0762 - val_loss: 0.1388 - lr: 6.1659e-04

Epoch 00514: LearningRateScheduler reducing learning rate to 0.0006139386854953852.
Epoch 514/4000
24/24 - 3s - loss: 0.0769 - val_loss: 0.1381 - lr: 6.1394e-04

Epoch 00515: LearningRateScheduler reducing learning rate to 0.0006112938126483171.
Epoch 515/4000
24/24 - 3s - loss: 0.0757 - val_loss: 0.1338 - lr: 6.1129e-04

Epoch 00516: LearningRateScheduler reducing learning rate to 0.0006086603340211317.
Epoch 516/4000
24/24 - 3s - loss: 0.0762 - val_loss: 0.1380 - lr: 6.0866e-04

Epoch 00517: LearningRateScheduler reducing learning rate to 0.0006060382005270663.
Epoch 517/4000
24/24 - 3s - loss: 0.0755 - val_loss: 0.1411 - lr: 6.0604e-04

Epoch 00518: LearningRateScheduler reducing learning rate to 0.0006034273632908255.
Epoch 518/4000
24/24 - 3s - loss: 0.0758 - val_loss: 0.1389 - lr: 6.0343e-04

Epoch 00519: LearningRateScheduler reducing learning rate to 0.0006008277736476707.
Epoch 519/4000
24/24 - 3s - loss: 0.0766 - val_loss: 0.1367 - lr: 6.0083e-04

Epoch 00520: LearningRateScheduler reducing learning rate to 0.0005982393831425131.
Epoch 520/4000
24/24 - 3s - loss: 0.0750 - val_loss: 0.1419 - lr: 5.9824e-04

Epoch 00521: LearningRateScheduler reducing learning rate to 0.0005956621435290103.
Epoch 521/4000
24/24 - 3s - loss: 0.0760 - val_loss: 0.1420 - lr: 5.9566e-04

Epoch 00522: LearningRateScheduler reducing learning rate to 0.0005930960067686675.
Epoch 522/4000
24/24 - 3s - loss: 0.0760 - val_loss: 0.1352 - lr: 5.9310e-04

Epoch 00523: LearningRateScheduler reducing learning rate to 0.000590540925029941.
Epoch 523/4000
24/24 - 3s - loss: 0.0760 - val_loss: 0.1455 - lr: 5.9054e-04

Epoch 00524: LearningRateScheduler reducing learning rate to 0.0005879968506873477.
Epoch 524/4000
24/24 - 3s - loss: 0.0756 - val_loss: 0.1353 - lr: 5.8800e-04

Epoch 00525: LearningRateScheduler reducing learning rate to 0.0005854637363205773.
Epoch 525/4000
24/24 - 3s - loss: 0.0758 - val_loss: 0.1381 - lr: 5.8546e-04

Epoch 00526: LearningRateScheduler reducing learning rate to 0.0005829415347136073.
Epoch 526/4000
24/24 - 3s - loss: 0.0759 - val_loss: 0.1383 - lr: 5.8294e-04

Epoch 00527: LearningRateScheduler reducing learning rate to 0.0005804301988538248.
Epoch 527/4000
24/24 - 3s - loss: 0.0751 - val_loss: 0.1304 - lr: 5.8043e-04

Epoch 00528: LearningRateScheduler reducing learning rate to 0.0005779296819311486.
Epoch 528/4000
24/24 - 3s - loss: 0.0750 - val_loss: 0.1380 - lr: 5.7793e-04

Epoch 00529: LearningRateScheduler reducing learning rate to 0.000575439937337157.
Epoch 529/4000
24/24 - 3s - loss: 0.0750 - val_loss: 0.1372 - lr: 5.7544e-04

Epoch 00530: LearningRateScheduler reducing learning rate to 0.0005729609186642196.
Epoch 530/4000
24/24 - 3s - loss: 0.0746 - val_loss: 0.1424 - lr: 5.7296e-04

Epoch 00531: LearningRateScheduler reducing learning rate to 0.000570492579704632.
Epoch 531/4000
24/24 - 3s - loss: 0.0758 - val_loss: 0.1387 - lr: 5.7049e-04

Epoch 00532: LearningRateScheduler reducing learning rate to 0.0005680348744497543.
Epoch 532/4000
24/24 - 3s - loss: 0.0755 - val_loss: 0.1454 - lr: 5.6803e-04

Epoch 00533: LearningRateScheduler reducing learning rate to 0.0005655877570891538.
Epoch 533/4000
24/24 - 3s - loss: 0.0745 - val_loss: 0.1368 - lr: 5.6559e-04

Epoch 00534: LearningRateScheduler reducing learning rate to 0.0005631511820097513.
Epoch 534/4000
24/24 - 3s - loss: 0.0747 - val_loss: 0.1396 - lr: 5.6315e-04

Epoch 00535: LearningRateScheduler reducing learning rate to 0.0005607251037949697.
Epoch 535/4000
24/24 - 3s - loss: 0.0752 - val_loss: 0.1388 - lr: 5.6073e-04

Epoch 00536: LearningRateScheduler reducing learning rate to 0.0005583094772238893.
Epoch 536/4000
24/24 - 3s - loss: 0.0740 - val_loss: 0.1402 - lr: 5.5831e-04

Epoch 00537: LearningRateScheduler reducing learning rate to 0.0005559042572704036.
Epoch 537/4000
24/24 - 3s - loss: 0.0756 - val_loss: 0.1406 - lr: 5.5590e-04

Epoch 00538: LearningRateScheduler reducing learning rate to 0.0005535093991023803.
Epoch 538/4000
24/24 - 3s - loss: 0.0744 - val_loss: 0.1383 - lr: 5.5351e-04

Epoch 00539: LearningRateScheduler reducing learning rate to 0.000551124858080826.
Epoch 539/4000
24/24 - 3s - loss: 0.0751 - val_loss: 0.1416 - lr: 5.5112e-04

Epoch 00540: LearningRateScheduler reducing learning rate to 0.0005487505897590534.
Epoch 540/4000
24/24 - 3s - loss: 0.0746 - val_loss: 0.1386 - lr: 5.4875e-04

Epoch 00541: LearningRateScheduler reducing learning rate to 0.0005463865498818542.
Epoch 541/4000
24/24 - 3s - loss: 0.0750 - val_loss: 0.1369 - lr: 5.4639e-04

Epoch 00542: LearningRateScheduler reducing learning rate to 0.0005440326943846725.
Epoch 542/4000
24/24 - 3s - loss: 0.0744 - val_loss: 0.1459 - lr: 5.4403e-04

Epoch 00543: LearningRateScheduler reducing learning rate to 0.0005416889793927849.
Epoch 543/4000
24/24 - 3s - loss: 0.0743 - val_loss: 0.1365 - lr: 5.4169e-04

Epoch 00544: LearningRateScheduler reducing learning rate to 0.0005393553612204814.
Epoch 544/4000
24/24 - 3s - loss: 0.0739 - val_loss: 0.1384 - lr: 5.3936e-04

Epoch 00545: LearningRateScheduler reducing learning rate to 0.0005370317963702527.
Epoch 545/4000
24/24 - 3s - loss: 0.0746 - val_loss: 0.1460 - lr: 5.3703e-04

Epoch 00546: LearningRateScheduler reducing learning rate to 0.0005347182415319779.
Epoch 546/4000
24/24 - 3s - loss: 0.0747 - val_loss: 0.1408 - lr: 5.3472e-04

Epoch 00547: LearningRateScheduler reducing learning rate to 0.0005324146535821179.
Epoch 547/4000
24/24 - 3s - loss: 0.0741 - val_loss: 0.1400 - lr: 5.3241e-04

Epoch 00548: LearningRateScheduler reducing learning rate to 0.0005301209895829121.
Epoch 548/4000
24/24 - 3s - loss: 0.0752 - val_loss: 0.1427 - lr: 5.3012e-04

Epoch 00549: LearningRateScheduler reducing learning rate to 0.0005278372067815767.
Epoch 549/4000
24/24 - 3s - loss: 0.0737 - val_loss: 0.1367 - lr: 5.2784e-04

Epoch 00550: LearningRateScheduler reducing learning rate to 0.0005255632626095095.
Epoch 550/4000
Model saved in ./model/scPDB_1221_pdbid--550--0.1506--0.0005256.
24/24 - 3s - loss: 0.0741 - val_loss: 0.1506 - lr: 5.2556e-04

Epoch 00551: LearningRateScheduler reducing learning rate to 0.0005232991146814946.
Epoch 551/4000
24/24 - 3s - loss: 0.0744 - val_loss: 0.1388 - lr: 5.2330e-04

Epoch 00552: LearningRateScheduler reducing learning rate to 0.0005210447207949143.
Epoch 552/4000
24/24 - 3s - loss: 0.0740 - val_loss: 0.1388 - lr: 5.2104e-04

Epoch 00553: LearningRateScheduler reducing learning rate to 0.0005188000389289611.
Epoch 553/4000
24/24 - 3s - loss: 0.0743 - val_loss: 0.1442 - lr: 5.1880e-04

Epoch 00554: LearningRateScheduler reducing learning rate to 0.0005165650272438546.
Epoch 554/4000
24/24 - 3s - loss: 0.0733 - val_loss: 0.1371 - lr: 5.1657e-04

Epoch 00555: LearningRateScheduler reducing learning rate to 0.000514339644080062.
Epoch 555/4000
24/24 - 3s - loss: 0.0749 - val_loss: 0.1377 - lr: 5.1434e-04

Epoch 00556: LearningRateScheduler reducing learning rate to 0.000512123847957522.
Epoch 556/4000
24/24 - 3s - loss: 0.0730 - val_loss: 0.1380 - lr: 5.1212e-04

Epoch 00557: LearningRateScheduler reducing learning rate to 0.0005099175975748702.
Epoch 557/4000
24/24 - 3s - loss: 0.0738 - val_loss: 0.1412 - lr: 5.0992e-04

Epoch 00558: LearningRateScheduler reducing learning rate to 0.0005077208518086707.
Epoch 558/4000
24/24 - 3s - loss: 0.0747 - val_loss: 0.1384 - lr: 5.0772e-04

Epoch 00559: LearningRateScheduler reducing learning rate to 0.0005055335697126491.
Epoch 559/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1411 - lr: 5.0553e-04

Epoch 00560: LearningRateScheduler reducing learning rate to 0.000503355710516929.
Epoch 560/4000
24/24 - 3s - loss: 0.0736 - val_loss: 0.1407 - lr: 5.0336e-04

Epoch 00561: LearningRateScheduler reducing learning rate to 0.0005011872336272722.
Epoch 561/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1419 - lr: 5.0119e-04

Epoch 00562: LearningRateScheduler reducing learning rate to 0.0004990280986243227.
Epoch 562/4000
24/24 - 3s - loss: 0.0738 - val_loss: 0.1437 - lr: 4.9903e-04

Epoch 00563: LearningRateScheduler reducing learning rate to 0.0004968782652628517.
Epoch 563/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1451 - lr: 4.9688e-04

Epoch 00564: LearningRateScheduler reducing learning rate to 0.0004947376934710095.
Epoch 564/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1398 - lr: 4.9474e-04

Epoch 00565: LearningRateScheduler reducing learning rate to 0.0004926063433495772.
Epoch 565/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1381 - lr: 4.9261e-04

Epoch 00566: LearningRateScheduler reducing learning rate to 0.0004904841751712231.
Epoch 566/4000
24/24 - 3s - loss: 0.0729 - val_loss: 0.1441 - lr: 4.9048e-04

Epoch 00567: LearningRateScheduler reducing learning rate to 0.0004883711493797627.
Epoch 567/4000
24/24 - 3s - loss: 0.0733 - val_loss: 0.1438 - lr: 4.8837e-04

Epoch 00568: LearningRateScheduler reducing learning rate to 0.0004862672265894213.
Epoch 568/4000
24/24 - 3s - loss: 0.0739 - val_loss: 0.1428 - lr: 4.8627e-04

Epoch 00569: LearningRateScheduler reducing learning rate to 0.00048417236758409933.
Epoch 569/4000
24/24 - 3s - loss: 0.0733 - val_loss: 0.1483 - lr: 4.8417e-04

Epoch 00570: LearningRateScheduler reducing learning rate to 0.0004820865333166421.
Epoch 570/4000
24/24 - 3s - loss: 0.0728 - val_loss: 0.1411 - lr: 4.8209e-04

Epoch 00571: LearningRateScheduler reducing learning rate to 0.00048000968490811155.
Epoch 571/4000
24/24 - 3s - loss: 0.0738 - val_loss: 0.1395 - lr: 4.8001e-04

Epoch 00572: LearningRateScheduler reducing learning rate to 0.00047794178364706164.
Epoch 572/4000
24/24 - 3s - loss: 0.0735 - val_loss: 0.1403 - lr: 4.7794e-04

Epoch 00573: LearningRateScheduler reducing learning rate to 0.0004758827909888169.
Epoch 573/4000
24/24 - 3s - loss: 0.0720 - val_loss: 0.1468 - lr: 4.7588e-04

Epoch 00574: LearningRateScheduler reducing learning rate to 0.0004738326685547537.
Epoch 574/4000
24/24 - 3s - loss: 0.0736 - val_loss: 0.1461 - lr: 4.7383e-04

Epoch 00575: LearningRateScheduler reducing learning rate to 0.00047179137813158523.
Epoch 575/4000
24/24 - 3s - loss: 0.0723 - val_loss: 0.1511 - lr: 4.7179e-04

Epoch 00576: LearningRateScheduler reducing learning rate to 0.00046975888167064917.
Epoch 576/4000
24/24 - 3s - loss: 0.0728 - val_loss: 0.1438 - lr: 4.6976e-04

Epoch 00577: LearningRateScheduler reducing learning rate to 0.0004677351412871982.
Epoch 577/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1433 - lr: 4.6774e-04

Epoch 00578: LearningRateScheduler reducing learning rate to 0.00046572011925969406.
Epoch 578/4000
24/24 - 3s - loss: 0.0726 - val_loss: 0.1422 - lr: 4.6572e-04

Epoch 00579: LearningRateScheduler reducing learning rate to 0.0004637137780291045.
Epoch 579/4000
24/24 - 3s - loss: 0.0724 - val_loss: 0.1429 - lr: 4.6371e-04

Epoch 00580: LearningRateScheduler reducing learning rate to 0.00046171608019820315.
Epoch 580/4000
24/24 - 3s - loss: 0.0728 - val_loss: 0.1470 - lr: 4.6172e-04

Epoch 00581: LearningRateScheduler reducing learning rate to 0.00045972698853087216.
Epoch 581/4000
24/24 - 3s - loss: 0.0718 - val_loss: 0.1410 - lr: 4.5973e-04

Epoch 00582: LearningRateScheduler reducing learning rate to 0.0004577464659514087.
Epoch 582/4000
24/24 - 3s - loss: 0.0729 - val_loss: 0.1417 - lr: 4.5775e-04

Epoch 00583: LearningRateScheduler reducing learning rate to 0.00045577447554383336.
Epoch 583/4000
24/24 - 3s - loss: 0.0727 - val_loss: 0.1428 - lr: 4.5577e-04

Epoch 00584: LearningRateScheduler reducing learning rate to 0.0004538109805512023.
Epoch 584/4000
24/24 - 3s - loss: 0.0728 - val_loss: 0.1443 - lr: 4.5381e-04

Epoch 00585: LearningRateScheduler reducing learning rate to 0.0004518559443749223.
Epoch 585/4000
24/24 - 3s - loss: 0.0727 - val_loss: 0.1406 - lr: 4.5186e-04

Epoch 00586: LearningRateScheduler reducing learning rate to 0.0004499093305740682.
Epoch 586/4000
24/24 - 3s - loss: 0.0718 - val_loss: 0.1412 - lr: 4.4991e-04

Epoch 00587: LearningRateScheduler reducing learning rate to 0.0004479711028647036.
Epoch 587/4000
24/24 - 3s - loss: 0.0717 - val_loss: 0.1459 - lr: 4.4797e-04

Epoch 00588: LearningRateScheduler reducing learning rate to 0.0004460412251192052.
Epoch 588/4000
24/24 - 3s - loss: 0.0726 - val_loss: 0.1459 - lr: 4.4604e-04

Epoch 00589: LearningRateScheduler reducing learning rate to 0.0004441196613655889.
Epoch 589/4000
24/24 - 3s - loss: 0.0728 - val_loss: 0.1439 - lr: 4.4412e-04

Epoch 00590: LearningRateScheduler reducing learning rate to 0.00044220637578683904.
Epoch 590/4000
24/24 - 3s - loss: 0.0716 - val_loss: 0.1411 - lr: 4.4221e-04

Epoch 00591: LearningRateScheduler reducing learning rate to 0.0004403013327202414.
Epoch 591/4000
24/24 - 3s - loss: 0.0727 - val_loss: 0.1520 - lr: 4.4030e-04

Epoch 00592: LearningRateScheduler reducing learning rate to 0.0004384044966567182.
Epoch 592/4000
24/24 - 3s - loss: 0.0715 - val_loss: 0.1516 - lr: 4.3840e-04

Epoch 00593: LearningRateScheduler reducing learning rate to 0.00043651583224016595.
Epoch 593/4000
24/24 - 3s - loss: 0.0732 - val_loss: 0.1447 - lr: 4.3652e-04

Epoch 00594: LearningRateScheduler reducing learning rate to 0.00043463530426679704.
Epoch 594/4000
24/24 - 3s - loss: 0.0714 - val_loss: 0.1391 - lr: 4.3464e-04

Epoch 00595: LearningRateScheduler reducing learning rate to 0.00043276287768448304.
Epoch 595/4000
24/24 - 3s - loss: 0.0714 - val_loss: 0.1468 - lr: 4.3276e-04

Epoch 00596: LearningRateScheduler reducing learning rate to 0.0004308985175921015.
Epoch 596/4000
24/24 - 3s - loss: 0.0722 - val_loss: 0.1398 - lr: 4.3090e-04

Epoch 00597: LearningRateScheduler reducing learning rate to 0.00042904218923888544.
Epoch 597/4000
24/24 - 3s - loss: 0.0716 - val_loss: 0.1534 - lr: 4.2904e-04

Epoch 00598: LearningRateScheduler reducing learning rate to 0.0004271938580237756.
Epoch 598/4000
24/24 - 3s - loss: 0.0722 - val_loss: 0.1518 - lr: 4.2719e-04

Epoch 00599: LearningRateScheduler reducing learning rate to 0.0004253534894947755.
Epoch 599/4000
24/24 - 3s - loss: 0.0723 - val_loss: 0.1429 - lr: 4.2535e-04

Epoch 00600: LearningRateScheduler reducing learning rate to 0.00042352104934830924.
Epoch 600/4000
Model saved in ./model/scPDB_1221_pdbid--600--0.1507--0.0004235.
24/24 - 3s - loss: 0.0717 - val_loss: 0.1507 - lr: 4.2352e-04

Epoch 00601: LearningRateScheduler reducing learning rate to 0.00042169650342858224.
Epoch 601/4000
24/24 - 3s - loss: 0.0710 - val_loss: 0.1500 - lr: 4.2170e-04

Epoch 00602: LearningRateScheduler reducing learning rate to 0.00041987981772694427.
Epoch 602/4000
24/24 - 3s - loss: 0.0721 - val_loss: 0.1474 - lr: 4.1988e-04

Epoch 00603: LearningRateScheduler reducing learning rate to 0.00041807095838125596.
Epoch 603/4000
24/24 - 3s - loss: 0.0718 - val_loss: 0.1442 - lr: 4.1807e-04

Epoch 00604: LearningRateScheduler reducing learning rate to 0.00041626989167525727.
Epoch 604/4000
24/24 - 3s - loss: 0.0714 - val_loss: 0.1502 - lr: 4.1627e-04

Epoch 00605: LearningRateScheduler reducing learning rate to 0.00041447658403793915.
Epoch 605/4000
24/24 - 3s - loss: 0.0715 - val_loss: 0.1468 - lr: 4.1448e-04

Epoch 00606: LearningRateScheduler reducing learning rate to 0.00041269100204291794.
Epoch 606/4000
24/24 - 3s - loss: 0.0719 - val_loss: 0.1493 - lr: 4.1269e-04

Epoch 00607: LearningRateScheduler reducing learning rate to 0.0004109131124078122.
Epoch 607/4000
24/24 - 3s - loss: 0.0713 - val_loss: 0.1423 - lr: 4.1091e-04

Epoch 00608: LearningRateScheduler reducing learning rate to 0.00040914288199362227.
Epoch 608/4000
24/24 - 3s - loss: 0.0716 - val_loss: 0.1475 - lr: 4.0914e-04

Epoch 00609: LearningRateScheduler reducing learning rate to 0.00040738027780411277.
Epoch 609/4000
24/24 - 3s - loss: 0.0715 - val_loss: 0.1470 - lr: 4.0738e-04

Epoch 00610: LearningRateScheduler reducing learning rate to 0.00040562526698519714.
Epoch 610/4000
24/24 - 3s - loss: 0.0709 - val_loss: 0.1480 - lr: 4.0563e-04

Epoch 00611: LearningRateScheduler reducing learning rate to 0.00040387781682432603.
Epoch 611/4000
24/24 - 3s - loss: 0.0716 - val_loss: 0.1461 - lr: 4.0388e-04

Epoch 00612: LearningRateScheduler reducing learning rate to 0.0004021378947498766.
Epoch 612/4000
24/24 - 3s - loss: 0.0717 - val_loss: 0.1524 - lr: 4.0214e-04

Epoch 00613: LearningRateScheduler reducing learning rate to 0.0004004054683305463.
Epoch 613/4000
24/24 - 3s - loss: 0.0715 - val_loss: 0.1479 - lr: 4.0041e-04

Epoch 00614: LearningRateScheduler reducing learning rate to 0.00039868050527474777.
Epoch 614/4000
24/24 - 3s - loss: 0.0708 - val_loss: 0.1499 - lr: 3.9868e-04

Epoch 00615: LearningRateScheduler reducing learning rate to 0.00039696297343000696.
Epoch 615/4000
24/24 - 3s - loss: 0.0717 - val_loss: 0.1522 - lr: 3.9696e-04

Epoch 00616: LearningRateScheduler reducing learning rate to 0.00039525284078236427.
Epoch 616/4000
24/24 - 3s - loss: 0.0706 - val_loss: 0.1468 - lr: 3.9525e-04

Epoch 00617: LearningRateScheduler reducing learning rate to 0.0003935500754557775.
Epoch 617/4000
24/24 - 3s - loss: 0.0708 - val_loss: 0.1459 - lr: 3.9355e-04

Epoch 00618: LearningRateScheduler reducing learning rate to 0.0003918546457115274.
Epoch 618/4000
24/24 - 3s - loss: 0.0714 - val_loss: 0.1480 - lr: 3.9185e-04

Epoch 00619: LearningRateScheduler reducing learning rate to 0.00039016651994762695.
Epoch 619/4000
24/24 - 3s - loss: 0.0713 - val_loss: 0.1517 - lr: 3.9017e-04

Epoch 00620: LearningRateScheduler reducing learning rate to 0.0003884856666982314.
Epoch 620/4000
24/24 - 3s - loss: 0.0711 - val_loss: 0.1481 - lr: 3.8849e-04

Epoch 00621: LearningRateScheduler reducing learning rate to 0.00038681205463305215.
Epoch 621/4000
24/24 - 3s - loss: 0.0703 - val_loss: 0.1509 - lr: 3.8681e-04

Epoch 00622: LearningRateScheduler reducing learning rate to 0.000385145652556773.
Epoch 622/4000
24/24 - 3s - loss: 0.0710 - val_loss: 0.1468 - lr: 3.8515e-04

Epoch 00623: LearningRateScheduler reducing learning rate to 0.0003834864294084682.
Epoch 623/4000
24/24 - 3s - loss: 0.0709 - val_loss: 0.1478 - lr: 3.8349e-04

Epoch 00624: LearningRateScheduler reducing learning rate to 0.00038183435426102373.
Epoch 624/4000
24/24 - 3s - loss: 0.0705 - val_loss: 0.1496 - lr: 3.8183e-04

Epoch 00625: LearningRateScheduler reducing learning rate to 0.00038018939632056113.
Epoch 625/4000
24/24 - 3s - loss: 0.0704 - val_loss: 0.1507 - lr: 3.8019e-04

Epoch 00626: LearningRateScheduler reducing learning rate to 0.00037855152492586295.
Epoch 626/4000
24/24 - 3s - loss: 0.0704 - val_loss: 0.1396 - lr: 3.7855e-04

Epoch 00627: LearningRateScheduler reducing learning rate to 0.0003769207095478016.
Epoch 627/4000
24/24 - 3s - loss: 0.0712 - val_loss: 0.1458 - lr: 3.7692e-04

Epoch 00628: LearningRateScheduler reducing learning rate to 0.0003752969197887701.
Epoch 628/4000
24/24 - 3s - loss: 0.0699 - val_loss: 0.1493 - lr: 3.7530e-04

Epoch 00629: LearningRateScheduler reducing learning rate to 0.00037368012538211575.
Epoch 629/4000
24/24 - 3s - loss: 0.0711 - val_loss: 0.1427 - lr: 3.7368e-04

Epoch 00630: LearningRateScheduler reducing learning rate to 0.0003720702961915758.
Epoch 630/4000
24/24 - 3s - loss: 0.0710 - val_loss: 0.1552 - lr: 3.7207e-04

Epoch 00631: LearningRateScheduler reducing learning rate to 0.00037046740221071566.
Epoch 631/4000
24/24 - 3s - loss: 0.0701 - val_loss: 0.1439 - lr: 3.7047e-04

Epoch 00632: LearningRateScheduler reducing learning rate to 0.0003688714135623698.
Epoch 632/4000
24/24 - 3s - loss: 0.0696 - val_loss: 0.1563 - lr: 3.6887e-04

Epoch 00633: LearningRateScheduler reducing learning rate to 0.00036728230049808467.
Epoch 633/4000
24/24 - 3s - loss: 0.0713 - val_loss: 0.1484 - lr: 3.6728e-04

Epoch 00634: LearningRateScheduler reducing learning rate to 0.00036570003339756417.
Epoch 634/4000
24/24 - 3s - loss: 0.0704 - val_loss: 0.1433 - lr: 3.6570e-04

Epoch 00635: LearningRateScheduler reducing learning rate to 0.0003641245827681179.
Epoch 635/4000
24/24 - 3s - loss: 0.0708 - val_loss: 0.1551 - lr: 3.6412e-04

Epoch 00636: LearningRateScheduler reducing learning rate to 0.00036255591924411087.
Epoch 636/4000
24/24 - 3s - loss: 0.0696 - val_loss: 0.1485 - lr: 3.6256e-04

Epoch 00637: LearningRateScheduler reducing learning rate to 0.0003609940135864166.
Epoch 637/4000
24/24 - 3s - loss: 0.0712 - val_loss: 0.1452 - lr: 3.6099e-04

Epoch 00638: LearningRateScheduler reducing learning rate to 0.00035943883668187207.
Epoch 638/4000
24/24 - 3s - loss: 0.0706 - val_loss: 0.1495 - lr: 3.5944e-04

Epoch 00639: LearningRateScheduler reducing learning rate to 0.0003578903595427346.
Epoch 639/4000
24/24 - 3s - loss: 0.0703 - val_loss: 0.1533 - lr: 3.5789e-04

Epoch 00640: LearningRateScheduler reducing learning rate to 0.0003563485533061423.
Epoch 640/4000
24/24 - 3s - loss: 0.0687 - val_loss: 0.1495 - lr: 3.5635e-04

Epoch 00641: LearningRateScheduler reducing learning rate to 0.00035481338923357543.
Epoch 641/4000
24/24 - 3s - loss: 0.0710 - val_loss: 0.1454 - lr: 3.5481e-04

Epoch 00642: LearningRateScheduler reducing learning rate to 0.00035328483871032096.
Epoch 642/4000
24/24 - 3s - loss: 0.0700 - val_loss: 0.1471 - lr: 3.5328e-04

Epoch 00643: LearningRateScheduler reducing learning rate to 0.0003517628732449393.
Epoch 643/4000
24/24 - 3s - loss: 0.0705 - val_loss: 0.1582 - lr: 3.5176e-04

Epoch 00644: LearningRateScheduler reducing learning rate to 0.00035024746446873304.
Epoch 644/4000
24/24 - 3s - loss: 0.0700 - val_loss: 0.1430 - lr: 3.5025e-04

Epoch 00645: LearningRateScheduler reducing learning rate to 0.00034873858413521835.
Epoch 645/4000
24/24 - 3s - loss: 0.0700 - val_loss: 0.1532 - lr: 3.4874e-04

Epoch 00646: LearningRateScheduler reducing learning rate to 0.00034723620411959846.
Epoch 646/4000
24/24 - 3s - loss: 0.0699 - val_loss: 0.1455 - lr: 3.4724e-04

Epoch 00647: LearningRateScheduler reducing learning rate to 0.0003457402964182391.
Epoch 647/4000
24/24 - 3s - loss: 0.0697 - val_loss: 0.1505 - lr: 3.4574e-04

Epoch 00648: LearningRateScheduler reducing learning rate to 0.0003442508331481472.
Epoch 648/4000
24/24 - 3s - loss: 0.0705 - val_loss: 0.1515 - lr: 3.4425e-04

Epoch 00649: LearningRateScheduler reducing learning rate to 0.0003427677865464504.
Epoch 649/4000
24/24 - 3s - loss: 0.0699 - val_loss: 0.1538 - lr: 3.4277e-04

Epoch 00650: LearningRateScheduler reducing learning rate to 0.00034129112896988005.
Epoch 650/4000
Model saved in ./model/scPDB_1221_pdbid--650--0.1535--0.0003413.
24/24 - 3s - loss: 0.0696 - val_loss: 0.1535 - lr: 3.4129e-04

Epoch 00651: LearningRateScheduler reducing learning rate to 0.00033982083289425585.
Epoch 651/4000
24/24 - 3s - loss: 0.0699 - val_loss: 0.1539 - lr: 3.3982e-04

Epoch 00652: LearningRateScheduler reducing learning rate to 0.00033835687091397294.
Epoch 652/4000
24/24 - 3s - loss: 0.0693 - val_loss: 0.1554 - lr: 3.3836e-04

Epoch 00653: LearningRateScheduler reducing learning rate to 0.0003368992157414907.
Epoch 653/4000
24/24 - 3s - loss: 0.0702 - val_loss: 0.1508 - lr: 3.3690e-04

Epoch 00654: LearningRateScheduler reducing learning rate to 0.0003354478402068243.
Epoch 654/4000
24/24 - 3s - loss: 0.0694 - val_loss: 0.1412 - lr: 3.3545e-04

Epoch 00655: LearningRateScheduler reducing learning rate to 0.0003340027172570385.
Epoch 655/4000
24/24 - 3s - loss: 0.0695 - val_loss: 0.1508 - lr: 3.3400e-04

Epoch 00656: LearningRateScheduler reducing learning rate to 0.00033256381995574314.
Epoch 656/4000
24/24 - 3s - loss: 0.0703 - val_loss: 0.1524 - lr: 3.3256e-04

Epoch 00657: LearningRateScheduler reducing learning rate to 0.00033113112148259105.
Epoch 657/4000
24/24 - 3s - loss: 0.0703 - val_loss: 0.1551 - lr: 3.3113e-04

Epoch 00658: LearningRateScheduler reducing learning rate to 0.00032970459513277834.
Epoch 658/4000
24/24 - 3s - loss: 0.0688 - val_loss: 0.1520 - lr: 3.2970e-04

Epoch 00659: LearningRateScheduler reducing learning rate to 0.0003282842143165464.
Epoch 659/4000
24/24 - 3s - loss: 0.0694 - val_loss: 0.1527 - lr: 3.2828e-04

Epoch 00660: LearningRateScheduler reducing learning rate to 0.0003268699525586865.
Epoch 660/4000
24/24 - 3s - loss: 0.0700 - val_loss: 0.1516 - lr: 3.2687e-04

Epoch 00661: LearningRateScheduler reducing learning rate to 0.0003254617834980459.
Epoch 661/4000
24/24 - 3s - loss: 0.0692 - val_loss: 0.1493 - lr: 3.2546e-04

Epoch 00662: LearningRateScheduler reducing learning rate to 0.00032405968088703715.
Epoch 662/4000
24/24 - 3s - loss: 0.0697 - val_loss: 0.1489 - lr: 3.2406e-04

Epoch 00663: LearningRateScheduler reducing learning rate to 0.0003226636185911482.
Epoch 663/4000
24/24 - 3s - loss: 0.0704 - val_loss: 0.1481 - lr: 3.2266e-04

Epoch 00664: LearningRateScheduler reducing learning rate to 0.0003212735705884557.
Epoch 664/4000
24/24 - 3s - loss: 0.0692 - val_loss: 0.1532 - lr: 3.2127e-04

Epoch 00665: LearningRateScheduler reducing learning rate to 0.0003198895109691398.
Epoch 665/4000
24/24 - 3s - loss: 0.0691 - val_loss: 0.1572 - lr: 3.1989e-04

Epoch 00666: LearningRateScheduler reducing learning rate to 0.000318511413935001.
Epoch 666/4000
24/24 - 3s - loss: 0.0696 - val_loss: 0.1412 - lr: 3.1851e-04

Epoch 00667: LearningRateScheduler reducing learning rate to 0.00031713925379897996.
Epoch 667/4000
24/24 - 3s - loss: 0.0696 - val_loss: 0.1509 - lr: 3.1714e-04

Epoch 00668: LearningRateScheduler reducing learning rate to 0.0003157730049846776.
Epoch 668/4000
24/24 - 3s - loss: 0.0689 - val_loss: 0.1563 - lr: 3.1577e-04

Epoch 00669: LearningRateScheduler reducing learning rate to 0.00031441264202587953.
Epoch 669/4000
24/24 - 3s - loss: 0.0688 - val_loss: 0.1468 - lr: 3.1441e-04

Epoch 00670: LearningRateScheduler reducing learning rate to 0.0003130581395660806.
Epoch 670/4000
24/24 - 3s - loss: 0.0702 - val_loss: 0.1500 - lr: 3.1306e-04

Epoch 00671: LearningRateScheduler reducing learning rate to 0.00031170947235801253.
Epoch 671/4000
24/24 - 3s - loss: 0.0682 - val_loss: 0.1510 - lr: 3.1171e-04

Epoch 00672: LearningRateScheduler reducing learning rate to 0.0003103666152631735.
Epoch 672/4000
24/24 - 3s - loss: 0.0697 - val_loss: 0.1566 - lr: 3.1037e-04

Epoch 00673: LearningRateScheduler reducing learning rate to 0.00030902954325135904.
Epoch 673/4000
24/24 - 3s - loss: 0.0696 - val_loss: 0.1516 - lr: 3.0903e-04

Epoch 00674: LearningRateScheduler reducing learning rate to 0.0003076982314001961.
Epoch 674/4000
24/24 - 3s - loss: 0.0686 - val_loss: 0.1440 - lr: 3.0770e-04

Epoch 00675: LearningRateScheduler reducing learning rate to 0.00030637265489467816.
Epoch 675/4000
24/24 - 3s - loss: 0.0691 - val_loss: 0.1528 - lr: 3.0637e-04

Epoch 00676: LearningRateScheduler reducing learning rate to 0.00030505278902670253.
Epoch 676/4000
24/24 - 3s - loss: 0.0686 - val_loss: 0.1545 - lr: 3.0505e-04

Epoch 00677: LearningRateScheduler reducing learning rate to 0.00030373860919461046.
Epoch 677/4000
24/24 - 3s - loss: 0.0691 - val_loss: 0.1596 - lr: 3.0374e-04

Epoch 00678: LearningRateScheduler reducing learning rate to 0.00030243009090272785.
Epoch 678/4000
24/24 - 3s - loss: 0.0687 - val_loss: 0.1506 - lr: 3.0243e-04

Epoch 00679: LearningRateScheduler reducing learning rate to 0.00030112720976090894.
Epoch 679/4000
24/24 - 3s - loss: 0.0684 - val_loss: 0.1473 - lr: 3.0113e-04

Epoch 00680: LearningRateScheduler reducing learning rate to 0.00029982994148408193.
Epoch 680/4000
24/24 - 3s - loss: 0.0697 - val_loss: 0.1546 - lr: 2.9983e-04

Epoch 00681: LearningRateScheduler reducing learning rate to 0.00029853826189179595.
Epoch 681/4000
24/24 - 3s - loss: 0.0683 - val_loss: 0.1466 - lr: 2.9854e-04

Epoch 00682: LearningRateScheduler reducing learning rate to 0.0002972521469077704.
Epoch 682/4000
24/24 - 3s - loss: 0.0693 - val_loss: 0.1597 - lr: 2.9725e-04

Epoch 00683: LearningRateScheduler reducing learning rate to 0.0002959715725594465.
Epoch 683/4000
24/24 - 3s - loss: 0.0685 - val_loss: 0.1474 - lr: 2.9597e-04

Epoch 00684: LearningRateScheduler reducing learning rate to 0.0002946965149775401.
Epoch 684/4000
24/24 - 3s - loss: 0.0685 - val_loss: 0.1513 - lr: 2.9470e-04

Epoch 00685: LearningRateScheduler reducing learning rate to 0.00029342695039559686.
Epoch 685/4000
24/24 - 3s - loss: 0.0691 - val_loss: 0.1573 - lr: 2.9343e-04

Epoch 00686: LearningRateScheduler reducing learning rate to 0.0002921628551495494.
Epoch 686/4000
24/24 - 3s - loss: 0.0686 - val_loss: 0.1497 - lr: 2.9216e-04

Epoch 00687: LearningRateScheduler reducing learning rate to 0.000290904205677276.
Epoch 687/4000
24/24 - 3s - loss: 0.0692 - val_loss: 0.1473 - lr: 2.9090e-04

Epoch 00688: LearningRateScheduler reducing learning rate to 0.0002896509785181617.
Epoch 688/4000
24/24 - 3s - loss: 0.0685 - val_loss: 0.1575 - lr: 2.8965e-04

Epoch 00689: LearningRateScheduler reducing learning rate to 0.00028840315031266055.
Epoch 689/4000
24/24 - 3s - loss: 0.0688 - val_loss: 0.1530 - lr: 2.8840e-04

Epoch 00690: LearningRateScheduler reducing learning rate to 0.00028716069780186074.
Epoch 690/4000
24/24 - 3s - loss: 0.0690 - val_loss: 0.1507 - lr: 2.8716e-04

Epoch 00691: LearningRateScheduler reducing learning rate to 0.0002859235978270506.
Epoch 691/4000
24/24 - 3s - loss: 0.0679 - val_loss: 0.1524 - lr: 2.8592e-04

Epoch 00692: LearningRateScheduler reducing learning rate to 0.0002846918273292873.
Epoch 692/4000
24/24 - 3s - loss: 0.0694 - val_loss: 0.1517 - lr: 2.8469e-04

Epoch 00693: LearningRateScheduler reducing learning rate to 0.00028346536334896674.
Epoch 693/4000
24/24 - 3s - loss: 0.0689 - val_loss: 0.1529 - lr: 2.8347e-04

Epoch 00694: LearningRateScheduler reducing learning rate to 0.00028224418302539575.
Epoch 694/4000
24/24 - 3s - loss: 0.0686 - val_loss: 0.1459 - lr: 2.8224e-04

Epoch 00695: LearningRateScheduler reducing learning rate to 0.000281028263596366.
Epoch 695/4000
24/24 - 3s - loss: 0.0682 - val_loss: 0.1567 - lr: 2.8103e-04

Epoch 00696: LearningRateScheduler reducing learning rate to 0.0002798175823977296.
Epoch 696/4000
24/24 - 3s - loss: 0.0681 - val_loss: 0.1583 - lr: 2.7982e-04

Epoch 00697: LearningRateScheduler reducing learning rate to 0.00027861211686297705.
Epoch 697/4000
24/24 - 3s - loss: 0.0682 - val_loss: 0.1536 - lr: 2.7861e-04

Epoch 00698: LearningRateScheduler reducing learning rate to 0.00027741184452281575.
Epoch 698/4000
24/24 - 3s - loss: 0.0689 - val_loss: 0.1559 - lr: 2.7741e-04

Epoch 00699: LearningRateScheduler reducing learning rate to 0.0002762167430047522.
Epoch 699/4000
24/24 - 3s - loss: 0.0676 - val_loss: 0.1560 - lr: 2.7622e-04

Epoch 00700: LearningRateScheduler reducing learning rate to 0.0002750267900326741.
Epoch 700/4000
Model saved in ./model/scPDB_1221_pdbid--700--0.1560--0.0002750.
24/24 - 3s - loss: 0.0691 - val_loss: 0.1560 - lr: 2.7503e-04

Epoch 00701: LearningRateScheduler reducing learning rate to 0.0002738419634264361.
Epoch 701/4000
24/24 - 3s - loss: 0.0682 - val_loss: 0.1525 - lr: 2.7384e-04

Epoch 00702: LearningRateScheduler reducing learning rate to 0.0002726622411014453.
Epoch 702/4000
24/24 - 3s - loss: 0.0689 - val_loss: 0.1552 - lr: 2.7266e-04

Epoch 00703: LearningRateScheduler reducing learning rate to 0.00027148760106825035.
Epoch 703/4000
24/24 - 3s - loss: 0.0684 - val_loss: 0.1535 - lr: 2.7149e-04

Epoch 00704: LearningRateScheduler reducing learning rate to 0.00027031802143213127.
Epoch 704/4000
24/24 - 3s - loss: 0.0683 - val_loss: 0.1540 - lr: 2.7032e-04

Epoch 00705: LearningRateScheduler reducing learning rate to 0.00026915348039269156.
Epoch 705/4000
24/24 - 3s - loss: 0.0679 - val_loss: 0.1497 - lr: 2.6915e-04

Epoch 00706: LearningRateScheduler reducing learning rate to 0.00026799395624345156.
Epoch 706/4000
24/24 - 3s - loss: 0.0677 - val_loss: 0.1516 - lr: 2.6799e-04

Epoch 00707: LearningRateScheduler reducing learning rate to 0.0002668394273714442.
Epoch 707/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1562 - lr: 2.6684e-04

Epoch 00708: LearningRateScheduler reducing learning rate to 0.00026568987225681175.
Epoch 708/4000
24/24 - 3s - loss: 0.0680 - val_loss: 0.1580 - lr: 2.6569e-04

Epoch 00709: LearningRateScheduler reducing learning rate to 0.00026454526947240493.
Epoch 709/4000
24/24 - 3s - loss: 0.0685 - val_loss: 0.1541 - lr: 2.6455e-04

Epoch 00710: LearningRateScheduler reducing learning rate to 0.00026340559768338366.
Epoch 710/4000
24/24 - 3s - loss: 0.0684 - val_loss: 0.1459 - lr: 2.6341e-04

Epoch 00711: LearningRateScheduler reducing learning rate to 0.00026227083564681904.
Epoch 711/4000
24/24 - 3s - loss: 0.0680 - val_loss: 0.1581 - lr: 2.6227e-04

Epoch 00712: LearningRateScheduler reducing learning rate to 0.00026114096221129755.
Epoch 712/4000
24/24 - 3s - loss: 0.0680 - val_loss: 0.1558 - lr: 2.6114e-04

Epoch 00713: LearningRateScheduler reducing learning rate to 0.00026001595631652716.
Epoch 713/4000
24/24 - 3s - loss: 0.0675 - val_loss: 0.1553 - lr: 2.6002e-04

Epoch 00714: LearningRateScheduler reducing learning rate to 0.00025889579699294395.
Epoch 714/4000
24/24 - 3s - loss: 0.0684 - val_loss: 0.1530 - lr: 2.5890e-04

Epoch 00715: LearningRateScheduler reducing learning rate to 0.0002577804633613221.
Epoch 715/4000
24/24 - 3s - loss: 0.0676 - val_loss: 0.1581 - lr: 2.5778e-04

Epoch 00716: LearningRateScheduler reducing learning rate to 0.0002566699346323842.
Epoch 716/4000
24/24 - 3s - loss: 0.0681 - val_loss: 0.1486 - lr: 2.5667e-04

Epoch 00717: LearningRateScheduler reducing learning rate to 0.0002555641901064138.
Epoch 717/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1538 - lr: 2.5556e-04

Epoch 00718: LearningRateScheduler reducing learning rate to 0.0002544632091728699.
Epoch 718/4000
24/24 - 3s - loss: 0.0681 - val_loss: 0.1502 - lr: 2.5446e-04

Epoch 00719: LearningRateScheduler reducing learning rate to 0.0002533669713100024.
Epoch 719/4000
24/24 - 3s - loss: 0.0679 - val_loss: 0.1618 - lr: 2.5337e-04

Epoch 00720: LearningRateScheduler reducing learning rate to 0.0002522754560844697.
Epoch 720/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1518 - lr: 2.5228e-04

Epoch 00721: LearningRateScheduler reducing learning rate to 0.000251188643150958.
Epoch 721/4000
24/24 - 3s - loss: 0.0686 - val_loss: 0.1522 - lr: 2.5119e-04

Epoch 00722: LearningRateScheduler reducing learning rate to 0.00025010651225180184.
Epoch 722/4000
24/24 - 3s - loss: 0.0682 - val_loss: 0.1542 - lr: 2.5011e-04

Epoch 00723: LearningRateScheduler reducing learning rate to 0.0002490290432166067.
Epoch 723/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1555 - lr: 2.4903e-04

Epoch 00724: LearningRateScheduler reducing learning rate to 0.0002479562159618727.
Epoch 724/4000
24/24 - 3s - loss: 0.0672 - val_loss: 0.1521 - lr: 2.4796e-04

Epoch 00725: LearningRateScheduler reducing learning rate to 0.0002468880104906208.
Epoch 725/4000
24/24 - 3s - loss: 0.0681 - val_loss: 0.1473 - lr: 2.4689e-04

Epoch 00726: LearningRateScheduler reducing learning rate to 0.0002458244068920197.
Epoch 726/4000
24/24 - 3s - loss: 0.0675 - val_loss: 0.1566 - lr: 2.4582e-04

Epoch 00727: LearningRateScheduler reducing learning rate to 0.0002447653853410146.
Epoch 727/4000
24/24 - 3s - loss: 0.0674 - val_loss: 0.1485 - lr: 2.4477e-04

Epoch 00728: LearningRateScheduler reducing learning rate to 0.00024371092609795801.
Epoch 728/4000
24/24 - 3s - loss: 0.0674 - val_loss: 0.1533 - lr: 2.4371e-04

Epoch 00729: LearningRateScheduler reducing learning rate to 0.00024266100950824152.
Epoch 729/4000
24/24 - 3s - loss: 0.0680 - val_loss: 0.1568 - lr: 2.4266e-04

Epoch 00730: LearningRateScheduler reducing learning rate to 0.00024161561600192968.
Epoch 730/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1552 - lr: 2.4162e-04

Epoch 00731: LearningRateScheduler reducing learning rate to 0.00024057472609339506.
Epoch 731/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1560 - lr: 2.4057e-04

Epoch 00732: LearningRateScheduler reducing learning rate to 0.0002395383203809551.
Epoch 732/4000
24/24 - 3s - loss: 0.0677 - val_loss: 0.1569 - lr: 2.3954e-04

Epoch 00733: LearningRateScheduler reducing learning rate to 0.00023850637954651055.
Epoch 733/4000
24/24 - 3s - loss: 0.0677 - val_loss: 0.1603 - lr: 2.3851e-04

Epoch 00734: LearningRateScheduler reducing learning rate to 0.0002374788843551852.
Epoch 734/4000
24/24 - 3s - loss: 0.0674 - val_loss: 0.1614 - lr: 2.3748e-04

Epoch 00735: LearningRateScheduler reducing learning rate to 0.00023645581565496758.
Epoch 735/4000
24/24 - 3s - loss: 0.0677 - val_loss: 0.1546 - lr: 2.3646e-04

Epoch 00736: LearningRateScheduler reducing learning rate to 0.0002354371543763538.
Epoch 736/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1529 - lr: 2.3544e-04

Epoch 00737: LearningRateScheduler reducing learning rate to 0.00023442288153199218.
Epoch 737/4000
24/24 - 3s - loss: 0.0677 - val_loss: 0.1595 - lr: 2.3442e-04

Epoch 00738: LearningRateScheduler reducing learning rate to 0.00023341297821632937.
Epoch 738/4000
24/24 - 3s - loss: 0.0673 - val_loss: 0.1485 - lr: 2.3341e-04

Epoch 00739: LearningRateScheduler reducing learning rate to 0.00023240742560525786.
Epoch 739/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1544 - lr: 2.3241e-04

Epoch 00740: LearningRateScheduler reducing learning rate to 0.0002314062049557652.
Epoch 740/4000
24/24 - 3s - loss: 0.0674 - val_loss: 0.1534 - lr: 2.3141e-04

Epoch 00741: LearningRateScheduler reducing learning rate to 0.00023040929760558454.
Epoch 741/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1587 - lr: 2.3041e-04

Epoch 00742: LearningRateScheduler reducing learning rate to 0.0002294166849728469.
Epoch 742/4000
24/24 - 3s - loss: 0.0675 - val_loss: 0.1584 - lr: 2.2942e-04

Epoch 00743: LearningRateScheduler reducing learning rate to 0.00022842834855573468.
Epoch 743/4000
24/24 - 3s - loss: 0.0672 - val_loss: 0.1564 - lr: 2.2843e-04

Epoch 00744: LearningRateScheduler reducing learning rate to 0.00022744426993213696.
Epoch 744/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1531 - lr: 2.2744e-04

Epoch 00745: LearningRateScheduler reducing learning rate to 0.00022646443075930594.
Epoch 745/4000
24/24 - 3s - loss: 0.0676 - val_loss: 0.1504 - lr: 2.2646e-04

Epoch 00746: LearningRateScheduler reducing learning rate to 0.0002254888127735152.
Epoch 746/4000
24/24 - 3s - loss: 0.0676 - val_loss: 0.1612 - lr: 2.2549e-04

Epoch 00747: LearningRateScheduler reducing learning rate to 0.00022451739778971906.
Epoch 747/4000
24/24 - 3s - loss: 0.0671 - val_loss: 0.1582 - lr: 2.2452e-04

Epoch 00748: LearningRateScheduler reducing learning rate to 0.00022355016770121393.
Epoch 748/4000
24/24 - 3s - loss: 0.0671 - val_loss: 0.1548 - lr: 2.2355e-04

Epoch 00749: LearningRateScheduler reducing learning rate to 0.00022258710447930043.
Epoch 749/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1570 - lr: 2.2259e-04

Epoch 00750: LearningRateScheduler reducing learning rate to 0.00022162819017294784.
Epoch 750/4000
Model saved in ./model/scPDB_1221_pdbid--750--0.1566--0.0002216.
24/24 - 3s - loss: 0.0673 - val_loss: 0.1566 - lr: 2.2163e-04

Epoch 00751: LearningRateScheduler reducing learning rate to 0.00022067340690845895.
Epoch 751/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1550 - lr: 2.2067e-04

Epoch 00752: LearningRateScheduler reducing learning rate to 0.00021972273688913727.
Epoch 752/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1555 - lr: 2.1972e-04

Epoch 00753: LearningRateScheduler reducing learning rate to 0.00021877616239495524.
Epoch 753/4000
24/24 - 3s - loss: 0.0678 - val_loss: 0.1577 - lr: 2.1878e-04

Epoch 00754: LearningRateScheduler reducing learning rate to 0.00021783366578222377.
Epoch 754/4000
24/24 - 3s - loss: 0.0674 - val_loss: 0.1606 - lr: 2.1783e-04

Epoch 00755: LearningRateScheduler reducing learning rate to 0.00021689522948326365.
Epoch 755/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1586 - lr: 2.1690e-04

Epoch 00756: LearningRateScheduler reducing learning rate to 0.00021596083600607785.
Epoch 756/4000
24/24 - 3s - loss: 0.0667 - val_loss: 0.1568 - lr: 2.1596e-04

Epoch 00757: LearningRateScheduler reducing learning rate to 0.00021503046793402565.
Epoch 757/4000
24/24 - 3s - loss: 0.0673 - val_loss: 0.1545 - lr: 2.1503e-04

Epoch 00758: LearningRateScheduler reducing learning rate to 0.0002141041079254978.
Epoch 758/4000
24/24 - 3s - loss: 0.0664 - val_loss: 0.1562 - lr: 2.1410e-04

Epoch 00759: LearningRateScheduler reducing learning rate to 0.00021318173871359355.
Epoch 759/4000
24/24 - 3s - loss: 0.0673 - val_loss: 0.1573 - lr: 2.1318e-04

Epoch 00760: LearningRateScheduler reducing learning rate to 0.0002122633431057986.
Epoch 760/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1605 - lr: 2.1226e-04

Epoch 00761: LearningRateScheduler reducing learning rate to 0.00021134890398366463.
Epoch 761/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1471 - lr: 2.1135e-04

Epoch 00762: LearningRateScheduler reducing learning rate to 0.00021043840430249051.
Epoch 762/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1602 - lr: 2.1044e-04

Epoch 00763: LearningRateScheduler reducing learning rate to 0.00020953182709100413.
Epoch 763/4000
24/24 - 3s - loss: 0.0665 - val_loss: 0.1633 - lr: 2.0953e-04

Epoch 00764: LearningRateScheduler reducing learning rate to 0.00020862915545104643.
Epoch 764/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1448 - lr: 2.0863e-04

Epoch 00765: LearningRateScheduler reducing learning rate to 0.00020773037255725633.
Epoch 765/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1642 - lr: 2.0773e-04

Epoch 00766: LearningRateScheduler reducing learning rate to 0.000206835461656757.
Epoch 766/4000
24/24 - 3s - loss: 0.0667 - val_loss: 0.1559 - lr: 2.0684e-04

Epoch 00767: LearningRateScheduler reducing learning rate to 0.00020594440606884376.
Epoch 767/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1608 - lr: 2.0594e-04

Epoch 00768: LearningRateScheduler reducing learning rate to 0.00020505718918467305.
Epoch 768/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1544 - lr: 2.0506e-04

Epoch 00769: LearningRateScheduler reducing learning rate to 0.00020417379446695293.
Epoch 769/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1577 - lr: 2.0417e-04

Epoch 00770: LearningRateScheduler reducing learning rate to 0.0002032942054496347.
Epoch 770/4000
24/24 - 3s - loss: 0.0671 - val_loss: 0.1673 - lr: 2.0329e-04

Epoch 00771: LearningRateScheduler reducing learning rate to 0.00020241840573760614.
Epoch 771/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1565 - lr: 2.0242e-04

Epoch 00772: LearningRateScheduler reducing learning rate to 0.00020154637900638586.
Epoch 772/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1584 - lr: 2.0155e-04

Epoch 00773: LearningRateScheduler reducing learning rate to 0.0002006781090018189.
Epoch 773/4000
24/24 - 3s - loss: 0.0664 - val_loss: 0.1588 - lr: 2.0068e-04

Epoch 00774: LearningRateScheduler reducing learning rate to 0.0001998135795397739.
Epoch 774/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1554 - lr: 1.9981e-04

Epoch 00775: LearningRateScheduler reducing learning rate to 0.00019895277450584156.
Epoch 775/4000
24/24 - 3s - loss: 0.0664 - val_loss: 0.1518 - lr: 1.9895e-04

Epoch 00776: LearningRateScheduler reducing learning rate to 0.00019809567785503384.
Epoch 776/4000
24/24 - 3s - loss: 0.0670 - val_loss: 0.1676 - lr: 1.9810e-04

Epoch 00777: LearningRateScheduler reducing learning rate to 0.00019724227361148536.
Epoch 777/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1578 - lr: 1.9724e-04

Epoch 00778: LearningRateScheduler reducing learning rate to 0.0001963925458681553.
Epoch 778/4000
24/24 - 3s - loss: 0.0669 - val_loss: 0.1589 - lr: 1.9639e-04

Epoch 00779: LearningRateScheduler reducing learning rate to 0.0001955464787865311.
Epoch 779/4000
24/24 - 3s - loss: 0.0661 - val_loss: 0.1503 - lr: 1.9555e-04

Epoch 00780: LearningRateScheduler reducing learning rate to 0.00019470405659633311.
Epoch 780/4000
24/24 - 3s - loss: 0.0671 - val_loss: 0.1590 - lr: 1.9470e-04

Epoch 00781: LearningRateScheduler reducing learning rate to 0.00019386526359522073.
Epoch 781/4000
24/24 - 3s - loss: 0.0664 - val_loss: 0.1661 - lr: 1.9387e-04

Epoch 00782: LearningRateScheduler reducing learning rate to 0.00019303008414849962.
Epoch 782/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1463 - lr: 1.9303e-04

Epoch 00783: LearningRateScheduler reducing learning rate to 0.0001921985026888304.
Epoch 783/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1666 - lr: 1.9220e-04

Epoch 00784: LearningRateScheduler reducing learning rate to 0.0001913705037159384.
Epoch 784/4000
24/24 - 3s - loss: 0.0673 - val_loss: 0.1601 - lr: 1.9137e-04

Epoch 00785: LearningRateScheduler reducing learning rate to 0.00019054607179632468.
Epoch 785/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1574 - lr: 1.9055e-04

Epoch 00786: LearningRateScheduler reducing learning rate to 0.00018972519156297866.
Epoch 786/4000
24/24 - 3s - loss: 0.0665 - val_loss: 0.1608 - lr: 1.8973e-04

Epoch 00787: LearningRateScheduler reducing learning rate to 0.00018890784771509125.
Epoch 787/4000
24/24 - 3s - loss: 0.0666 - val_loss: 0.1544 - lr: 1.8891e-04

Epoch 00788: LearningRateScheduler reducing learning rate to 0.00018809402501776995.
Epoch 788/4000
24/24 - 3s - loss: 0.0663 - val_loss: 0.1639 - lr: 1.8809e-04

Epoch 00789: LearningRateScheduler reducing learning rate to 0.00018728370830175484.
Epoch 789/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1585 - lr: 1.8728e-04

Epoch 00790: LearningRateScheduler reducing learning rate to 0.0001864768824631357.
Epoch 790/4000
24/24 - 3s - loss: 0.0664 - val_loss: 0.1530 - lr: 1.8648e-04

Epoch 00791: LearningRateScheduler reducing learning rate to 0.0001856735324630706.
Epoch 791/4000
24/24 - 3s - loss: 0.0666 - val_loss: 0.1617 - lr: 1.8567e-04

Epoch 00792: LearningRateScheduler reducing learning rate to 0.0001848736433275056.
Epoch 792/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1580 - lr: 1.8487e-04

Epoch 00793: LearningRateScheduler reducing learning rate to 0.00018407720014689558.
Epoch 793/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1563 - lr: 1.8408e-04

Epoch 00794: LearningRateScheduler reducing learning rate to 0.00018328418807592628.
Epoch 794/4000
24/24 - 3s - loss: 0.0665 - val_loss: 0.1709 - lr: 1.8328e-04

Epoch 00795: LearningRateScheduler reducing learning rate to 0.00018249459233323772.
Epoch 795/4000
24/24 - 3s - loss: 0.0667 - val_loss: 0.1576 - lr: 1.8249e-04

Epoch 00796: LearningRateScheduler reducing learning rate to 0.00018170839820114864.
Epoch 796/4000
24/24 - 3s - loss: 0.0663 - val_loss: 0.1600 - lr: 1.8171e-04

Epoch 00797: LearningRateScheduler reducing learning rate to 0.00018092559102538208.
Epoch 797/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1640 - lr: 1.8093e-04

Epoch 00798: LearningRateScheduler reducing learning rate to 0.00018014615621479233.
Epoch 798/4000
24/24 - 3s - loss: 0.0665 - val_loss: 0.1524 - lr: 1.8015e-04

Epoch 00799: LearningRateScheduler reducing learning rate to 0.000179370079241093.
Epoch 799/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1623 - lr: 1.7937e-04

Epoch 00800: LearningRateScheduler reducing learning rate to 0.00017859734563858601.
Epoch 800/4000
Model saved in ./model/scPDB_1221_pdbid--800--0.1544--0.0001786.
24/24 - 3s - loss: 0.0668 - val_loss: 0.1544 - lr: 1.7860e-04

Epoch 00801: LearningRateScheduler reducing learning rate to 0.00017782794100389227.
Epoch 801/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1603 - lr: 1.7783e-04

Epoch 00802: LearningRateScheduler reducing learning rate to 0.00017706185099568283.
Epoch 802/4000
24/24 - 3s - loss: 0.0668 - val_loss: 0.1596 - lr: 1.7706e-04

Epoch 00803: LearningRateScheduler reducing learning rate to 0.00017629906133441196.
Epoch 803/4000
24/24 - 3s - loss: 0.0663 - val_loss: 0.1587 - lr: 1.7630e-04

Epoch 00804: LearningRateScheduler reducing learning rate to 0.00017553955780205067.
Epoch 804/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1646 - lr: 1.7554e-04

Epoch 00805: LearningRateScheduler reducing learning rate to 0.00017478332624182183.
Epoch 805/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1600 - lr: 1.7478e-04

Epoch 00806: LearningRateScheduler reducing learning rate to 0.0001740303525579364.
Epoch 806/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1648 - lr: 1.7403e-04

Epoch 00807: LearningRateScheduler reducing learning rate to 0.00017328062271533039.
Epoch 807/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1558 - lr: 1.7328e-04

Epoch 00808: LearningRateScheduler reducing learning rate to 0.00017253412273940356.
Epoch 808/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1549 - lr: 1.7253e-04

Epoch 00809: LearningRateScheduler reducing learning rate to 0.00017179083871575882.
Epoch 809/4000
24/24 - 3s - loss: 0.0661 - val_loss: 0.1579 - lr: 1.7179e-04

Epoch 00810: LearningRateScheduler reducing learning rate to 0.00017105075678994276.
Epoch 810/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1615 - lr: 1.7105e-04

Epoch 00811: LearningRateScheduler reducing learning rate to 0.00017031386316718766.
Epoch 811/4000
24/24 - 3s - loss: 0.0661 - val_loss: 0.1617 - lr: 1.7031e-04

Epoch 00812: LearningRateScheduler reducing learning rate to 0.00016958014411215416.
Epoch 812/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1573 - lr: 1.6958e-04

Epoch 00813: LearningRateScheduler reducing learning rate to 0.00016884958594867532.
Epoch 813/4000
24/24 - 3s - loss: 0.0663 - val_loss: 0.1652 - lr: 1.6885e-04

Epoch 00814: LearningRateScheduler reducing learning rate to 0.00016812217505950155.
Epoch 814/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1634 - lr: 1.6812e-04

Epoch 00815: LearningRateScheduler reducing learning rate to 0.00016739789788604713.
Epoch 815/4000
24/24 - 3s - loss: 0.0665 - val_loss: 0.1480 - lr: 1.6740e-04

Epoch 00816: LearningRateScheduler reducing learning rate to 0.00016667674092813714.
Epoch 816/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1608 - lr: 1.6668e-04

Epoch 00817: LearningRateScheduler reducing learning rate to 0.00016595869074375604.
Epoch 817/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1622 - lr: 1.6596e-04

Epoch 00818: LearningRateScheduler reducing learning rate to 0.00016524373394879703.
Epoch 818/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1560 - lr: 1.6524e-04

Epoch 00819: LearningRateScheduler reducing learning rate to 0.00016453185721681247.
Epoch 819/4000
24/24 - 3s - loss: 0.0660 - val_loss: 0.1632 - lr: 1.6453e-04

Epoch 00820: LearningRateScheduler reducing learning rate to 0.0001638230472787658.
Epoch 820/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1597 - lr: 1.6382e-04

Epoch 00821: LearningRateScheduler reducing learning rate to 0.00016311729092278383.
Epoch 821/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1582 - lr: 1.6312e-04

Epoch 00822: LearningRateScheduler reducing learning rate to 0.00016241457499391074.
Epoch 822/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1602 - lr: 1.6241e-04

Epoch 00823: LearningRateScheduler reducing learning rate to 0.00016171488639386283.
Epoch 823/4000
24/24 - 3s - loss: 0.0666 - val_loss: 0.1592 - lr: 1.6171e-04

Epoch 00824: LearningRateScheduler reducing learning rate to 0.0001610182120807843.
Epoch 824/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1574 - lr: 1.6102e-04

Epoch 00825: LearningRateScheduler reducing learning rate to 0.00016032453906900413.
Epoch 825/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1647 - lr: 1.6032e-04

Epoch 00826: LearningRateScheduler reducing learning rate to 0.0001596338544287942.
Epoch 826/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1629 - lr: 1.5963e-04

Epoch 00827: LearningRateScheduler reducing learning rate to 0.00015894614528612813.
Epoch 827/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1665 - lr: 1.5895e-04

Epoch 00828: LearningRateScheduler reducing learning rate to 0.00015826139882244142.
Epoch 828/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1573 - lr: 1.5826e-04

Epoch 00829: LearningRateScheduler reducing learning rate to 0.00015757960227439242.
Epoch 829/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1598 - lr: 1.5758e-04

Epoch 00830: LearningRateScheduler reducing learning rate to 0.00015690074293362444.
Epoch 830/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1665 - lr: 1.5690e-04

Epoch 00831: LearningRateScheduler reducing learning rate to 0.00015622480814652903.
Epoch 831/4000
24/24 - 3s - loss: 0.0657 - val_loss: 0.1590 - lr: 1.5622e-04

Epoch 00832: LearningRateScheduler reducing learning rate to 0.00015555178531400987.
Epoch 832/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1627 - lr: 1.5555e-04

Epoch 00833: LearningRateScheduler reducing learning rate to 0.00015488166189124813.
Epoch 833/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1547 - lr: 1.5488e-04

Epoch 00834: LearningRateScheduler reducing learning rate to 0.00015421442538746856.
Epoch 834/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1596 - lr: 1.5421e-04

Epoch 00835: LearningRateScheduler reducing learning rate to 0.0001535500633657067.
Epoch 835/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1547 - lr: 1.5355e-04

Epoch 00836: LearningRateScheduler reducing learning rate to 0.00015288856344257697.
Epoch 836/4000
24/24 - 3s - loss: 0.0661 - val_loss: 0.1649 - lr: 1.5289e-04

Epoch 00837: LearningRateScheduler reducing learning rate to 0.000152229913288042.
Epoch 837/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1616 - lr: 1.5223e-04

Epoch 00838: LearningRateScheduler reducing learning rate to 0.00015157410062518266.
Epoch 838/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1655 - lr: 1.5157e-04

Epoch 00839: LearningRateScheduler reducing learning rate to 0.00015092111322996933.
Epoch 839/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1612 - lr: 1.5092e-04

Epoch 00840: LearningRateScheduler reducing learning rate to 0.00015027093893103398.
Epoch 840/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1628 - lr: 1.5027e-04

Epoch 00841: LearningRateScheduler reducing learning rate to 0.00014962356560944333.
Epoch 841/4000
24/24 - 3s - loss: 0.0662 - val_loss: 0.1544 - lr: 1.4962e-04

Epoch 00842: LearningRateScheduler reducing learning rate to 0.000148978981198473.
Epoch 842/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1643 - lr: 1.4898e-04

Epoch 00843: LearningRateScheduler reducing learning rate to 0.00014833717368338247.
Epoch 843/4000
24/24 - 3s - loss: 0.0656 - val_loss: 0.1611 - lr: 1.4834e-04

Epoch 00844: LearningRateScheduler reducing learning rate to 0.00014769813110119133.
Epoch 844/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1587 - lr: 1.4770e-04

Epoch 00845: LearningRateScheduler reducing learning rate to 0.00014706184154045603.
Epoch 845/4000
24/24 - 3s - loss: 0.0658 - val_loss: 0.1613 - lr: 1.4706e-04

Epoch 00846: LearningRateScheduler reducing learning rate to 0.0001464282931410481.
Epoch 846/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1590 - lr: 1.4643e-04

Epoch 00847: LearningRateScheduler reducing learning rate to 0.00014579747409393298.
Epoch 847/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1597 - lr: 1.4580e-04

Epoch 00848: LearningRateScheduler reducing learning rate to 0.00014516937264094992.
Epoch 848/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1589 - lr: 1.4517e-04

Epoch 00849: LearningRateScheduler reducing learning rate to 0.00014454397707459272.
Epoch 849/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1623 - lr: 1.4454e-04

Epoch 00850: LearningRateScheduler reducing learning rate to 0.0001439212757377917.
Epoch 850/4000
Model saved in ./model/scPDB_1221_pdbid--850--0.1595--0.0001439.
24/24 - 3s - loss: 0.0645 - val_loss: 0.1595 - lr: 1.4392e-04

Epoch 00851: LearningRateScheduler reducing learning rate to 0.00014330125702369625.
Epoch 851/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1648 - lr: 1.4330e-04

Epoch 00852: LearningRateScheduler reducing learning rate to 0.00014268390937545856.
Epoch 852/4000
24/24 - 3s - loss: 0.0657 - val_loss: 0.1577 - lr: 1.4268e-04

Epoch 00853: LearningRateScheduler reducing learning rate to 0.00014206922128601822.
Epoch 853/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1560 - lr: 1.4207e-04

Epoch 00854: LearningRateScheduler reducing learning rate to 0.0001414571812978876.
Epoch 854/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1725 - lr: 1.4146e-04

Epoch 00855: LearningRateScheduler reducing learning rate to 0.0001408477780029385.
Epoch 855/4000
24/24 - 3s - loss: 0.0657 - val_loss: 0.1633 - lr: 1.4085e-04

Epoch 00856: LearningRateScheduler reducing learning rate to 0.00014024100004218947.
Epoch 856/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1601 - lr: 1.4024e-04

Epoch 00857: LearningRateScheduler reducing learning rate to 0.00013963683610559375.
Epoch 857/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1613 - lr: 1.3964e-04

Epoch 00858: LearningRateScheduler reducing learning rate to 0.00013903527493182898.
Epoch 858/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1655 - lr: 1.3904e-04

Epoch 00859: LearningRateScheduler reducing learning rate to 0.00013843630530808692.
Epoch 859/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1643 - lr: 1.3844e-04

Epoch 00860: LearningRateScheduler reducing learning rate to 0.00013783991606986458.
Epoch 860/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1583 - lr: 1.3784e-04

Epoch 00861: LearningRateScheduler reducing learning rate to 0.00013724609610075617.
Epoch 861/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1588 - lr: 1.3725e-04

Epoch 00862: LearningRateScheduler reducing learning rate to 0.00013665483433224568.
Epoch 862/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1567 - lr: 1.3665e-04

Epoch 00863: LearningRateScheduler reducing learning rate to 0.00013606611974350085.
Epoch 863/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1642 - lr: 1.3607e-04

Epoch 00864: LearningRateScheduler reducing learning rate to 0.00013547994136116757.
Epoch 864/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1599 - lr: 1.3548e-04

Epoch 00865: LearningRateScheduler reducing learning rate to 0.00013489628825916533.
Epoch 865/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1674 - lr: 1.3490e-04

Epoch 00866: LearningRateScheduler reducing learning rate to 0.00013431514955848377.
Epoch 866/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1479 - lr: 1.3432e-04

Epoch 00867: LearningRateScheduler reducing learning rate to 0.00013373651442697958.
Epoch 867/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1661 - lr: 1.3374e-04

Epoch 00868: LearningRateScheduler reducing learning rate to 0.00013316037207917482.
Epoch 868/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1579 - lr: 1.3316e-04

Epoch 00869: LearningRateScheduler reducing learning rate to 0.00013258671177605592.
Epoch 869/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1627 - lr: 1.3259e-04

Epoch 00870: LearningRateScheduler reducing learning rate to 0.0001320155228248733.
Epoch 870/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1620 - lr: 1.3202e-04

Epoch 00871: LearningRateScheduler reducing learning rate to 0.0001314467945789422.
Epoch 871/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1625 - lr: 1.3145e-04

Epoch 00872: LearningRateScheduler reducing learning rate to 0.00013088051643744432.
Epoch 872/4000
24/24 - 3s - loss: 0.0655 - val_loss: 0.1592 - lr: 1.3088e-04

Epoch 00873: LearningRateScheduler reducing learning rate to 0.00013031667784522993.
Epoch 873/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1591 - lr: 1.3032e-04

Epoch 00874: LearningRateScheduler reducing learning rate to 0.0001297552682926215.
Epoch 874/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1632 - lr: 1.2976e-04

Epoch 00875: LearningRateScheduler reducing learning rate to 0.0001291962773152175.
Epoch 875/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1624 - lr: 1.2920e-04

Epoch 00876: LearningRateScheduler reducing learning rate to 0.00012863969449369747.
Epoch 876/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1658 - lr: 1.2864e-04

Epoch 00877: LearningRateScheduler reducing learning rate to 0.0001280855094536278.
Epoch 877/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1666 - lr: 1.2809e-04

Epoch 00878: LearningRateScheduler reducing learning rate to 0.00012753371186526857.
Epoch 878/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1634 - lr: 1.2753e-04

Epoch 00879: LearningRateScheduler reducing learning rate to 0.00012698429144338054.
Epoch 879/4000
24/24 - 3s - loss: 0.0659 - val_loss: 0.1651 - lr: 1.2698e-04

Epoch 00880: LearningRateScheduler reducing learning rate to 0.00012643723794703376.
Epoch 880/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1604 - lr: 1.2644e-04

Epoch 00881: LearningRateScheduler reducing learning rate to 0.00012589254117941666.
Epoch 881/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1706 - lr: 1.2589e-04

Epoch 00882: LearningRateScheduler reducing learning rate to 0.000125350190987646.
Epoch 882/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1647 - lr: 1.2535e-04

Epoch 00883: LearningRateScheduler reducing learning rate to 0.0001248101772625775.
Epoch 883/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1566 - lr: 1.2481e-04

Epoch 00884: LearningRateScheduler reducing learning rate to 0.00012427248993861746.
Epoch 884/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1521 - lr: 1.2427e-04

Epoch 00885: LearningRateScheduler reducing learning rate to 0.00012373711899353522.
Epoch 885/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1718 - lr: 1.2374e-04

Epoch 00886: LearningRateScheduler reducing learning rate to 0.0001232040544482763.
Epoch 886/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1645 - lr: 1.2320e-04

Epoch 00887: LearningRateScheduler reducing learning rate to 0.0001226732863667764.
Epoch 887/4000
24/24 - 3s - loss: 0.0653 - val_loss: 0.1643 - lr: 1.2267e-04

Epoch 00888: LearningRateScheduler reducing learning rate to 0.00012214480485577616.
Epoch 888/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1636 - lr: 1.2214e-04

Epoch 00889: LearningRateScheduler reducing learning rate to 0.00012161860006463679.
Epoch 889/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1648 - lr: 1.2162e-04

Epoch 00890: LearningRateScheduler reducing learning rate to 0.00012109466218515644.
Epoch 890/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1569 - lr: 1.2109e-04

Epoch 00891: LearningRateScheduler reducing learning rate to 0.00012057298145138743.
Epoch 891/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1644 - lr: 1.2057e-04

Epoch 00892: LearningRateScheduler reducing learning rate to 0.00012005354813945414.
Epoch 892/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1565 - lr: 1.2005e-04

Epoch 00893: LearningRateScheduler reducing learning rate to 0.00011953635256737187.
Epoch 893/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1634 - lr: 1.1954e-04

Epoch 00894: LearningRateScheduler reducing learning rate to 0.00011902138509486618.
Epoch 894/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1618 - lr: 1.1902e-04

Epoch 00895: LearningRateScheduler reducing learning rate to 0.00011850863612319345.
Epoch 895/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1615 - lr: 1.1851e-04

Epoch 00896: LearningRateScheduler reducing learning rate to 0.0001179980960949618.
Epoch 896/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1589 - lr: 1.1800e-04

Epoch 00897: LearningRateScheduler reducing learning rate to 0.00011748975549395295.
Epoch 897/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1675 - lr: 1.1749e-04

Epoch 00898: LearningRateScheduler reducing learning rate to 0.00011698360484494491.
Epoch 898/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1626 - lr: 1.1698e-04

Epoch 00899: LearningRateScheduler reducing learning rate to 0.0001164796347135353.
Epoch 899/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1588 - lr: 1.1648e-04

Epoch 00900: LearningRateScheduler reducing learning rate to 0.00011597783570596556.
Epoch 900/4000
Model saved in ./model/scPDB_1221_pdbid--900--0.1591--0.0001160.
24/24 - 3s - loss: 0.0646 - val_loss: 0.1591 - lr: 1.1598e-04

Epoch 00901: LearningRateScheduler reducing learning rate to 0.00011547819846894578.
Epoch 901/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1681 - lr: 1.1548e-04

Epoch 00902: LearningRateScheduler reducing learning rate to 0.00011498071368948052.
Epoch 902/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1627 - lr: 1.1498e-04

Epoch 00903: LearningRateScheduler reducing learning rate to 0.00011448537209469497.
Epoch 903/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1636 - lr: 1.1449e-04

Epoch 00904: LearningRateScheduler reducing learning rate to 0.00011399216445166229.
Epoch 904/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1594 - lr: 1.1399e-04

Epoch 00905: LearningRateScheduler reducing learning rate to 0.00011350108156723148.
Epoch 905/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1604 - lr: 1.1350e-04

Epoch 00906: LearningRateScheduler reducing learning rate to 0.00011301211428785599.
Epoch 906/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1696 - lr: 1.1301e-04

Epoch 00907: LearningRateScheduler reducing learning rate to 0.00011252525349942312.
Epoch 907/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1683 - lr: 1.1253e-04

Epoch 00908: LearningRateScheduler reducing learning rate to 0.00011204049012708417.
Epoch 908/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1661 - lr: 1.1204e-04

Epoch 00909: LearningRateScheduler reducing learning rate to 0.0001115578151350852.
Epoch 909/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1630 - lr: 1.1156e-04

Epoch 00910: LearningRateScheduler reducing learning rate to 0.00011107721952659873.
Epoch 910/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1642 - lr: 1.1108e-04

Epoch 00911: LearningRateScheduler reducing learning rate to 0.00011059869434355593.
Epoch 911/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1659 - lr: 1.1060e-04

Epoch 00912: LearningRateScheduler reducing learning rate to 0.00011012223066647972.
Epoch 912/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1595 - lr: 1.1012e-04

Epoch 00913: LearningRateScheduler reducing learning rate to 0.00010964781961431847.
Epoch 913/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1570 - lr: 1.0965e-04

Epoch 00914: LearningRateScheduler reducing learning rate to 0.00010917545234428055.
Epoch 914/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1672 - lr: 1.0918e-04

Epoch 00915: LearningRateScheduler reducing learning rate to 0.0001087051200516693.
Epoch 915/4000
24/24 - 3s - loss: 0.0642 - val_loss: 0.1589 - lr: 1.0871e-04

Epoch 00916: LearningRateScheduler reducing learning rate to 0.00010823681396971918.
Epoch 916/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1546 - lr: 1.0824e-04

Epoch 00917: LearningRateScheduler reducing learning rate to 0.00010777052536943218.
Epoch 917/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1632 - lr: 1.0777e-04

Epoch 00918: LearningRateScheduler reducing learning rate to 0.00010730624555941517.
Epoch 918/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1677 - lr: 1.0731e-04

Epoch 00919: LearningRateScheduler reducing learning rate to 0.00010684396588571793.
Epoch 919/4000
24/24 - 3s - loss: 0.0652 - val_loss: 0.1653 - lr: 1.0684e-04

Epoch 00920: LearningRateScheduler reducing learning rate to 0.00010638367773167174.
Epoch 920/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1610 - lr: 1.0638e-04

Epoch 00921: LearningRateScheduler reducing learning rate to 0.00010592537251772889.
Epoch 921/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1579 - lr: 1.0593e-04

Epoch 00922: LearningRateScheduler reducing learning rate to 0.0001054690417013027.
Epoch 922/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1578 - lr: 1.0547e-04

Epoch 00923: LearningRateScheduler reducing learning rate to 0.00010501467677660833.
Epoch 923/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1637 - lr: 1.0501e-04

Epoch 00924: LearningRateScheduler reducing learning rate to 0.00010456226927450415.
Epoch 924/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1603 - lr: 1.0456e-04

Epoch 00925: LearningRateScheduler reducing learning rate to 0.00010411181076233396.
Epoch 925/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1588 - lr: 1.0411e-04

Epoch 00926: LearningRateScheduler reducing learning rate to 0.00010366329284376977.
Epoch 926/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1614 - lr: 1.0366e-04

Epoch 00927: LearningRateScheduler reducing learning rate to 0.0001032167071586554.
Epoch 927/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1611 - lr: 1.0322e-04

Epoch 00928: LearningRateScheduler reducing learning rate to 0.00010277204538285048.
Epoch 928/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1653 - lr: 1.0277e-04

Epoch 00929: LearningRateScheduler reducing learning rate to 0.00010232929922807538.
Epoch 929/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1598 - lr: 1.0233e-04

Epoch 00930: LearningRateScheduler reducing learning rate to 0.00010188846044175673.
Epoch 930/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1669 - lr: 1.0189e-04

Epoch 00931: LearningRateScheduler reducing learning rate to 0.00010144952080687359.
Epoch 931/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1579 - lr: 1.0145e-04

Epoch 00932: LearningRateScheduler reducing learning rate to 0.00010101247214180425.
Epoch 932/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1676 - lr: 1.0101e-04

Epoch 00933: LearningRateScheduler reducing learning rate to 0.00010057730630017379.
Epoch 933/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1604 - lr: 1.0058e-04

Epoch 00934: LearningRateScheduler reducing learning rate to 0.00010014401517070223.
Epoch 934/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1630 - lr: 1.0014e-04

Epoch 00935: LearningRateScheduler reducing learning rate to 9.971259067705322e-05.
Epoch 935/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1618 - lr: 9.9713e-05

Epoch 00936: LearningRateScheduler reducing learning rate to 9.928302477768371e-05.
Epoch 936/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1668 - lr: 9.9283e-05

Epoch 00937: LearningRateScheduler reducing learning rate to 9.885530946569386e-05.
Epoch 937/4000
24/24 - 3s - loss: 0.0642 - val_loss: 0.1684 - lr: 9.8855e-05

Epoch 00938: LearningRateScheduler reducing learning rate to 9.842943676867794e-05.
Epoch 938/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1617 - lr: 9.8429e-05

Epoch 00939: LearningRateScheduler reducing learning rate to 9.80053987485756e-05.
Epoch 939/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1639 - lr: 9.8005e-05

Epoch 00940: LearningRateScheduler reducing learning rate to 9.758318750152405e-05.
Epoch 940/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1647 - lr: 9.7583e-05

Epoch 00941: LearningRateScheduler reducing learning rate to 9.71627951577106e-05.
Epoch 941/4000
24/24 - 3s - loss: 0.0647 - val_loss: 0.1683 - lr: 9.7163e-05

Epoch 00942: LearningRateScheduler reducing learning rate to 9.67442138812261e-05.
Epoch 942/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1652 - lr: 9.6744e-05

Epoch 00943: LearningRateScheduler reducing learning rate to 9.632743586991876e-05.
Epoch 943/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1600 - lr: 9.6327e-05

Epoch 00944: LearningRateScheduler reducing learning rate to 9.591245335524878e-05.
Epoch 944/4000
24/24 - 3s - loss: 0.0651 - val_loss: 0.1613 - lr: 9.5912e-05

Epoch 00945: LearningRateScheduler reducing learning rate to 9.54992586021436e-05.
Epoch 945/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1671 - lr: 9.5499e-05

Epoch 00946: LearningRateScheduler reducing learning rate to 9.508784390885358e-05.
Epoch 946/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1664 - lr: 9.5088e-05

Epoch 00947: LearningRateScheduler reducing learning rate to 9.467820160680862e-05.
Epoch 947/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1675 - lr: 9.4678e-05

Epoch 00948: LearningRateScheduler reducing learning rate to 9.427032406047509e-05.
Epoch 948/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1660 - lr: 9.4270e-05

Epoch 00949: LearningRateScheduler reducing learning rate to 9.386420366721353e-05.
Epoch 949/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1720 - lr: 9.3864e-05

Epoch 00950: LearningRateScheduler reducing learning rate to 9.345983285713695e-05.
Epoch 950/4000
Model saved in ./model/scPDB_1221_pdbid--950--0.1567--0.0000935.
24/24 - 3s - loss: 0.0633 - val_loss: 0.1567 - lr: 9.3460e-05

Epoch 00951: LearningRateScheduler reducing learning rate to 9.305720409296986e-05.
Epoch 951/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1667 - lr: 9.3057e-05

Epoch 00952: LearningRateScheduler reducing learning rate to 9.265630986990754e-05.
Epoch 952/4000
24/24 - 3s - loss: 0.0654 - val_loss: 0.1615 - lr: 9.2656e-05

Epoch 00953: LearningRateScheduler reducing learning rate to 9.225714271547629e-05.
Epoch 953/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1631 - lr: 9.2257e-05

Epoch 00954: LearningRateScheduler reducing learning rate to 9.185969518939414e-05.
Epoch 954/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1668 - lr: 9.1860e-05

Epoch 00955: LearningRateScheduler reducing learning rate to 9.146395988343222e-05.
Epoch 955/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1710 - lr: 9.1464e-05

Epoch 00956: LearningRateScheduler reducing learning rate to 9.106992942127648e-05.
Epoch 956/4000
24/24 - 3s - loss: 0.0646 - val_loss: 0.1586 - lr: 9.1070e-05

Epoch 00957: LearningRateScheduler reducing learning rate to 9.067759645839046e-05.
Epoch 957/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1672 - lr: 9.0678e-05

Epoch 00958: LearningRateScheduler reducing learning rate to 9.028695368187822e-05.
Epoch 958/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1628 - lr: 9.0287e-05

Epoch 00959: LearningRateScheduler reducing learning rate to 8.9897993810348e-05.
Epoch 959/4000
24/24 - 3s - loss: 0.0650 - val_loss: 0.1589 - lr: 8.9898e-05

Epoch 00960: LearningRateScheduler reducing learning rate to 8.95107095937767e-05.
Epoch 960/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1661 - lr: 8.9511e-05

Epoch 00961: LearningRateScheduler reducing learning rate to 8.912509381337453e-05.
Epoch 961/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1687 - lr: 8.9125e-05

Epoch 00962: LearningRateScheduler reducing learning rate to 8.874113928145057e-05.
Epoch 962/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1629 - lr: 8.8741e-05

Epoch 00963: LearningRateScheduler reducing learning rate to 8.835883884127873e-05.
Epoch 963/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1636 - lr: 8.8359e-05

Epoch 00964: LearningRateScheduler reducing learning rate to 8.797818536696443e-05.
Epoch 964/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1701 - lr: 8.7978e-05

Epoch 00965: LearningRateScheduler reducing learning rate to 8.759917176331172e-05.
Epoch 965/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1642 - lr: 8.7599e-05

Epoch 00966: LearningRateScheduler reducing learning rate to 8.722179096569103e-05.
Epoch 966/4000
24/24 - 3s - loss: 0.0649 - val_loss: 0.1621 - lr: 8.7222e-05

Epoch 00967: LearningRateScheduler reducing learning rate to 8.684603593990752e-05.
Epoch 967/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1623 - lr: 8.6846e-05

Epoch 00968: LearningRateScheduler reducing learning rate to 8.647189968206993e-05.
Epoch 968/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1632 - lr: 8.6472e-05

Epoch 00969: LearningRateScheduler reducing learning rate to 8.609937521846007e-05.
Epoch 969/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1647 - lr: 8.6099e-05

Epoch 00970: LearningRateScheduler reducing learning rate to 8.572845560540279e-05.
Epoch 970/4000
24/24 - 3s - loss: 0.0648 - val_loss: 0.1643 - lr: 8.5728e-05

Epoch 00971: LearningRateScheduler reducing learning rate to 8.535913392913659e-05.
Epoch 971/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1653 - lr: 8.5359e-05

Epoch 00972: LearningRateScheduler reducing learning rate to 8.499140330568473e-05.
Epoch 972/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1537 - lr: 8.4991e-05

Epoch 00973: LearningRateScheduler reducing learning rate to 8.462525688072693e-05.
Epoch 973/4000
24/24 - 3s - loss: 0.0642 - val_loss: 0.1666 - lr: 8.4625e-05

Epoch 00974: LearningRateScheduler reducing learning rate to 8.426068782947154e-05.
Epoch 974/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1694 - lr: 8.4261e-05

Epoch 00975: LearningRateScheduler reducing learning rate to 8.389768935652854e-05.
Epoch 975/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1587 - lr: 8.3898e-05

Epoch 00976: LearningRateScheduler reducing learning rate to 8.353625469578259e-05.
Epoch 976/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1618 - lr: 8.3536e-05

Epoch 00977: LearningRateScheduler reducing learning rate to 8.317637711026708e-05.
Epoch 977/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1582 - lr: 8.3176e-05

Epoch 00978: LearningRateScheduler reducing learning rate to 8.281804989203853e-05.
Epoch 978/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1696 - lr: 8.2818e-05

Epoch 00979: LearningRateScheduler reducing learning rate to 8.246126636205158e-05.
Epoch 979/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1600 - lr: 8.2461e-05

Epoch 00980: LearningRateScheduler reducing learning rate to 8.210601987003444e-05.
Epoch 980/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1670 - lr: 8.2106e-05

Epoch 00981: LearningRateScheduler reducing learning rate to 8.175230379436498e-05.
Epoch 981/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1638 - lr: 8.1752e-05

Epoch 00982: LearningRateScheduler reducing learning rate to 8.140011154194728e-05.
Epoch 982/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1699 - lr: 8.1400e-05

Epoch 00983: LearningRateScheduler reducing learning rate to 8.104943654808874e-05.
Epoch 983/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1618 - lr: 8.1049e-05

Epoch 00984: LearningRateScheduler reducing learning rate to 8.070027227637771e-05.
Epoch 984/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1610 - lr: 8.0700e-05

Epoch 00985: LearningRateScheduler reducing learning rate to 8.035261221856171e-05.
Epoch 985/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1663 - lr: 8.0353e-05

Epoch 00986: LearningRateScheduler reducing learning rate to 8.000644989442605e-05.
Epoch 986/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1654 - lr: 8.0006e-05

Epoch 00987: LearningRateScheduler reducing learning rate to 7.966177885167306e-05.
Epoch 987/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1704 - lr: 7.9662e-05

Epoch 00988: LearningRateScheduler reducing learning rate to 7.931859266580187e-05.
Epoch 988/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1691 - lr: 7.9319e-05

Epoch 00989: LearningRateScheduler reducing learning rate to 7.897688493998855e-05.
Epoch 989/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1567 - lr: 7.8977e-05

Epoch 00990: LearningRateScheduler reducing learning rate to 7.863664930496702e-05.
Epoch 990/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1698 - lr: 7.8637e-05

Epoch 00991: LearningRateScheduler reducing learning rate to 7.829787941891022e-05.
Epoch 991/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1649 - lr: 7.8298e-05

Epoch 00992: LearningRateScheduler reducing learning rate to 7.796056896731196e-05.
Epoch 992/4000
24/24 - 3s - loss: 0.0645 - val_loss: 0.1636 - lr: 7.7961e-05

Epoch 00993: LearningRateScheduler reducing learning rate to 7.762471166286918e-05.
Epoch 993/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1703 - lr: 7.7625e-05

Epoch 00994: LearningRateScheduler reducing learning rate to 7.729030124536477e-05.
Epoch 994/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1614 - lr: 7.7290e-05

Epoch 00995: LearningRateScheduler reducing learning rate to 7.69573314815509e-05.
Epoch 995/4000
24/24 - 3s - loss: 0.0642 - val_loss: 0.1681 - lr: 7.6957e-05

Epoch 00996: LearningRateScheduler reducing learning rate to 7.662579616503287e-05.
Epoch 996/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1590 - lr: 7.6626e-05

Epoch 00997: LearningRateScheduler reducing learning rate to 7.629568911615331e-05.
Epoch 997/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1642 - lr: 7.6296e-05

Epoch 00998: LearningRateScheduler reducing learning rate to 7.596700418187711e-05.
Epoch 998/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1655 - lr: 7.5967e-05

Epoch 00999: LearningRateScheduler reducing learning rate to 7.563973523567662e-05.
Epoch 999/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1594 - lr: 7.5640e-05

Epoch 01000: LearningRateScheduler reducing learning rate to 7.531387617741766e-05.
Epoch 1000/4000
Model saved in ./model/scPDB_1221_pdbid--1000--0.1685--0.0000753.
24/24 - 3s - loss: 0.0643 - val_loss: 0.1685 - lr: 7.5314e-05

Epoch 01001: LearningRateScheduler reducing learning rate to 7.498942093324556e-05.
Epoch 1001/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1627 - lr: 7.4989e-05

Epoch 01002: LearningRateScheduler reducing learning rate to 7.466636345547208e-05.
Epoch 1002/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1661 - lr: 7.4666e-05

Epoch 01003: LearningRateScheduler reducing learning rate to 7.434469772246266e-05.
Epoch 1003/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1673 - lr: 7.4345e-05

Epoch 01004: LearningRateScheduler reducing learning rate to 7.402441773852425e-05.
Epoch 1004/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1647 - lr: 7.4024e-05

Epoch 01005: LearningRateScheduler reducing learning rate to 7.370551753379342e-05.
Epoch 1005/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1725 - lr: 7.3706e-05

Epoch 01006: LearningRateScheduler reducing learning rate to 7.338799116412519e-05.
Epoch 1006/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1673 - lr: 7.3388e-05

Epoch 01007: LearningRateScheduler reducing learning rate to 7.307183271098216e-05.
Epoch 1007/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1718 - lr: 7.3072e-05

Epoch 01008: LearningRateScheduler reducing learning rate to 7.275703628132431e-05.
Epoch 1008/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1601 - lr: 7.2757e-05

Epoch 01009: LearningRateScheduler reducing learning rate to 7.2443596007499e-05.
Epoch 1009/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1646 - lr: 7.2444e-05

Epoch 01010: LearningRateScheduler reducing learning rate to 7.21315060471317e-05.
Epoch 1010/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1586 - lr: 7.2132e-05

Epoch 01011: LearningRateScheduler reducing learning rate to 7.182076058301705e-05.
Epoch 1011/4000
24/24 - 3s - loss: 0.0643 - val_loss: 0.1699 - lr: 7.1821e-05

Epoch 01012: LearningRateScheduler reducing learning rate to 7.15113538230105e-05.
Epoch 1012/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1615 - lr: 7.1511e-05

Epoch 01013: LearningRateScheduler reducing learning rate to 7.120327999992024e-05.
Epoch 1013/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1700 - lr: 7.1203e-05

Epoch 01014: LearningRateScheduler reducing learning rate to 7.08965333713998e-05.
Epoch 1014/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1645 - lr: 7.0897e-05

Epoch 01015: LearningRateScheduler reducing learning rate to 7.059110821984094e-05.
Epoch 1015/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1639 - lr: 7.0591e-05

Epoch 01016: LearningRateScheduler reducing learning rate to 7.02869988522671e-05.
Epoch 1016/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1659 - lr: 7.0287e-05

Epoch 01017: LearningRateScheduler reducing learning rate to 6.998419960022735e-05.
Epoch 1017/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1696 - lr: 6.9984e-05

Epoch 01018: LearningRateScheduler reducing learning rate to 6.968270481969061e-05.
Epoch 1018/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1570 - lr: 6.9683e-05

Epoch 01019: LearningRateScheduler reducing learning rate to 6.938250889094057e-05.
Epoch 1019/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1659 - lr: 6.9383e-05

Epoch 01020: LearningRateScheduler reducing learning rate to 6.908360621847085e-05.
Epoch 1020/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1732 - lr: 6.9084e-05

Epoch 01021: LearningRateScheduler reducing learning rate to 6.878599123088077e-05.
Epoch 1021/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1652 - lr: 6.8786e-05

Epoch 01022: LearningRateScheduler reducing learning rate to 6.848965838077142e-05.
Epoch 1022/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1641 - lr: 6.8490e-05

Epoch 01023: LearningRateScheduler reducing learning rate to 6.819460214464235e-05.
Epoch 1023/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1628 - lr: 6.8195e-05

Epoch 01024: LearningRateScheduler reducing learning rate to 6.790081702278863e-05.
Epoch 1024/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1682 - lr: 6.7901e-05

Epoch 01025: LearningRateScheduler reducing learning rate to 6.760829753919816e-05.
Epoch 1025/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1668 - lr: 6.7608e-05

Epoch 01026: LearningRateScheduler reducing learning rate to 6.731703824144981e-05.
Epoch 1026/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1610 - lr: 6.7317e-05

Epoch 01027: LearningRateScheduler reducing learning rate to 6.702703370061166e-05.
Epoch 1027/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1636 - lr: 6.7027e-05

Epoch 01028: LearningRateScheduler reducing learning rate to 6.673827851113987e-05.
Epoch 1028/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1664 - lr: 6.6738e-05

Epoch 01029: LearningRateScheduler reducing learning rate to 6.645076729077794e-05.
Epoch 1029/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1669 - lr: 6.6451e-05

Epoch 01030: LearningRateScheduler reducing learning rate to 6.616449468045625e-05.
Epoch 1030/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1626 - lr: 6.6164e-05

Epoch 01031: LearningRateScheduler reducing learning rate to 6.587945534419238e-05.
Epoch 1031/4000
24/24 - 3s - loss: 0.0644 - val_loss: 0.1697 - lr: 6.5879e-05

Epoch 01032: LearningRateScheduler reducing learning rate to 6.559564396899144e-05.
Epoch 1032/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1688 - lr: 6.5596e-05

Epoch 01033: LearningRateScheduler reducing learning rate to 6.531305526474722e-05.
Epoch 1033/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1681 - lr: 6.5313e-05

Epoch 01034: LearningRateScheduler reducing learning rate to 6.503168396414347e-05.
Epoch 1034/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1589 - lr: 6.5032e-05

Epoch 01035: LearningRateScheduler reducing learning rate to 6.475152482255575e-05.
Epoch 1035/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1691 - lr: 6.4752e-05

Epoch 01036: LearningRateScheduler reducing learning rate to 6.447257261795367e-05.
Epoch 1036/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1696 - lr: 6.4473e-05

Epoch 01037: LearningRateScheduler reducing learning rate to 6.419482215080358e-05.
Epoch 1037/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1549 - lr: 6.4195e-05

Epoch 01038: LearningRateScheduler reducing learning rate to 6.391826824397161e-05.
Epoch 1038/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1694 - lr: 6.3918e-05

Epoch 01039: LearningRateScheduler reducing learning rate to 6.36429057426272e-05.
Epoch 1039/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1736 - lr: 6.3643e-05

Epoch 01040: LearningRateScheduler reducing learning rate to 6.336872951414704e-05.
Epoch 1040/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1604 - lr: 6.3369e-05

Epoch 01041: LearningRateScheduler reducing learning rate to 6.309573444801932e-05.
Epoch 1041/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1598 - lr: 6.3096e-05

Epoch 01042: LearningRateScheduler reducing learning rate to 6.282391545574857e-05.
Epoch 1042/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1644 - lr: 6.2824e-05

Epoch 01043: LearningRateScheduler reducing learning rate to 6.25532674707607e-05.
Epoch 1043/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1668 - lr: 6.2553e-05

Epoch 01044: LearningRateScheduler reducing learning rate to 6.228378544830872e-05.
Epoch 1044/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1655 - lr: 6.2284e-05

Epoch 01045: LearningRateScheduler reducing learning rate to 6.201546436537854e-05.
Epoch 1045/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1592 - lr: 6.2015e-05

Epoch 01046: LearningRateScheduler reducing learning rate to 6.174829922059545e-05.
Epoch 1046/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1767 - lr: 6.1748e-05

Epoch 01047: LearningRateScheduler reducing learning rate to 6.148228503413087e-05.
Epoch 1047/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1643 - lr: 6.1482e-05

Epoch 01048: LearningRateScheduler reducing learning rate to 6.121741684760946e-05.
Epoch 1048/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1689 - lr: 6.1217e-05

Epoch 01049: LearningRateScheduler reducing learning rate to 6.09536897240169e-05.
Epoch 1049/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1706 - lr: 6.0954e-05

Epoch 01050: LearningRateScheduler reducing learning rate to 6.0691098747607604e-05.
Epoch 1050/4000
Model saved in ./model/scPDB_1221_pdbid--1050--0.1703--0.0000607.
24/24 - 3s - loss: 0.0631 - val_loss: 0.1703 - lr: 6.0691e-05

Epoch 01051: LearningRateScheduler reducing learning rate to 6.042963902381326e-05.
Epoch 1051/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1673 - lr: 6.0430e-05

Epoch 01052: LearningRateScheduler reducing learning rate to 6.0169305679151566e-05.
Epoch 1052/4000
24/24 - 3s - loss: 0.0639 - val_loss: 0.1679 - lr: 6.0169e-05

Epoch 01053: LearningRateScheduler reducing learning rate to 5.991009386113537e-05.
Epoch 1053/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1669 - lr: 5.9910e-05

Epoch 01054: LearningRateScheduler reducing learning rate to 5.9651998738182226e-05.
Epoch 1054/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1658 - lr: 5.9652e-05

Epoch 01055: LearningRateScheduler reducing learning rate to 5.939501549952435e-05.
Epoch 1055/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1759 - lr: 5.9395e-05

Epoch 01056: LearningRateScheduler reducing learning rate to 5.9139139355118933e-05.
Epoch 1056/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1618 - lr: 5.9139e-05

Epoch 01057: LearningRateScheduler reducing learning rate to 5.888436553555889e-05.
Epoch 1057/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1662 - lr: 5.8884e-05

Epoch 01058: LearningRateScheduler reducing learning rate to 5.863068929198389e-05.
Epoch 1058/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1674 - lr: 5.8631e-05

Epoch 01059: LearningRateScheduler reducing learning rate to 5.837810589599194e-05.
Epoch 1059/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1620 - lr: 5.8378e-05

Epoch 01060: LearningRateScheduler reducing learning rate to 5.812661063955115e-05.
Epoch 1060/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1646 - lr: 5.8127e-05

Epoch 01061: LearningRateScheduler reducing learning rate to 5.7876198834912056e-05.
Epoch 1061/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1681 - lr: 5.7876e-05

Epoch 01062: LearningRateScheduler reducing learning rate to 5.762686581452019e-05.
Epoch 1062/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1646 - lr: 5.7627e-05

Epoch 01063: LearningRateScheduler reducing learning rate to 5.737860693092909e-05.
Epoch 1063/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1682 - lr: 5.7379e-05

Epoch 01064: LearningRateScheduler reducing learning rate to 5.713141755671372e-05.
Epoch 1064/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1717 - lr: 5.7131e-05

Epoch 01065: LearningRateScheduler reducing learning rate to 5.688529308438414e-05.
Epoch 1065/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1624 - lr: 5.6885e-05

Epoch 01066: LearningRateScheduler reducing learning rate to 5.664022892629968e-05.
Epoch 1066/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1632 - lr: 5.6640e-05

Epoch 01067: LearningRateScheduler reducing learning rate to 5.639622051458343e-05.
Epoch 1067/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1680 - lr: 5.6396e-05

Epoch 01068: LearningRateScheduler reducing learning rate to 5.6153263301037036e-05.
Epoch 1068/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1741 - lr: 5.6153e-05

Epoch 01069: LearningRateScheduler reducing learning rate to 5.5911352757056015e-05.
Epoch 1069/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1698 - lr: 5.5911e-05

Epoch 01070: LearningRateScheduler reducing learning rate to 5.5670484373545255e-05.
Epoch 1070/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1567 - lr: 5.5670e-05

Epoch 01071: LearningRateScheduler reducing learning rate to 5.543065366083506e-05.
Epoch 1071/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1641 - lr: 5.5431e-05

Epoch 01072: LearningRateScheduler reducing learning rate to 5.519185614859733e-05.
Epoch 1072/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1679 - lr: 5.5192e-05

Epoch 01073: LearningRateScheduler reducing learning rate to 5.4954087385762434e-05.
Epoch 1073/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1764 - lr: 5.4954e-05

Epoch 01074: LearningRateScheduler reducing learning rate to 5.471734294043604e-05.
Epoch 1074/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1683 - lr: 5.4717e-05

Epoch 01075: LearningRateScheduler reducing learning rate to 5.448161839981665e-05.
Epoch 1075/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1642 - lr: 5.4482e-05

Epoch 01076: LearningRateScheduler reducing learning rate to 5.4246909370113244e-05.
Epoch 1076/4000
24/24 - 3s - loss: 0.0638 - val_loss: 0.1680 - lr: 5.4247e-05

Epoch 01077: LearningRateScheduler reducing learning rate to 5.401321147646347e-05.
Epoch 1077/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1676 - lr: 5.4013e-05

Epoch 01078: LearningRateScheduler reducing learning rate to 5.3780520362852054e-05.
Epoch 1078/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1715 - lr: 5.3781e-05

Epoch 01079: LearningRateScheduler reducing learning rate to 5.354883169202961e-05.
Epoch 1079/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1678 - lr: 5.3549e-05

Epoch 01080: LearningRateScheduler reducing learning rate to 5.3318141145431795e-05.
Epoch 1080/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1706 - lr: 5.3318e-05

Epoch 01081: LearningRateScheduler reducing learning rate to 5.308844442309882e-05.
Epoch 1081/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1654 - lr: 5.3088e-05

Epoch 01082: LearningRateScheduler reducing learning rate to 5.285973724359531e-05.
Epoch 1082/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1682 - lr: 5.2860e-05

Epoch 01083: LearningRateScheduler reducing learning rate to 5.263201534393047e-05.
Epoch 1083/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1664 - lr: 5.2632e-05

Epoch 01084: LearningRateScheduler reducing learning rate to 5.2405274479478646e-05.
Epoch 1084/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1651 - lr: 5.2405e-05

Epoch 01085: LearningRateScheduler reducing learning rate to 5.217951042390022e-05.
Epoch 1085/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1751 - lr: 5.2180e-05

Epoch 01086: LearningRateScheduler reducing learning rate to 5.195471896906279e-05.
Epoch 1086/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1687 - lr: 5.1955e-05

Epoch 01087: LearningRateScheduler reducing learning rate to 5.1730895924962786e-05.
Epoch 1087/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1701 - lr: 5.1731e-05

Epoch 01088: LearningRateScheduler reducing learning rate to 5.150803711964733e-05.
Epoch 1088/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1656 - lr: 5.1508e-05

Epoch 01089: LearningRateScheduler reducing learning rate to 5.128613839913648e-05.
Epoch 1089/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1739 - lr: 5.1286e-05

Epoch 01090: LearningRateScheduler reducing learning rate to 5.106519562734583e-05.
Epoch 1090/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1745 - lr: 5.1065e-05

Epoch 01091: LearningRateScheduler reducing learning rate to 5.084520468600938e-05.
Epoch 1091/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1553 - lr: 5.0845e-05

Epoch 01092: LearningRateScheduler reducing learning rate to 5.062616147460279e-05.
Epoch 1092/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1683 - lr: 5.0626e-05

Epoch 01093: LearningRateScheduler reducing learning rate to 5.040806191026694e-05.
Epoch 1093/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1704 - lr: 5.0408e-05

Epoch 01094: LearningRateScheduler reducing learning rate to 5.0190901927731847e-05.
Epoch 1094/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1658 - lr: 5.0191e-05

Epoch 01095: LearningRateScheduler reducing learning rate to 4.997467747924086e-05.
Epoch 1095/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1628 - lr: 4.9975e-05

Epoch 01096: LearningRateScheduler reducing learning rate to 4.975938453447522e-05.
Epoch 1096/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1670 - lr: 4.9759e-05

Epoch 01097: LearningRateScheduler reducing learning rate to 4.9545019080479005e-05.
Epoch 1097/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1724 - lr: 4.9545e-05

Epoch 01098: LearningRateScheduler reducing learning rate to 4.9331577121584205e-05.
Epoch 1098/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1619 - lr: 4.9332e-05

Epoch 01099: LearningRateScheduler reducing learning rate to 4.9119054679336324e-05.
Epoch 1099/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1692 - lr: 4.9119e-05

Epoch 01100: LearningRateScheduler reducing learning rate to 4.8907447792420234e-05.
Epoch 1100/4000
Model saved in ./model/scPDB_1221_pdbid--1100--0.1598--0.0000489.
24/24 - 3s - loss: 0.0636 - val_loss: 0.1598 - lr: 4.8907e-05

Epoch 01101: LearningRateScheduler reducing learning rate to 4.86967525165863e-05.
Epoch 1101/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1744 - lr: 4.8697e-05

Epoch 01102: LearningRateScheduler reducing learning rate to 4.8486964924576855e-05.
Epoch 1102/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1649 - lr: 4.8487e-05

Epoch 01103: LearningRateScheduler reducing learning rate to 4.827808110605305e-05.
Epoch 1103/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1705 - lr: 4.8278e-05

Epoch 01104: LearningRateScheduler reducing learning rate to 4.807009716752192e-05.
Epoch 1104/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1641 - lr: 4.8070e-05

Epoch 01105: LearningRateScheduler reducing learning rate to 4.7863009232263824e-05.
Epoch 1105/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1673 - lr: 4.7863e-05

Epoch 01106: LearningRateScheduler reducing learning rate to 4.765681344026019e-05.
Epoch 1106/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1668 - lr: 4.7657e-05

Epoch 01107: LearningRateScheduler reducing learning rate to 4.745150594812157e-05.
Epoch 1107/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1697 - lr: 4.7452e-05

Epoch 01108: LearningRateScheduler reducing learning rate to 4.724708292901599e-05.
Epoch 1108/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1677 - lr: 4.7247e-05

Epoch 01109: LearningRateScheduler reducing learning rate to 4.704354057259761e-05.
Epoch 1109/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1734 - lr: 4.7044e-05

Epoch 01110: LearningRateScheduler reducing learning rate to 4.684087508493573e-05.
Epoch 1110/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1582 - lr: 4.6841e-05

Epoch 01111: LearningRateScheduler reducing learning rate to 4.6639082688444056e-05.
Epoch 1111/4000
24/24 - 3s - loss: 0.0641 - val_loss: 0.1704 - lr: 4.6639e-05

Epoch 01112: LearningRateScheduler reducing learning rate to 4.643815962181029e-05.
Epoch 1112/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1724 - lr: 4.6438e-05

Epoch 01113: LearningRateScheduler reducing learning rate to 4.623810213992603e-05.
Epoch 1113/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1658 - lr: 4.6238e-05

Epoch 01114: LearningRateScheduler reducing learning rate to 4.6038906513816915e-05.
Epoch 1114/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1646 - lr: 4.6039e-05

Epoch 01115: LearningRateScheduler reducing learning rate to 4.584056903057321e-05.
Epoch 1115/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1688 - lr: 4.5841e-05

Epoch 01116: LearningRateScheduler reducing learning rate to 4.5643085993280506e-05.
Epoch 1116/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1647 - lr: 4.5643e-05

Epoch 01117: LearningRateScheduler reducing learning rate to 4.5446453720950864e-05.
Epoch 1117/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1650 - lr: 4.5446e-05

Epoch 01118: LearningRateScheduler reducing learning rate to 4.5250668548454216e-05.
Epoch 1118/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1703 - lr: 4.5251e-05

Epoch 01119: LearningRateScheduler reducing learning rate to 4.505572682644997e-05.
Epoch 1119/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1728 - lr: 4.5056e-05

Epoch 01120: LearningRateScheduler reducing learning rate to 4.48616249213191e-05.
Epoch 1120/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1701 - lr: 4.4862e-05

Epoch 01121: LearningRateScheduler reducing learning rate to 4.4668359215096294e-05.
Epoch 1121/4000
24/24 - 3s - loss: 0.0640 - val_loss: 0.1602 - lr: 4.4668e-05

Epoch 01122: LearningRateScheduler reducing learning rate to 4.447592610540266e-05.
Epoch 1122/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1712 - lr: 4.4476e-05

Epoch 01123: LearningRateScheduler reducing learning rate to 4.428432200537845e-05.
Epoch 1123/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1734 - lr: 4.4284e-05

Epoch 01124: LearningRateScheduler reducing learning rate to 4.409354334361626e-05.
Epoch 1124/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1700 - lr: 4.4094e-05

Epoch 01125: LearningRateScheduler reducing learning rate to 4.3903586564094445e-05.
Epoch 1125/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1690 - lr: 4.3904e-05

Epoch 01126: LearningRateScheduler reducing learning rate to 4.371444812611088e-05.
Epoch 1126/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1633 - lr: 4.3714e-05

Epoch 01127: LearningRateScheduler reducing learning rate to 4.3526124504216896e-05.
Epoch 1127/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1764 - lr: 4.3526e-05

Epoch 01128: LearningRateScheduler reducing learning rate to 4.3338612188151617e-05.
Epoch 1128/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1692 - lr: 4.3339e-05

Epoch 01129: LearningRateScheduler reducing learning rate to 4.3151907682776516e-05.
Epoch 1129/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1622 - lr: 4.3152e-05

Epoch 01130: LearningRateScheduler reducing learning rate to 4.296600750801024e-05.
Epoch 1130/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1620 - lr: 4.2966e-05

Epoch 01131: LearningRateScheduler reducing learning rate to 4.27809081987638e-05.
Epoch 1131/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1675 - lr: 4.2781e-05

Epoch 01132: LearningRateScheduler reducing learning rate to 4.2596606304875924e-05.
Epoch 1132/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1636 - lr: 4.2597e-05

Epoch 01133: LearningRateScheduler reducing learning rate to 4.241309839104881e-05.
Epoch 1133/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1719 - lr: 4.2413e-05

Epoch 01134: LearningRateScheduler reducing learning rate to 4.223038103678403e-05.
Epoch 1134/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1697 - lr: 4.2230e-05

Epoch 01135: LearningRateScheduler reducing learning rate to 4.204845083631879e-05.
Epoch 1135/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1668 - lr: 4.2048e-05

Epoch 01136: LearningRateScheduler reducing learning rate to 4.186730439856252e-05.
Epoch 1136/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1610 - lr: 4.1867e-05

Epoch 01137: LearningRateScheduler reducing learning rate to 4.168693834703353e-05.
Epoch 1137/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1728 - lr: 4.1687e-05

Epoch 01138: LearningRateScheduler reducing learning rate to 4.1507349319796214e-05.
Epoch 1138/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1655 - lr: 4.1507e-05

Epoch 01139: LearningRateScheduler reducing learning rate to 4.132853396939829e-05.
Epoch 1139/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1635 - lr: 4.1329e-05

Epoch 01140: LearningRateScheduler reducing learning rate to 4.1150488962808425e-05.
Epoch 1140/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1633 - lr: 4.1150e-05

Epoch 01141: LearningRateScheduler reducing learning rate to 4.097321098135415e-05.
Epoch 1141/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1597 - lr: 4.0973e-05

Epoch 01142: LearningRateScheduler reducing learning rate to 4.079669672065996e-05.
Epoch 1142/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1688 - lr: 4.0797e-05

Epoch 01143: LearningRateScheduler reducing learning rate to 4.062094289058573e-05.
Epoch 1143/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1719 - lr: 4.0621e-05

Epoch 01144: LearningRateScheduler reducing learning rate to 4.04459462151654e-05.
Epoch 1144/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1702 - lr: 4.0446e-05

Epoch 01145: LearningRateScheduler reducing learning rate to 4.0271703432545897e-05.
Epoch 1145/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1625 - lr: 4.0272e-05

Epoch 01146: LearningRateScheduler reducing learning rate to 4.0098211294926354e-05.
Epoch 1146/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1673 - lr: 4.0098e-05

Epoch 01147: LearningRateScheduler reducing learning rate to 3.992546656849756e-05.
Epoch 1147/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1669 - lr: 3.9925e-05

Epoch 01148: LearningRateScheduler reducing learning rate to 3.9753466033381675e-05.
Epoch 1148/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1654 - lr: 3.9753e-05

Epoch 01149: LearningRateScheduler reducing learning rate to 3.958220648357223e-05.
Epoch 1149/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1709 - lr: 3.9582e-05

Epoch 01150: LearningRateScheduler reducing learning rate to 3.9411684726874375e-05.
Epoch 1150/4000
Model saved in ./model/scPDB_1221_pdbid--1150--0.1676--0.0000394.
24/24 - 13s - loss: 0.0629 - val_loss: 0.1676 - lr: 3.9412e-05

Epoch 01151: LearningRateScheduler reducing learning rate to 3.924189758484534e-05.
Epoch 1151/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1624 - lr: 3.9242e-05

Epoch 01152: LearningRateScheduler reducing learning rate to 3.907284189273524e-05.
Epoch 1152/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1697 - lr: 3.9073e-05

Epoch 01153: LearningRateScheduler reducing learning rate to 3.890451449942805e-05.
Epoch 1153/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1677 - lr: 3.8905e-05

Epoch 01154: LearningRateScheduler reducing learning rate to 3.8736912267382875e-05.
Epoch 1154/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1647 - lr: 3.8737e-05

Epoch 01155: LearningRateScheduler reducing learning rate to 3.8570032072575476e-05.
Epoch 1155/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1700 - lr: 3.8570e-05

Epoch 01156: LearningRateScheduler reducing learning rate to 3.840387080444006e-05.
Epoch 1156/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1695 - lr: 3.8404e-05

Epoch 01157: LearningRateScheduler reducing learning rate to 3.8238425365811254e-05.
Epoch 1157/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1664 - lr: 3.8238e-05

Epoch 01158: LearningRateScheduler reducing learning rate to 3.8073692672866404e-05.
Epoch 1158/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1719 - lr: 3.8074e-05

Epoch 01159: LearningRateScheduler reducing learning rate to 3.7909669655068084e-05.
Epoch 1159/4000
24/24 - 3s - loss: 0.0637 - val_loss: 0.1695 - lr: 3.7910e-05

Epoch 01160: LearningRateScheduler reducing learning rate to 3.774635325510689e-05.
Epoch 1160/4000
24/24 - 2s - loss: 0.0626 - val_loss: 0.1657 - lr: 3.7746e-05

Epoch 01161: LearningRateScheduler reducing learning rate to 3.758374042884441e-05.
Epoch 1161/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1685 - lr: 3.7584e-05

Epoch 01162: LearningRateScheduler reducing learning rate to 3.742182814525651e-05.
Epoch 1162/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1669 - lr: 3.7422e-05

Epoch 01163: LearningRateScheduler reducing learning rate to 3.726061338637684e-05.
Epoch 1163/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1741 - lr: 3.7261e-05

Epoch 01164: LearningRateScheduler reducing learning rate to 3.710009314724056e-05.
Epoch 1164/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1676 - lr: 3.7100e-05

Epoch 01165: LearningRateScheduler reducing learning rate to 3.6940264435828346e-05.
Epoch 1165/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1641 - lr: 3.6940e-05

Epoch 01166: LearningRateScheduler reducing learning rate to 3.678112427301061e-05.
Epoch 1166/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1737 - lr: 3.6781e-05

Epoch 01167: LearningRateScheduler reducing learning rate to 3.662266969249198e-05.
Epoch 1167/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1662 - lr: 3.6623e-05

Epoch 01168: LearningRateScheduler reducing learning rate to 3.6464897740756024e-05.
Epoch 1168/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1715 - lr: 3.6465e-05

Epoch 01169: LearningRateScheduler reducing learning rate to 3.630780547701012e-05.
Epoch 1169/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1725 - lr: 3.6308e-05

Epoch 01170: LearningRateScheduler reducing learning rate to 3.615138997313079e-05.
Epoch 1170/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1647 - lr: 3.6151e-05

Epoch 01171: LearningRateScheduler reducing learning rate to 3.5995648313608944e-05.
Epoch 1171/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1669 - lr: 3.5996e-05

Epoch 01172: LearningRateScheduler reducing learning rate to 3.5840577595495686e-05.
Epoch 1172/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1662 - lr: 3.5841e-05

Epoch 01173: LearningRateScheduler reducing learning rate to 3.56861749283481e-05.
Epoch 1173/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1628 - lr: 3.5686e-05

Epoch 01174: LearningRateScheduler reducing learning rate to 3.553243743417545e-05.
Epoch 1174/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1735 - lr: 3.5532e-05

Epoch 01175: LearningRateScheduler reducing learning rate to 3.537936224738547e-05.
Epoch 1175/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1626 - lr: 3.5379e-05

Epoch 01176: LearningRateScheduler reducing learning rate to 3.5226946514731004e-05.
Epoch 1176/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1698 - lr: 3.5227e-05

Epoch 01177: LearningRateScheduler reducing learning rate to 3.507518739525679e-05.
Epoch 1177/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1655 - lr: 3.5075e-05

Epoch 01178: LearningRateScheduler reducing learning rate to 3.4924082060246523e-05.
Epoch 1178/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1691 - lr: 3.4924e-05

Epoch 01179: LearningRateScheduler reducing learning rate to 3.477362769317012e-05.
Epoch 1179/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1738 - lr: 3.4774e-05

Epoch 01180: LearningRateScheduler reducing learning rate to 3.462382148963123e-05.
Epoch 1180/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1656 - lr: 3.4624e-05

Epoch 01181: LearningRateScheduler reducing learning rate to 3.447466065731493e-05.
Epoch 1181/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1696 - lr: 3.4475e-05

Epoch 01182: LearningRateScheduler reducing learning rate to 3.432614241593575e-05.
Epoch 1182/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1697 - lr: 3.4326e-05

Epoch 01183: LearningRateScheduler reducing learning rate to 3.4178263997185756e-05.
Epoch 1183/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1699 - lr: 3.4178e-05

Epoch 01184: LearningRateScheduler reducing learning rate to 3.403102264468303e-05.
Epoch 1184/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1701 - lr: 3.4031e-05

Epoch 01185: LearningRateScheduler reducing learning rate to 3.388441561392025e-05.
Epoch 1185/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1738 - lr: 3.3884e-05

Epoch 01186: LearningRateScheduler reducing learning rate to 3.373844017221353e-05.
Epoch 1186/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1703 - lr: 3.3738e-05

Epoch 01187: LearningRateScheduler reducing learning rate to 3.3593093598651516e-05.
Epoch 1187/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1627 - lr: 3.3593e-05

Epoch 01188: LearningRateScheduler reducing learning rate to 3.3448373184044636e-05.
Epoch 1188/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1713 - lr: 3.3448e-05

Epoch 01189: LearningRateScheduler reducing learning rate to 3.330427623087463e-05.
Epoch 1189/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1617 - lr: 3.3304e-05

Epoch 01190: LearningRateScheduler reducing learning rate to 3.316080005324425e-05.
Epoch 1190/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1759 - lr: 3.3161e-05

Epoch 01191: LearningRateScheduler reducing learning rate to 3.30179419768272e-05.
Epoch 1191/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1662 - lr: 3.3018e-05

Epoch 01192: LearningRateScheduler reducing learning rate to 3.287569933881829e-05.
Epoch 1192/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1722 - lr: 3.2876e-05

Epoch 01193: LearningRateScheduler reducing learning rate to 3.273406948788382e-05.
Epoch 1193/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1610 - lr: 3.2734e-05

Epoch 01194: LearningRateScheduler reducing learning rate to 3.25930497841121e-05.
Epoch 1194/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1651 - lr: 3.2593e-05

Epoch 01195: LearningRateScheduler reducing learning rate to 3.2452637598964356e-05.
Epoch 1195/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1634 - lr: 3.2453e-05

Epoch 01196: LearningRateScheduler reducing learning rate to 3.231283031522562e-05.
Epoch 1196/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1736 - lr: 3.2313e-05

Epoch 01197: LearningRateScheduler reducing learning rate to 3.217362532695597e-05.
Epoch 1197/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1651 - lr: 3.2174e-05

Epoch 01198: LearningRateScheduler reducing learning rate to 3.2035020039442044e-05.
Epoch 1198/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1717 - lr: 3.2035e-05

Epoch 01199: LearningRateScheduler reducing learning rate to 3.1897011869148564e-05.
Epoch 1199/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1647 - lr: 3.1897e-05

Epoch 01200: LearningRateScheduler reducing learning rate to 3.175959824367023e-05.
Epoch 1200/4000
Model saved in ./model/scPDB_1221_pdbid--1200--0.1776--0.0000318.
24/24 - 14s - loss: 0.0631 - val_loss: 0.1776 - lr: 3.1760e-05

Epoch 01201: LearningRateScheduler reducing learning rate to 3.162277660168378e-05.
Epoch 1201/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1672 - lr: 3.1623e-05

Epoch 01202: LearningRateScheduler reducing learning rate to 3.148654439290025e-05.
Epoch 1202/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1689 - lr: 3.1487e-05

Epoch 01203: LearningRateScheduler reducing learning rate to 3.1350899078017395e-05.
Epoch 1203/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1708 - lr: 3.1351e-05

Epoch 01204: LearningRateScheduler reducing learning rate to 3.12158381286724e-05.
Epoch 1204/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1703 - lr: 3.1216e-05

Epoch 01205: LearningRateScheduler reducing learning rate to 3.1081359027394744e-05.
Epoch 1205/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1687 - lr: 3.1081e-05

Epoch 01206: LearningRateScheduler reducing learning rate to 3.094745926755928e-05.
Epoch 1206/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1664 - lr: 3.0947e-05

Epoch 01207: LearningRateScheduler reducing learning rate to 3.081413635333948e-05.
Epoch 1207/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1657 - lr: 3.0814e-05

Epoch 01208: LearningRateScheduler reducing learning rate to 3.068138779966096e-05.
Epoch 1208/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1717 - lr: 3.0681e-05

Epoch 01209: LearningRateScheduler reducing learning rate to 3.054921113215513e-05.
Epoch 1209/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1718 - lr: 3.0549e-05

Epoch 01210: LearningRateScheduler reducing learning rate to 3.041760388711307e-05.
Epoch 1210/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1630 - lr: 3.0418e-05

Epoch 01211: LearningRateScheduler reducing learning rate to 3.0286563611439635e-05.
Epoch 1211/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1709 - lr: 3.0287e-05

Epoch 01212: LearningRateScheduler reducing learning rate to 3.0156087862607707e-05.
Epoch 1212/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1707 - lr: 3.0156e-05

Epoch 01213: LearningRateScheduler reducing learning rate to 3.002617420861267e-05.
Epoch 1213/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1750 - lr: 3.0026e-05

Epoch 01214: LearningRateScheduler reducing learning rate to 2.9896820227927092e-05.
Epoch 1214/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1656 - lr: 2.9897e-05

Epoch 01215: LearningRateScheduler reducing learning rate to 2.9768023509455572e-05.
Epoch 1215/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1703 - lr: 2.9768e-05

Epoch 01216: LearningRateScheduler reducing learning rate to 2.9639781652489813e-05.
Epoch 1216/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1660 - lr: 2.9640e-05

Epoch 01217: LearningRateScheduler reducing learning rate to 2.9512092266663854e-05.
Epoch 1217/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1687 - lr: 2.9512e-05

Epoch 01218: LearningRateScheduler reducing learning rate to 2.9384952971909533e-05.
Epoch 1218/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1720 - lr: 2.9385e-05

Epoch 01219: LearningRateScheduler reducing learning rate to 2.925836139841215e-05.
Epoch 1219/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1683 - lr: 2.9258e-05

Epoch 01220: LearningRateScheduler reducing learning rate to 2.9132315186566206e-05.
Epoch 1220/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1704 - lr: 2.9132e-05

Epoch 01221: LearningRateScheduler reducing learning rate to 2.9006811986931526e-05.
Epoch 1221/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1715 - lr: 2.9007e-05

Epoch 01222: LearningRateScheduler reducing learning rate to 2.888184946018939e-05.
Epoch 1222/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1710 - lr: 2.8882e-05

Epoch 01223: LearningRateScheduler reducing learning rate to 2.8757425277098977e-05.
Epoch 1223/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1714 - lr: 2.8757e-05

Epoch 01224: LearningRateScheduler reducing learning rate to 2.863353711845392e-05.
Epoch 1224/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1681 - lr: 2.8634e-05

Epoch 01225: LearningRateScheduler reducing learning rate to 2.8510182675039083e-05.
Epoch 1225/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1705 - lr: 2.8510e-05

Epoch 01226: LearningRateScheduler reducing learning rate to 2.838735964758754e-05.
Epoch 1226/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1641 - lr: 2.8387e-05

Epoch 01227: LearningRateScheduler reducing learning rate to 2.8265065746737683e-05.
Epoch 1227/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1686 - lr: 2.8265e-05

Epoch 01228: LearningRateScheduler reducing learning rate to 2.8143298692990577e-05.
Epoch 1228/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1712 - lr: 2.8143e-05

Epoch 01229: LearningRateScheduler reducing learning rate to 2.802205621666746e-05.
Epoch 1229/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1590 - lr: 2.8022e-05

Epoch 01230: LearningRateScheduler reducing learning rate to 2.7901336057867433e-05.
Epoch 1230/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1680 - lr: 2.7901e-05

Epoch 01231: LearningRateScheduler reducing learning rate to 2.7781135966425348e-05.
Epoch 1231/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1689 - lr: 2.7781e-05

Epoch 01232: LearningRateScheduler reducing learning rate to 2.766145370186986e-05.
Epoch 1232/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1730 - lr: 2.7661e-05

Epoch 01233: LearningRateScheduler reducing learning rate to 2.754228703338166e-05.
Epoch 1233/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1648 - lr: 2.7542e-05

Epoch 01234: LearningRateScheduler reducing learning rate to 2.7423633739751904e-05.
Epoch 1234/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1678 - lr: 2.7424e-05

Epoch 01235: LearningRateScheduler reducing learning rate to 2.7305491609340808e-05.
Epoch 1235/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1773 - lr: 2.7305e-05

Epoch 01236: LearningRateScheduler reducing learning rate to 2.7187858440036418e-05.
Epoch 1236/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1680 - lr: 2.7188e-05

Epoch 01237: LearningRateScheduler reducing learning rate to 2.7070732039213566e-05.
Epoch 1237/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1669 - lr: 2.7071e-05

Epoch 01238: LearningRateScheduler reducing learning rate to 2.6954110223693013e-05.
Epoch 1238/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1679 - lr: 2.6954e-05

Epoch 01239: LearningRateScheduler reducing learning rate to 2.683799081970073e-05.
Epoch 1239/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1731 - lr: 2.6838e-05

Epoch 01240: LearningRateScheduler reducing learning rate to 2.672237166282741e-05.
Epoch 1240/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1688 - lr: 2.6722e-05

Epoch 01241: LearningRateScheduler reducing learning rate to 2.6607250597988095e-05.
Epoch 1241/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1629 - lr: 2.6607e-05

Epoch 01242: LearningRateScheduler reducing learning rate to 2.6492625479382033e-05.
Epoch 1242/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1673 - lr: 2.6493e-05

Epoch 01243: LearningRateScheduler reducing learning rate to 2.6378494170452653e-05.
Epoch 1243/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1669 - lr: 2.6378e-05

Epoch 01244: LearningRateScheduler reducing learning rate to 2.6264854543847787e-05.
Epoch 1244/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1747 - lr: 2.6265e-05

Epoch 01245: LearningRateScheduler reducing learning rate to 2.615170448137996e-05.
Epoch 1245/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1654 - lr: 2.6152e-05

Epoch 01246: LearningRateScheduler reducing learning rate to 2.603904187398694e-05.
Epoch 1246/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1627 - lr: 2.6039e-05

Epoch 01247: LearningRateScheduler reducing learning rate to 2.5926864621692424e-05.
Epoch 1247/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1715 - lr: 2.5927e-05

Epoch 01248: LearningRateScheduler reducing learning rate to 2.5815170633566893e-05.
Epoch 1248/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1705 - lr: 2.5815e-05

Epoch 01249: LearningRateScheduler reducing learning rate to 2.5703957827688628e-05.
Epoch 1249/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1708 - lr: 2.5704e-05

Epoch 01250: LearningRateScheduler reducing learning rate to 2.5593224131104935e-05.
Epoch 1250/4000
Model saved in ./model/scPDB_1221_pdbid--1250--0.1702--0.0000256.
24/24 - 3s - loss: 0.0626 - val_loss: 0.1702 - lr: 2.5593e-05

Epoch 01251: LearningRateScheduler reducing learning rate to 2.5482967479793457e-05.
Epoch 1251/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1656 - lr: 2.5483e-05

Epoch 01252: LearningRateScheduler reducing learning rate to 2.5373185818623756e-05.
Epoch 1252/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1694 - lr: 2.5373e-05

Epoch 01253: LearningRateScheduler reducing learning rate to 2.5263877101318958e-05.
Epoch 1253/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1652 - lr: 2.5264e-05

Epoch 01254: LearningRateScheduler reducing learning rate to 2.5155039290417645e-05.
Epoch 1254/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1716 - lr: 2.5155e-05

Epoch 01255: LearningRateScheduler reducing learning rate to 2.5046670357235868e-05.
Epoch 1255/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1651 - lr: 2.5047e-05

Epoch 01256: LearningRateScheduler reducing learning rate to 2.4938768281829317e-05.
Epoch 1256/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1665 - lr: 2.4939e-05

Epoch 01257: LearningRateScheduler reducing learning rate to 2.48313310529557e-05.
Epoch 1257/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1737 - lr: 2.4831e-05

Epoch 01258: LearningRateScheduler reducing learning rate to 2.4724356668037226e-05.
Epoch 1258/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1727 - lr: 2.4724e-05

Epoch 01259: LearningRateScheduler reducing learning rate to 2.46178431331233e-05.
Epoch 1259/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1708 - lr: 2.4618e-05

Epoch 01260: LearningRateScheduler reducing learning rate to 2.451178846285335e-05.
Epoch 1260/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1591 - lr: 2.4512e-05

Epoch 01261: LearningRateScheduler reducing learning rate to 2.44061906804198e-05.
Epoch 1261/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1742 - lr: 2.4406e-05

Epoch 01262: LearningRateScheduler reducing learning rate to 2.4301047817531263e-05.
Epoch 1262/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1630 - lr: 2.4301e-05

Epoch 01263: LearningRateScheduler reducing learning rate to 2.4196357914375814e-05.
Epoch 1263/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1693 - lr: 2.4196e-05

Epoch 01264: LearningRateScheduler reducing learning rate to 2.4092119019584494e-05.
Epoch 1264/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1721 - lr: 2.4092e-05

Epoch 01265: LearningRateScheduler reducing learning rate to 2.3988329190194904e-05.
Epoch 1265/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1631 - lr: 2.3988e-05

Epoch 01266: LearningRateScheduler reducing learning rate to 2.388498649161502e-05.
Epoch 1266/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1733 - lr: 2.3885e-05

Epoch 01267: LearningRateScheduler reducing learning rate to 2.3782088997587102e-05.
Epoch 1267/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1727 - lr: 2.3782e-05

Epoch 01268: LearningRateScheduler reducing learning rate to 2.3679634790151838e-05.
Epoch 1268/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1701 - lr: 2.3680e-05

Epoch 01269: LearningRateScheduler reducing learning rate to 2.3577621959612534e-05.
Epoch 1269/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1633 - lr: 2.3578e-05

Epoch 01270: LearningRateScheduler reducing learning rate to 2.3476048604499555e-05.
Epoch 1270/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1732 - lr: 2.3476e-05

Epoch 01271: LearningRateScheduler reducing learning rate to 2.337491283153488e-05.
Epoch 1271/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1640 - lr: 2.3375e-05

Epoch 01272: LearningRateScheduler reducing learning rate to 2.3274212755596792e-05.
Epoch 1272/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1628 - lr: 2.3274e-05

Epoch 01273: LearningRateScheduler reducing learning rate to 2.3173946499684777e-05.
Epoch 1273/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1715 - lr: 2.3174e-05

Epoch 01274: LearningRateScheduler reducing learning rate to 2.3074112194884503e-05.
Epoch 1274/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1678 - lr: 2.3074e-05

Epoch 01275: LearningRateScheduler reducing learning rate to 2.2974707980332993e-05.
Epoch 1275/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1688 - lr: 2.2975e-05

Epoch 01276: LearningRateScheduler reducing learning rate to 2.287573200318395e-05.
Epoch 1276/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1691 - lr: 2.2876e-05

Epoch 01277: LearningRateScheduler reducing learning rate to 2.2777182418573213e-05.
Epoch 1277/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1696 - lr: 2.2777e-05

Epoch 01278: LearningRateScheduler reducing learning rate to 2.2679057389584378e-05.
Epoch 1278/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1758 - lr: 2.2679e-05

Epoch 01279: LearningRateScheduler reducing learning rate to 2.2581355087214538e-05.
Epoch 1279/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1713 - lr: 2.2581e-05

Epoch 01280: LearningRateScheduler reducing learning rate to 2.248407369034021e-05.
Epoch 1280/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1650 - lr: 2.2484e-05

Epoch 01281: LearningRateScheduler reducing learning rate to 2.2387211385683393e-05.
Epoch 1281/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1702 - lr: 2.2387e-05

Epoch 01282: LearningRateScheduler reducing learning rate to 2.2290766367777745e-05.
Epoch 1282/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1710 - lr: 2.2291e-05

Epoch 01283: LearningRateScheduler reducing learning rate to 2.219473683893497e-05.
Epoch 1283/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1725 - lr: 2.2195e-05

Epoch 01284: LearningRateScheduler reducing learning rate to 2.2099121009211264e-05.
Epoch 1284/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1702 - lr: 2.2099e-05

Epoch 01285: LearningRateScheduler reducing learning rate to 2.2003917096373983e-05.
Epoch 1285/4000
24/24 - 3s - loss: 0.0634 - val_loss: 0.1705 - lr: 2.2004e-05

Epoch 01286: LearningRateScheduler reducing learning rate to 2.1909123325868414e-05.
Epoch 1286/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1663 - lr: 2.1909e-05

Epoch 01287: LearningRateScheduler reducing learning rate to 2.18147379307847e-05.
Epoch 1287/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1713 - lr: 2.1815e-05

Epoch 01288: LearningRateScheduler reducing learning rate to 2.17207591518249e-05.
Epoch 1288/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1688 - lr: 2.1721e-05

Epoch 01289: LearningRateScheduler reducing learning rate to 2.16271852372702e-05.
Epoch 1289/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1701 - lr: 2.1627e-05

Epoch 01290: LearningRateScheduler reducing learning rate to 2.1534014442948266e-05.
Epoch 1290/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1710 - lr: 2.1534e-05

Epoch 01291: LearningRateScheduler reducing learning rate to 2.1441245032200713e-05.
Epoch 1291/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1722 - lr: 2.1441e-05

Epoch 01292: LearningRateScheduler reducing learning rate to 2.1348875275850787e-05.
Epoch 1292/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1707 - lr: 2.1349e-05

Epoch 01293: LearningRateScheduler reducing learning rate to 2.125690345217106e-05.
Epoch 1293/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1684 - lr: 2.1257e-05

Epoch 01294: LearningRateScheduler reducing learning rate to 2.11653278468514e-05.
Epoch 1294/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1743 - lr: 2.1165e-05

Epoch 01295: LearningRateScheduler reducing learning rate to 2.1074146752966975e-05.
Epoch 1295/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1708 - lr: 2.1074e-05

Epoch 01296: LearningRateScheduler reducing learning rate to 2.0983358470946475e-05.
Epoch 1296/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1714 - lr: 2.0983e-05

Epoch 01297: LearningRateScheduler reducing learning rate to 2.0892961308540385e-05.
Epoch 1297/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1732 - lr: 2.0893e-05

Epoch 01298: LearningRateScheduler reducing learning rate to 2.08029535807895e-05.
Epoch 1298/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1659 - lr: 2.0803e-05

Epoch 01299: LearningRateScheduler reducing learning rate to 2.071333360999347e-05.
Epoch 1299/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1660 - lr: 2.0713e-05

Epoch 01300: LearningRateScheduler reducing learning rate to 2.062409972567955e-05.
Epoch 1300/4000
Model saved in ./model/scPDB_1221_pdbid--1300--0.1668--0.0000206.
24/24 - 3s - loss: 0.0626 - val_loss: 0.1668 - lr: 2.0624e-05

Epoch 01301: LearningRateScheduler reducing learning rate to 2.0535250264571452e-05.
Epoch 1301/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1715 - lr: 2.0535e-05

Epoch 01302: LearningRateScheduler reducing learning rate to 2.044678357055837e-05.
Epoch 1302/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1672 - lr: 2.0447e-05

Epoch 01303: LearningRateScheduler reducing learning rate to 2.0358697994664072e-05.
Epoch 1303/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1681 - lr: 2.0359e-05

Epoch 01304: LearningRateScheduler reducing learning rate to 2.027099189501619e-05.
Epoch 1304/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1718 - lr: 2.0271e-05

Epoch 01305: LearningRateScheduler reducing learning rate to 2.0183663636815606e-05.
Epoch 1305/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1688 - lr: 2.0184e-05

Epoch 01306: LearningRateScheduler reducing learning rate to 2.0096711592305986e-05.
Epoch 1306/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1771 - lr: 2.0097e-05

Epoch 01307: LearningRateScheduler reducing learning rate to 2.001013414074344e-05.
Epoch 1307/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1653 - lr: 2.0010e-05

Epoch 01308: LearningRateScheduler reducing learning rate to 1.99239296683663e-05.
Epoch 1308/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1727 - lr: 1.9924e-05

Epoch 01309: LearningRateScheduler reducing learning rate to 1.9838096568365052e-05.
Epoch 1309/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1694 - lr: 1.9838e-05

Epoch 01310: LearningRateScheduler reducing learning rate to 1.9752633240852394e-05.
Epoch 1310/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1696 - lr: 1.9753e-05

Epoch 01311: LearningRateScheduler reducing learning rate to 1.9667538092833383e-05.
Epoch 1311/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1720 - lr: 1.9668e-05

Epoch 01312: LearningRateScheduler reducing learning rate to 1.9582809538175776e-05.
Epoch 1312/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1769 - lr: 1.9583e-05

Epoch 01313: LearningRateScheduler reducing learning rate to 1.9498445997580452e-05.
Epoch 1313/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1666 - lr: 1.9498e-05

Epoch 01314: LearningRateScheduler reducing learning rate to 1.9414445898551976e-05.
Epoch 1314/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1666 - lr: 1.9414e-05

Epoch 01315: LearningRateScheduler reducing learning rate to 1.9330807675369276e-05.
Epoch 1315/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1616 - lr: 1.9331e-05

Epoch 01316: LearningRateScheduler reducing learning rate to 1.9247529769056477e-05.
Epoch 1316/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1749 - lr: 1.9248e-05

Epoch 01317: LearningRateScheduler reducing learning rate to 1.9164610627353855e-05.
Epoch 1317/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1764 - lr: 1.9165e-05

Epoch 01318: LearningRateScheduler reducing learning rate to 1.9082048704688853e-05.
Epoch 1318/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1695 - lr: 1.9082e-05

Epoch 01319: LearningRateScheduler reducing learning rate to 1.899984246214732e-05.
Epoch 1319/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1638 - lr: 1.9000e-05

Epoch 01320: LearningRateScheduler reducing learning rate to 1.8917990367444804e-05.
Epoch 1320/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1696 - lr: 1.8918e-05

Epoch 01321: LearningRateScheduler reducing learning rate to 1.8836490894897997e-05.
Epoch 1321/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1648 - lr: 1.8836e-05

Epoch 01322: LearningRateScheduler reducing learning rate to 1.8755342525396304e-05.
Epoch 1322/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1736 - lr: 1.8755e-05

Epoch 01323: LearningRateScheduler reducing learning rate to 1.8674543746373513e-05.
Epoch 1323/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1678 - lr: 1.8675e-05

Epoch 01324: LearningRateScheduler reducing learning rate to 1.8594093051779615e-05.
Epoch 1324/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1569 - lr: 1.8594e-05

Epoch 01325: LearningRateScheduler reducing learning rate to 1.8513988942052713e-05.
Epoch 1325/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1833 - lr: 1.8514e-05

Epoch 01326: LearningRateScheduler reducing learning rate to 1.84342299240911e-05.
Epoch 1326/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1691 - lr: 1.8434e-05

Epoch 01327: LearningRateScheduler reducing learning rate to 1.83548145112254e-05.
Epoch 1327/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1685 - lr: 1.8355e-05

Epoch 01328: LearningRateScheduler reducing learning rate to 1.827574122319088e-05.
Epoch 1328/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1717 - lr: 1.8276e-05

Epoch 01329: LearningRateScheduler reducing learning rate to 1.819700858609983e-05.
Epoch 1329/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1681 - lr: 1.8197e-05

Epoch 01330: LearningRateScheduler reducing learning rate to 1.811861513241413e-05.
Epoch 1330/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1648 - lr: 1.8119e-05

Epoch 01331: LearningRateScheduler reducing learning rate to 1.804055940091786e-05.
Epoch 1331/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1694 - lr: 1.8041e-05

Epoch 01332: LearningRateScheduler reducing learning rate to 1.796283993669008e-05.
Epoch 1332/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1668 - lr: 1.7963e-05

Epoch 01333: LearningRateScheduler reducing learning rate to 1.7885455291077713e-05.
Epoch 1333/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1688 - lr: 1.7885e-05

Epoch 01334: LearningRateScheduler reducing learning rate to 1.7808404021668527e-05.
Epoch 1334/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1721 - lr: 1.7808e-05

Epoch 01335: LearningRateScheduler reducing learning rate to 1.773168469226428e-05.
Epoch 1335/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1692 - lr: 1.7732e-05

Epoch 01336: LearningRateScheduler reducing learning rate to 1.7655295872853916e-05.
Epoch 1336/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1685 - lr: 1.7655e-05

Epoch 01337: LearningRateScheduler reducing learning rate to 1.7579236139586924e-05.
Epoch 1337/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1702 - lr: 1.7579e-05

Epoch 01338: LearningRateScheduler reducing learning rate to 1.7503504074746806e-05.
Epoch 1338/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1671 - lr: 1.7504e-05

Epoch 01339: LearningRateScheduler reducing learning rate to 1.7428098266724642e-05.
Epoch 1339/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1771 - lr: 1.7428e-05

Epoch 01340: LearningRateScheduler reducing learning rate to 1.7353017309992776e-05.
Epoch 1340/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1611 - lr: 1.7353e-05

Epoch 01341: LearningRateScheduler reducing learning rate to 1.7278259805078634e-05.
Epoch 1341/4000
24/24 - 3s - loss: 0.0636 - val_loss: 0.1760 - lr: 1.7278e-05

Epoch 01342: LearningRateScheduler reducing learning rate to 1.7203824358538613e-05.
Epoch 1342/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1672 - lr: 1.7204e-05

Epoch 01343: LearningRateScheduler reducing learning rate to 1.712970958293213e-05.
Epoch 1343/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1681 - lr: 1.7130e-05

Epoch 01344: LearningRateScheduler reducing learning rate to 1.7055914096795753e-05.
Epoch 1344/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1724 - lr: 1.7056e-05

Epoch 01345: LearningRateScheduler reducing learning rate to 1.6982436524617442e-05.
Epoch 1345/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1632 - lr: 1.6982e-05

Epoch 01346: LearningRateScheduler reducing learning rate to 1.6909275496810935e-05.
Epoch 1346/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1735 - lr: 1.6909e-05

Epoch 01347: LearningRateScheduler reducing learning rate to 1.6836429649690184e-05.
Epoch 1347/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1623 - lr: 1.6836e-05

Epoch 01348: LearningRateScheduler reducing learning rate to 1.676389762544397e-05.
Epoch 1348/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1647 - lr: 1.6764e-05

Epoch 01349: LearningRateScheduler reducing learning rate to 1.669167807211058e-05.
Epoch 1349/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1716 - lr: 1.6692e-05

Epoch 01350: LearningRateScheduler reducing learning rate to 1.6619769643552592e-05.
Epoch 1350/4000
Model saved in ./model/scPDB_1221_pdbid--1350--0.1673--0.0000166.
24/24 - 17s - loss: 0.0617 - val_loss: 0.1673 - lr: 1.6620e-05

Epoch 01351: LearningRateScheduler reducing learning rate to 1.6548170999431816e-05.
Epoch 1351/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1724 - lr: 1.6548e-05

Epoch 01352: LearningRateScheduler reducing learning rate to 1.647688080518427e-05.
Epoch 1352/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1628 - lr: 1.6477e-05

Epoch 01353: LearningRateScheduler reducing learning rate to 1.640589773199538e-05.
Epoch 1353/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1755 - lr: 1.6406e-05

Epoch 01354: LearningRateScheduler reducing learning rate to 1.6335220456775104e-05.
Epoch 1354/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1670 - lr: 1.6335e-05

Epoch 01355: LearningRateScheduler reducing learning rate to 1.626484766213335e-05.
Epoch 1355/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1836 - lr: 1.6265e-05

Epoch 01356: LearningRateScheduler reducing learning rate to 1.6194778036355382e-05.
Epoch 1356/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1675 - lr: 1.6195e-05

Epoch 01357: LearningRateScheduler reducing learning rate to 1.6125010273377407e-05.
Epoch 1357/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1762 - lr: 1.6125e-05

Epoch 01358: LearningRateScheduler reducing learning rate to 1.6055543072762187e-05.
Epoch 1358/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1692 - lr: 1.6056e-05

Epoch 01359: LearningRateScheduler reducing learning rate to 1.598637513967483e-05.
Epoch 1359/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1646 - lr: 1.5986e-05

Epoch 01360: LearningRateScheduler reducing learning rate to 1.5917505184858654e-05.
Epoch 1360/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1720 - lr: 1.5918e-05

Epoch 01361: LearningRateScheduler reducing learning rate to 1.5848931924611128e-05.
Epoch 1361/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1712 - lr: 1.5849e-05

Epoch 01362: LearningRateScheduler reducing learning rate to 1.5780654080759974e-05.
Epoch 1362/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1721 - lr: 1.5781e-05

Epoch 01363: LearningRateScheduler reducing learning rate to 1.5712670380639335e-05.
Epoch 1363/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1663 - lr: 1.5713e-05

Epoch 01364: LearningRateScheduler reducing learning rate to 1.5644979557066044e-05.
Epoch 1364/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1755 - lr: 1.5645e-05

Epoch 01365: LearningRateScheduler reducing learning rate to 1.5577580348316014e-05.
Epoch 1365/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1661 - lr: 1.5578e-05

Epoch 01366: LearningRateScheduler reducing learning rate to 1.551047149810072e-05.
Epoch 1366/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1651 - lr: 1.5510e-05

Epoch 01367: LearningRateScheduler reducing learning rate to 1.5443651755543775e-05.
Epoch 1367/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1690 - lr: 1.5444e-05

Epoch 01368: LearningRateScheduler reducing learning rate to 1.5377119875157617e-05.
Epoch 1368/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1669 - lr: 1.5377e-05

Epoch 01369: LearningRateScheduler reducing learning rate to 1.5310874616820297e-05.
Epoch 1369/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1674 - lr: 1.5311e-05

Epoch 01370: LearningRateScheduler reducing learning rate to 1.524491474575236e-05.
Epoch 1370/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1706 - lr: 1.5245e-05

Epoch 01371: LearningRateScheduler reducing learning rate to 1.5179239032493834e-05.
Epoch 1371/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1679 - lr: 1.5179e-05

Epoch 01372: LearningRateScheduler reducing learning rate to 1.5113846252881314e-05.
Epoch 1372/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1731 - lr: 1.5114e-05

Epoch 01373: LearningRateScheduler reducing learning rate to 1.5048735188025132e-05.
Epoch 1373/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1690 - lr: 1.5049e-05

Epoch 01374: LearningRateScheduler reducing learning rate to 1.4983904624286652e-05.
Epoch 1374/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1642 - lr: 1.4984e-05

Epoch 01375: LearningRateScheduler reducing learning rate to 1.491935335325564e-05.
Epoch 1375/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1749 - lr: 1.4919e-05

Epoch 01376: LearningRateScheduler reducing learning rate to 1.4855080171727746e-05.
Epoch 1376/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1563 - lr: 1.4855e-05

Epoch 01377: LearningRateScheduler reducing learning rate to 1.479108388168207e-05.
Epoch 1377/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1735 - lr: 1.4791e-05

Epoch 01378: LearningRateScheduler reducing learning rate to 1.4727363290258837e-05.
Epoch 1378/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1724 - lr: 1.4727e-05

Epoch 01379: LearningRateScheduler reducing learning rate to 1.4663917209737157e-05.
Epoch 1379/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1672 - lr: 1.4664e-05

Epoch 01380: LearningRateScheduler reducing learning rate to 1.4600744457512892e-05.
Epoch 1380/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1798 - lr: 1.4601e-05

Epoch 01381: LearningRateScheduler reducing learning rate to 1.4537843856076616e-05.
Epoch 1381/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1699 - lr: 1.4538e-05

Epoch 01382: LearningRateScheduler reducing learning rate to 1.447521423299165e-05.
Epoch 1382/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1640 - lr: 1.4475e-05

Epoch 01383: LearningRateScheduler reducing learning rate to 1.4412854420872235e-05.
Epoch 1383/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1756 - lr: 1.4413e-05

Epoch 01384: LearningRateScheduler reducing learning rate to 1.4350763257361739e-05.
Epoch 1384/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1721 - lr: 1.4351e-05

Epoch 01385: LearningRateScheduler reducing learning rate to 1.4288939585111027e-05.
Epoch 1385/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1715 - lr: 1.4289e-05

Epoch 01386: LearningRateScheduler reducing learning rate to 1.422738225175686e-05.
Epoch 1386/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1701 - lr: 1.4227e-05

Epoch 01387: LearningRateScheduler reducing learning rate to 1.4166090109900434e-05.
Epoch 1387/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1719 - lr: 1.4166e-05

Epoch 01388: LearningRateScheduler reducing learning rate to 1.4105062017085979e-05.
Epoch 1388/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1684 - lr: 1.4105e-05

Epoch 01389: LearningRateScheduler reducing learning rate to 1.4044296835779475e-05.
Epoch 1389/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1717 - lr: 1.4044e-05

Epoch 01390: LearningRateScheduler reducing learning rate to 1.3983793433347445e-05.
Epoch 1390/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1687 - lr: 1.3984e-05

Epoch 01391: LearningRateScheduler reducing learning rate to 1.3923550682035842e-05.
Epoch 1391/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1798 - lr: 1.3924e-05

Epoch 01392: LearningRateScheduler reducing learning rate to 1.3863567458949028e-05.
Epoch 1392/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1662 - lr: 1.3864e-05

Epoch 01393: LearningRateScheduler reducing learning rate to 1.3803842646028849e-05.
Epoch 1393/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1694 - lr: 1.3804e-05

Epoch 01394: LearningRateScheduler reducing learning rate to 1.3744375130033788e-05.
Epoch 1394/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1665 - lr: 1.3744e-05

Epoch 01395: LearningRateScheduler reducing learning rate to 1.3685163802518218e-05.
Epoch 1395/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1731 - lr: 1.3685e-05

Epoch 01396: LearningRateScheduler reducing learning rate to 1.3626207559811741e-05.
Epoch 1396/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1653 - lr: 1.3626e-05

Epoch 01397: LearningRateScheduler reducing learning rate to 1.3567505302998619e-05.
Epoch 1397/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1694 - lr: 1.3568e-05

Epoch 01398: LearningRateScheduler reducing learning rate to 1.350905593789728e-05.
Epoch 1398/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1757 - lr: 1.3509e-05

Epoch 01399: LearningRateScheduler reducing learning rate to 1.3450858375039942e-05.
Epoch 1399/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1729 - lr: 1.3451e-05

Epoch 01400: LearningRateScheduler reducing learning rate to 1.3392911529652282e-05.
Epoch 1400/4000
Model saved in ./model/scPDB_1221_pdbid--1400--0.1690--0.0000134.
24/24 - 18s - loss: 0.0624 - val_loss: 0.1690 - lr: 1.3393e-05

Epoch 01401: LearningRateScheduler reducing learning rate to 1.333521432163323e-05.
Epoch 1401/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1680 - lr: 1.3335e-05

Epoch 01402: LearningRateScheduler reducing learning rate to 1.3277765675534862e-05.
Epoch 1402/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1715 - lr: 1.3278e-05

Epoch 01403: LearningRateScheduler reducing learning rate to 1.322056452054229e-05.
Epoch 1403/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1714 - lr: 1.3221e-05

Epoch 01404: LearningRateScheduler reducing learning rate to 1.3163609790453764e-05.
Epoch 1404/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1678 - lr: 1.3164e-05

Epoch 01405: LearningRateScheduler reducing learning rate to 1.3106900423660759e-05.
Epoch 1405/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1664 - lr: 1.3107e-05

Epoch 01406: LearningRateScheduler reducing learning rate to 1.3050435363128215e-05.
Epoch 1406/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1690 - lr: 1.3050e-05

Epoch 01407: LearningRateScheduler reducing learning rate to 1.2994213556374819e-05.
Epoch 1407/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1665 - lr: 1.2994e-05

Epoch 01408: LearningRateScheduler reducing learning rate to 1.2938233955453386e-05.
Epoch 1408/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1704 - lr: 1.2938e-05

Epoch 01409: LearningRateScheduler reducing learning rate to 1.2882495516931332e-05.
Epoch 1409/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1693 - lr: 1.2882e-05

Epoch 01410: LearningRateScheduler reducing learning rate to 1.2826997201871227e-05.
Epoch 1410/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1755 - lr: 1.2827e-05

Epoch 01411: LearningRateScheduler reducing learning rate to 1.2771737975811423e-05.
Epoch 1411/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1692 - lr: 1.2772e-05

Epoch 01412: LearningRateScheduler reducing learning rate to 1.2716716808746772e-05.
Epoch 1412/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1726 - lr: 1.2717e-05

Epoch 01413: LearningRateScheduler reducing learning rate to 1.2661932675109436e-05.
Epoch 1413/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1659 - lr: 1.2662e-05

Epoch 01414: LearningRateScheduler reducing learning rate to 1.260738455374976e-05.
Epoch 1414/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1722 - lr: 1.2607e-05

Epoch 01415: LearningRateScheduler reducing learning rate to 1.2553071427917244e-05.
Epoch 1415/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1721 - lr: 1.2553e-05

Epoch 01416: LearningRateScheduler reducing learning rate to 1.2498992285241594e-05.
Epoch 1416/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1710 - lr: 1.2499e-05

Epoch 01417: LearningRateScheduler reducing learning rate to 1.2445146117713845e-05.
Epoch 1417/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1739 - lr: 1.2445e-05

Epoch 01418: LearningRateScheduler reducing learning rate to 1.2391531921667578e-05.
Epoch 1418/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1707 - lr: 1.2392e-05

Epoch 01419: LearningRateScheduler reducing learning rate to 1.2338148697760207e-05.
Epoch 1419/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1724 - lr: 1.2338e-05

Epoch 01420: LearningRateScheduler reducing learning rate to 1.2284995450954356e-05.
Epoch 1420/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1696 - lr: 1.2285e-05

Epoch 01421: LearningRateScheduler reducing learning rate to 1.2232071190499312e-05.
Epoch 1421/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1668 - lr: 1.2232e-05

Epoch 01422: LearningRateScheduler reducing learning rate to 1.2179374929912552e-05.
Epoch 1422/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1742 - lr: 1.2179e-05

Epoch 01423: LearningRateScheduler reducing learning rate to 1.2126905686961367e-05.
Epoch 1423/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1677 - lr: 1.2127e-05

Epoch 01424: LearningRateScheduler reducing learning rate to 1.207466248364454e-05.
Epoch 1424/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1781 - lr: 1.2075e-05

Epoch 01425: LearningRateScheduler reducing learning rate to 1.2022644346174125e-05.
Epoch 1425/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1644 - lr: 1.2023e-05

Epoch 01426: LearningRateScheduler reducing learning rate to 1.1970850304957296e-05.
Epoch 1426/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1733 - lr: 1.1971e-05

Epoch 01427: LearningRateScheduler reducing learning rate to 1.1919279394578271e-05.
Epoch 1427/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1617 - lr: 1.1919e-05

Epoch 01428: LearningRateScheduler reducing learning rate to 1.1867930653780316e-05.
Epoch 1428/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1661 - lr: 1.1868e-05

Epoch 01429: LearningRateScheduler reducing learning rate to 1.1816803125447834e-05.
Epoch 1429/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1694 - lr: 1.1817e-05

Epoch 01430: LearningRateScheduler reducing learning rate to 1.1765895856588519e-05.
Epoch 1430/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1678 - lr: 1.1766e-05

Epoch 01431: LearningRateScheduler reducing learning rate to 1.1715207898315598e-05.
Epoch 1431/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1751 - lr: 1.1715e-05

Epoch 01432: LearningRateScheduler reducing learning rate to 1.1664738305830134e-05.
Epoch 1432/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1666 - lr: 1.1665e-05

Epoch 01433: LearningRateScheduler reducing learning rate to 1.1614486138403426e-05.
Epoch 1433/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1748 - lr: 1.1614e-05

Epoch 01434: LearningRateScheduler reducing learning rate to 1.1564450459359473e-05.
Epoch 1434/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1664 - lr: 1.1564e-05

Epoch 01435: LearningRateScheduler reducing learning rate to 1.151463033605751e-05.
Epoch 1435/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1693 - lr: 1.1515e-05

Epoch 01436: LearningRateScheduler reducing learning rate to 1.1465024839874626e-05.
Epoch 1436/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1676 - lr: 1.1465e-05

Epoch 01437: LearningRateScheduler reducing learning rate to 1.1415633046188456e-05.
Epoch 1437/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1745 - lr: 1.1416e-05

Epoch 01438: LearningRateScheduler reducing learning rate to 1.1366454034359944e-05.
Epoch 1438/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1667 - lr: 1.1366e-05

Epoch 01439: LearningRateScheduler reducing learning rate to 1.1317486887716188e-05.
Epoch 1439/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1631 - lr: 1.1317e-05

Epoch 01440: LearningRateScheduler reducing learning rate to 1.1268730693533348e-05.
Epoch 1440/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1697 - lr: 1.1269e-05

Epoch 01441: LearningRateScheduler reducing learning rate to 1.1220184543019633e-05.
Epoch 1441/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1716 - lr: 1.1220e-05

Epoch 01442: LearningRateScheduler reducing learning rate to 1.1171847531298373e-05.
Epoch 1442/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1760 - lr: 1.1172e-05

Epoch 01443: LearningRateScheduler reducing learning rate to 1.1123718757391131e-05.
Epoch 1443/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1728 - lr: 1.1124e-05

Epoch 01444: LearningRateScheduler reducing learning rate to 1.1075797324200929e-05.
Epoch 1444/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1708 - lr: 1.1076e-05

Epoch 01445: LearningRateScheduler reducing learning rate to 1.102808233849552e-05.
Epoch 1445/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1711 - lr: 1.1028e-05

Epoch 01446: LearningRateScheduler reducing learning rate to 1.0980572910890735e-05.
Epoch 1446/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1725 - lr: 1.0981e-05

Epoch 01447: LearningRateScheduler reducing learning rate to 1.0933268155833913e-05.
Epoch 1447/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1643 - lr: 1.0933e-05

Epoch 01448: LearningRateScheduler reducing learning rate to 1.0886167191587383e-05.
Epoch 1448/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1704 - lr: 1.0886e-05

Epoch 01449: LearningRateScheduler reducing learning rate to 1.0839269140212037e-05.
Epoch 1449/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1742 - lr: 1.0839e-05

Epoch 01450: LearningRateScheduler reducing learning rate to 1.0792573127550961e-05.
Epoch 1450/4000
Model saved in ./model/scPDB_1221_pdbid--1450--0.1686--0.0000108.
24/24 - 3s - loss: 0.0624 - val_loss: 0.1686 - lr: 1.0793e-05

Epoch 01451: LearningRateScheduler reducing learning rate to 1.0746078283213167e-05.
Epoch 1451/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1738 - lr: 1.0746e-05

Epoch 01452: LearningRateScheduler reducing learning rate to 1.0699783740557322e-05.
Epoch 1452/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1621 - lr: 1.0700e-05

Epoch 01453: LearningRateScheduler reducing learning rate to 1.0653688636675625e-05.
Epoch 1453/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1735 - lr: 1.0654e-05

Epoch 01454: LearningRateScheduler reducing learning rate to 1.0607792112377721e-05.
Epoch 1454/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1744 - lr: 1.0608e-05

Epoch 01455: LearningRateScheduler reducing learning rate to 1.0562093312174678e-05.
Epoch 1455/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1586 - lr: 1.0562e-05

Epoch 01456: LearningRateScheduler reducing learning rate to 1.0516591384263051e-05.
Epoch 1456/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1648 - lr: 1.0517e-05

Epoch 01457: LearningRateScheduler reducing learning rate to 1.0471285480508989e-05.
Epoch 1457/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1681 - lr: 1.0471e-05

Epoch 01458: LearningRateScheduler reducing learning rate to 1.0426174756432446e-05.
Epoch 1458/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1820 - lr: 1.0426e-05

Epoch 01459: LearningRateScheduler reducing learning rate to 1.0381258371191425e-05.
Epoch 1459/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1606 - lr: 1.0381e-05

Epoch 01460: LearningRateScheduler reducing learning rate to 1.0336535487566314e-05.
Epoch 1460/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1828 - lr: 1.0337e-05

Epoch 01461: LearningRateScheduler reducing learning rate to 1.0292005271944276e-05.
Epoch 1461/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1710 - lr: 1.0292e-05

Epoch 01462: LearningRateScheduler reducing learning rate to 1.0247666894303708e-05.
Epoch 1462/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1743 - lr: 1.0248e-05

Epoch 01463: LearningRateScheduler reducing learning rate to 1.020351952819878e-05.
Epoch 1463/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1628 - lr: 1.0204e-05

Epoch 01464: LearningRateScheduler reducing learning rate to 1.015956235074402e-05.
Epoch 1464/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1670 - lr: 1.0160e-05

Epoch 01465: LearningRateScheduler reducing learning rate to 1.0115794542598982e-05.
Epoch 1465/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1750 - lr: 1.0116e-05

Epoch 01466: LearningRateScheduler reducing learning rate to 1.007221528795297e-05.
Epoch 1466/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1626 - lr: 1.0072e-05

Epoch 01467: LearningRateScheduler reducing learning rate to 1.0028823774509838e-05.
Epoch 1467/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1695 - lr: 1.0029e-05

Epoch 01468: LearningRateScheduler reducing learning rate to 9.98561919347284e-06.
Epoch 1468/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1664 - lr: 9.9856e-06

Epoch 01469: LearningRateScheduler reducing learning rate to 9.942600739529562e-06.
Epoch 1469/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1697 - lr: 9.9426e-06

Epoch 01470: LearningRateScheduler reducing learning rate to 9.89976761083691e-06.
Epoch 1470/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1706 - lr: 9.8998e-06

Epoch 01471: LearningRateScheduler reducing learning rate to 9.857119009006159e-06.
Epoch 1471/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1698 - lr: 9.8571e-06

Epoch 01472: LearningRateScheduler reducing learning rate to 9.814654139088075e-06.
Epoch 1472/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1682 - lr: 9.8147e-06

Epoch 01473: LearningRateScheduler reducing learning rate to 9.772372209558104e-06.
Epoch 1473/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1712 - lr: 9.7724e-06

Epoch 01474: LearningRateScheduler reducing learning rate to 9.730272432301604e-06.
Epoch 1474/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1702 - lr: 9.7303e-06

Epoch 01475: LearningRateScheduler reducing learning rate to 9.688354022599167e-06.
Epoch 1475/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1677 - lr: 9.6884e-06

Epoch 01476: LearningRateScheduler reducing learning rate to 9.64661619911199e-06.
Epoch 1476/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1738 - lr: 9.6466e-06

Epoch 01477: LearningRateScheduler reducing learning rate to 9.605058183867303e-06.
Epoch 1477/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1704 - lr: 9.6051e-06

Epoch 01478: LearningRateScheduler reducing learning rate to 9.563679202243884e-06.
Epoch 1478/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1791 - lr: 9.5637e-06

Epoch 01479: LearningRateScheduler reducing learning rate to 9.522478482957599e-06.
Epoch 1479/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1675 - lr: 9.5225e-06

Epoch 01480: LearningRateScheduler reducing learning rate to 9.481455258047047e-06.
Epoch 1480/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1756 - lr: 9.4815e-06

Epoch 01481: LearningRateScheduler reducing learning rate to 9.440608762859232e-06.
Epoch 1481/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1691 - lr: 9.4406e-06

Epoch 01482: LearningRateScheduler reducing learning rate to 9.399938236035314e-06.
Epoch 1482/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1707 - lr: 9.3999e-06

Epoch 01483: LearningRateScheduler reducing learning rate to 9.359442919496422e-06.
Epoch 1483/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1719 - lr: 9.3594e-06

Epoch 01484: LearningRateScheduler reducing learning rate to 9.319122058429512e-06.
Epoch 1484/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1666 - lr: 9.3191e-06

Epoch 01485: LearningRateScheduler reducing learning rate to 9.27897490127331e-06.
Epoch 1485/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1691 - lr: 9.2790e-06

Epoch 01486: LearningRateScheduler reducing learning rate to 9.239000699704303e-06.
Epoch 1486/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1606 - lr: 9.2390e-06

Epoch 01487: LearningRateScheduler reducing learning rate to 9.199198708622774e-06.
Epoch 1487/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1749 - lr: 9.1992e-06

Epoch 01488: LearningRateScheduler reducing learning rate to 9.15956818613894e-06.
Epoch 1488/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1767 - lr: 9.1596e-06

Epoch 01489: LearningRateScheduler reducing learning rate to 9.120108393559096e-06.
Epoch 1489/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1623 - lr: 9.1201e-06

Epoch 01490: LearningRateScheduler reducing learning rate to 9.080818595371873e-06.
Epoch 1490/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1836 - lr: 9.0808e-06

Epoch 01491: LearningRateScheduler reducing learning rate to 9.041698059234504e-06.
Epoch 1491/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1706 - lr: 9.0417e-06

Epoch 01492: LearningRateScheduler reducing learning rate to 9.00274605595919e-06.
Epoch 1492/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1697 - lr: 9.0027e-06

Epoch 01493: LearningRateScheduler reducing learning rate to 8.963961859499501e-06.
Epoch 1493/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1811 - lr: 8.9640e-06

Epoch 01494: LearningRateScheduler reducing learning rate to 8.925344746936842e-06.
Epoch 1494/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1632 - lr: 8.9253e-06

Epoch 01495: LearningRateScheduler reducing learning rate to 8.886893998466989e-06.
Epoch 1495/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1655 - lr: 8.8869e-06

Epoch 01496: LearningRateScheduler reducing learning rate to 8.848608897386654e-06.
Epoch 1496/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1677 - lr: 8.8486e-06

Epoch 01497: LearningRateScheduler reducing learning rate to 8.810488730080142e-06.
Epoch 1497/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1692 - lr: 8.8105e-06

Epoch 01498: LearningRateScheduler reducing learning rate to 8.772532786006041e-06.
Epoch 1498/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1747 - lr: 8.7725e-06

Epoch 01499: LearningRateScheduler reducing learning rate to 8.734740357683976e-06.
Epoch 1499/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1697 - lr: 8.7347e-06

Epoch 01500: LearningRateScheduler reducing learning rate to 8.697110740681444e-06.
Epoch 1500/4000
Model saved in ./model/scPDB_1221_pdbid--1500--0.1672--0.0000087.
24/24 - 6s - loss: 0.0626 - val_loss: 0.1672 - lr: 8.6971e-06

Epoch 01501: LearningRateScheduler reducing learning rate to 8.659643233600647e-06.
Epoch 1501/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1777 - lr: 8.6596e-06

Epoch 01502: LearningRateScheduler reducing learning rate to 8.622337138065444e-06.
Epoch 1502/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1671 - lr: 8.6223e-06

Epoch 01503: LearningRateScheduler reducing learning rate to 8.585191758708325e-06.
Epoch 1503/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1667 - lr: 8.5852e-06

Epoch 01504: LearningRateScheduler reducing learning rate to 8.548206403157453e-06.
Epoch 1504/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1760 - lr: 8.5482e-06

Epoch 01505: LearningRateScheduler reducing learning rate to 8.511380382023758e-06.
Epoch 1505/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1642 - lr: 8.5114e-06

Epoch 01506: LearningRateScheduler reducing learning rate to 8.474713008888087e-06.
Epoch 1506/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1704 - lr: 8.4747e-06

Epoch 01507: LearningRateScheduler reducing learning rate to 8.438203600288402e-06.
Epoch 1507/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1711 - lr: 8.4382e-06

Epoch 01508: LearningRateScheduler reducing learning rate to 8.401851475707057e-06.
Epoch 1508/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1688 - lr: 8.4019e-06

Epoch 01509: LearningRateScheduler reducing learning rate to 8.365655957558096e-06.
Epoch 1509/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1714 - lr: 8.3657e-06

Epoch 01510: LearningRateScheduler reducing learning rate to 8.329616371174635e-06.
Epoch 1510/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1659 - lr: 8.3296e-06

Epoch 01511: LearningRateScheduler reducing learning rate to 8.29373204479628e-06.
Epoch 1511/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1792 - lr: 8.2937e-06

Epoch 01512: LearningRateScheduler reducing learning rate to 8.25800230955661e-06.
Epoch 1512/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1763 - lr: 8.2580e-06

Epoch 01513: LearningRateScheduler reducing learning rate to 8.222426499470708e-06.
Epoch 1513/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1768 - lr: 8.2224e-06

Epoch 01514: LearningRateScheduler reducing learning rate to 8.187003951422742e-06.
Epoch 1514/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1605 - lr: 8.1870e-06

Epoch 01515: LearningRateScheduler reducing learning rate to 8.151734005153621e-06.
Epoch 1515/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1750 - lr: 8.1517e-06

Epoch 01516: LearningRateScheduler reducing learning rate to 8.116616003248664e-06.
Epoch 1516/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1692 - lr: 8.1166e-06

Epoch 01517: LearningRateScheduler reducing learning rate to 8.08164929112537e-06.
Epoch 1517/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1741 - lr: 8.0816e-06

Epoch 01518: LearningRateScheduler reducing learning rate to 8.046833217021196e-06.
Epoch 1518/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1724 - lr: 8.0468e-06

Epoch 01519: LearningRateScheduler reducing learning rate to 8.01216713198143e-06.
Epoch 1519/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1711 - lr: 8.0122e-06

Epoch 01520: LearningRateScheduler reducing learning rate to 7.977650389847075e-06.
Epoch 1520/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1690 - lr: 7.9777e-06

Epoch 01521: LearningRateScheduler reducing learning rate to 7.943282347242812e-06.
Epoch 1521/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1746 - lr: 7.9433e-06

Epoch 01522: LearningRateScheduler reducing learning rate to 7.909062363565018e-06.
Epoch 1522/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1709 - lr: 7.9091e-06

Epoch 01523: LearningRateScheduler reducing learning rate to 7.874989800969808e-06.
Epoch 1523/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1628 - lr: 7.8750e-06

Epoch 01524: LearningRateScheduler reducing learning rate to 7.841064024361159e-06.
Epoch 1524/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1718 - lr: 7.8411e-06

Epoch 01525: LearningRateScheduler reducing learning rate to 7.807284401379066e-06.
Epoch 1525/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1797 - lr: 7.8073e-06

Epoch 01526: LearningRateScheduler reducing learning rate to 7.773650302387755e-06.
Epoch 1526/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1680 - lr: 7.7737e-06

Epoch 01527: LearningRateScheduler reducing learning rate to 7.740161100463955e-06.
Epoch 1527/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1706 - lr: 7.7402e-06

Epoch 01528: LearningRateScheduler reducing learning rate to 7.706816171385193e-06.
Epoch 1528/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1731 - lr: 7.7068e-06

Epoch 01529: LearningRateScheduler reducing learning rate to 7.673614893618188e-06.
Epoch 1529/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1652 - lr: 7.6736e-06

Epoch 01530: LearningRateScheduler reducing learning rate to 7.640556648307238e-06.
Epoch 1530/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1705 - lr: 7.6406e-06

Epoch 01531: LearningRateScheduler reducing learning rate to 7.6076408192627e-06.
Epoch 1531/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1730 - lr: 7.6076e-06

Epoch 01532: LearningRateScheduler reducing learning rate to 7.574866792949503e-06.
Epoch 1532/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1607 - lr: 7.5749e-06

Epoch 01533: LearningRateScheduler reducing learning rate to 7.5422339584757065e-06.
Epoch 1533/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1707 - lr: 7.5422e-06

Epoch 01534: LearningRateScheduler reducing learning rate to 7.5097417075811206e-06.
Epoch 1534/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1703 - lr: 7.5097e-06

Epoch 01535: LearningRateScheduler reducing learning rate to 7.477389434625965e-06.
Epoch 1535/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1702 - lr: 7.4774e-06

Epoch 01536: LearningRateScheduler reducing learning rate to 7.445176536579575e-06.
Epoch 1536/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1723 - lr: 7.4452e-06

Epoch 01537: LearningRateScheduler reducing learning rate to 7.413102413009175e-06.
Epoch 1537/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1686 - lr: 7.4131e-06

Epoch 01538: LearningRateScheduler reducing learning rate to 7.3811664660686705e-06.
Epoch 1538/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1764 - lr: 7.3812e-06

Epoch 01539: LearningRateScheduler reducing learning rate to 7.349368100487516e-06.
Epoch 1539/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1687 - lr: 7.3494e-06

Epoch 01540: LearningRateScheduler reducing learning rate to 7.317706723559617e-06.
Epoch 1540/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1618 - lr: 7.3177e-06

Epoch 01541: LearningRateScheduler reducing learning rate to 7.286181745132278e-06.
Epoch 1541/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1683 - lr: 7.2862e-06

Epoch 01542: LearningRateScheduler reducing learning rate to 7.254792577595206e-06.
Epoch 1542/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1705 - lr: 7.2548e-06

Epoch 01543: LearningRateScheduler reducing learning rate to 7.223538635869557e-06.
Epoch 1543/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1737 - lr: 7.2235e-06

Epoch 01544: LearningRateScheduler reducing learning rate to 7.192419337397034e-06.
Epoch 1544/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1739 - lr: 7.1924e-06

Epoch 01545: LearningRateScheduler reducing learning rate to 7.161434102129021e-06.
Epoch 1545/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1698 - lr: 7.1614e-06

Epoch 01546: LearningRateScheduler reducing learning rate to 7.130582352515775e-06.
Epoch 1546/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1650 - lr: 7.1306e-06

Epoch 01547: LearningRateScheduler reducing learning rate to 7.0998635134956545e-06.
Epoch 1547/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1766 - lr: 7.0999e-06

Epoch 01548: LearningRateScheduler reducing learning rate to 7.06927701248443e-06.
Epoch 1548/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1689 - lr: 7.0693e-06

Epoch 01549: LearningRateScheduler reducing learning rate to 7.038822279364564e-06.
Epoch 1549/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1708 - lr: 7.0388e-06

Epoch 01550: LearningRateScheduler reducing learning rate to 7.0084987464746165e-06.
Epoch 1550/4000
Model saved in ./model/scPDB_1221_pdbid--1550--0.1721--0.0000070.
24/24 - 3s - loss: 0.0624 - val_loss: 0.1721 - lr: 7.0085e-06

Epoch 01551: LearningRateScheduler reducing learning rate to 6.978305848598658e-06.
Epoch 1551/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1608 - lr: 6.9783e-06

Epoch 01552: LearningRateScheduler reducing learning rate to 6.948243022955731e-06.
Epoch 1552/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1729 - lr: 6.9482e-06

Epoch 01553: LearningRateScheduler reducing learning rate to 6.91830970918936e-06.
Epoch 1553/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1619 - lr: 6.9183e-06

Epoch 01554: LearningRateScheduler reducing learning rate to 6.88850534935711e-06.
Epoch 1554/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1745 - lr: 6.8885e-06

Epoch 01555: LearningRateScheduler reducing learning rate to 6.858829387920183e-06.
Epoch 1555/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1672 - lr: 6.8588e-06

Epoch 01556: LearningRateScheduler reducing learning rate to 6.829281271733067e-06.
Epoch 1556/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1771 - lr: 6.8293e-06

Epoch 01557: LearningRateScheduler reducing learning rate to 6.79986045003322e-06.
Epoch 1557/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1686 - lr: 6.7999e-06

Epoch 01558: LearningRateScheduler reducing learning rate to 6.77056637443081e-06.
Epoch 1558/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1731 - lr: 6.7706e-06

Epoch 01559: LearningRateScheduler reducing learning rate to 6.74139849889849e-06.
Epoch 1559/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1757 - lr: 6.7414e-06

Epoch 01560: LearningRateScheduler reducing learning rate to 6.712356279761223e-06.
Epoch 1560/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1681 - lr: 6.7124e-06

Epoch 01561: LearningRateScheduler reducing learning rate to 6.683439175686142e-06.
Epoch 1561/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1692 - lr: 6.6834e-06

Epoch 01562: LearningRateScheduler reducing learning rate to 6.654646647672469e-06.
Epoch 1562/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1755 - lr: 6.6546e-06

Epoch 01563: LearningRateScheduler reducing learning rate to 6.625978159041458e-06.
Epoch 1563/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1726 - lr: 6.6260e-06

Epoch 01564: LearningRateScheduler reducing learning rate to 6.5974331754264e-06.
Epoch 1564/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1687 - lr: 6.5974e-06

Epoch 01565: LearningRateScheduler reducing learning rate to 6.56901116476266e-06.
Epoch 1565/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1716 - lr: 6.5690e-06

Epoch 01566: LearningRateScheduler reducing learning rate to 6.5407115972777586e-06.
Epoch 1566/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1642 - lr: 6.5407e-06

Epoch 01567: LearningRateScheduler reducing learning rate to 6.512533945481496e-06.
Epoch 1567/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1708 - lr: 6.5125e-06

Epoch 01568: LearningRateScheduler reducing learning rate to 6.484477684156124e-06.
Epoch 1568/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1680 - lr: 6.4845e-06

Epoch 01569: LearningRateScheduler reducing learning rate to 6.456542290346552e-06.
Epoch 1569/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1698 - lr: 6.4565e-06

Epoch 01570: LearningRateScheduler reducing learning rate to 6.4287272433506045e-06.
Epoch 1570/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1721 - lr: 6.4287e-06

Epoch 01571: LearningRateScheduler reducing learning rate to 6.401032024709306e-06.
Epoch 1571/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1735 - lr: 6.4010e-06

Epoch 01572: LearningRateScheduler reducing learning rate to 6.37345611819723e-06.
Epoch 1572/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1673 - lr: 6.3735e-06

Epoch 01573: LearningRateScheduler reducing learning rate to 6.345999009812866e-06.
Epoch 1573/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1652 - lr: 6.3460e-06

Epoch 01574: LearningRateScheduler reducing learning rate to 6.318660187769046e-06.
Epoch 1574/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1799 - lr: 6.3187e-06

Epoch 01575: LearningRateScheduler reducing learning rate to 6.291439142483398e-06.
Epoch 1575/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1711 - lr: 6.2914e-06

Epoch 01576: LearningRateScheduler reducing learning rate to 6.264335366568854e-06.
Epoch 1576/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1721 - lr: 6.2643e-06

Epoch 01577: LearningRateScheduler reducing learning rate to 6.237348354824191e-06.
Epoch 1577/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1775 - lr: 6.2373e-06

Epoch 01578: LearningRateScheduler reducing learning rate to 6.2104776042246125e-06.
Epoch 1578/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1630 - lr: 6.2105e-06

Epoch 01579: LearningRateScheduler reducing learning rate to 6.183722613912371e-06.
Epoch 1579/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1794 - lr: 6.1837e-06

Epoch 01580: LearningRateScheduler reducing learning rate to 6.1570828851874394e-06.
Epoch 1580/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1578 - lr: 6.1571e-06

Epoch 01581: LearningRateScheduler reducing learning rate to 6.130557921498206e-06.
Epoch 1581/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1719 - lr: 6.1306e-06

Epoch 01582: LearningRateScheduler reducing learning rate to 6.104147228432227e-06.
Epoch 1582/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1678 - lr: 6.1041e-06

Epoch 01583: LearningRateScheduler reducing learning rate to 6.077850313707005e-06.
Epoch 1583/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1766 - lr: 6.0779e-06

Epoch 01584: LearningRateScheduler reducing learning rate to 6.051666687160817e-06.
Epoch 1584/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1677 - lr: 6.0517e-06

Epoch 01585: LearningRateScheduler reducing learning rate to 6.025595860743577e-06.
Epoch 1585/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1726 - lr: 6.0256e-06

Epoch 01586: LearningRateScheduler reducing learning rate to 5.9996373485077375e-06.
Epoch 1586/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1729 - lr: 5.9996e-06

Epoch 01587: LearningRateScheduler reducing learning rate to 5.973790666599233e-06.
Epoch 1587/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1697 - lr: 5.9738e-06

Epoch 01588: LearningRateScheduler reducing learning rate to 5.948055333248462e-06.
Epoch 1588/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1662 - lr: 5.9481e-06

Epoch 01589: LearningRateScheduler reducing learning rate to 5.9224308687613064e-06.
Epoch 1589/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1807 - lr: 5.9224e-06

Epoch 01590: LearningRateScheduler reducing learning rate to 5.896916795510187e-06.
Epoch 1590/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1695 - lr: 5.8969e-06

Epoch 01591: LearningRateScheduler reducing learning rate to 5.871512637925165e-06.
Epoch 1591/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1731 - lr: 5.8715e-06

Epoch 01592: LearningRateScheduler reducing learning rate to 5.84621792248508e-06.
Epoch 1592/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1680 - lr: 5.8462e-06

Epoch 01593: LearningRateScheduler reducing learning rate to 5.821032177708714e-06.
Epoch 1593/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1723 - lr: 5.8210e-06

Epoch 01594: LearningRateScheduler reducing learning rate to 5.795954934146014e-06.
Epoch 1594/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1743 - lr: 5.7960e-06

Epoch 01595: LearningRateScheduler reducing learning rate to 5.770985724369333e-06.
Epoch 1595/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1685 - lr: 5.7710e-06

Epoch 01596: LearningRateScheduler reducing learning rate to 5.74612408296472e-06.
Epoch 1596/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1635 - lr: 5.7461e-06

Epoch 01597: LearningRateScheduler reducing learning rate to 5.72136954652326e-06.
Epoch 1597/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1706 - lr: 5.7214e-06

Epoch 01598: LearningRateScheduler reducing learning rate to 5.6967216536324055e-06.
Epoch 1598/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1692 - lr: 5.6967e-06

Epoch 01599: LearningRateScheduler reducing learning rate to 5.6721799448674e-06.
Epoch 1599/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1706 - lr: 5.6722e-06

Epoch 01600: LearningRateScheduler reducing learning rate to 5.647743962782708e-06.
Epoch 1600/4000
Model saved in ./model/scPDB_1221_pdbid--1600--0.1744--0.0000056.
24/24 - 3s - loss: 0.0627 - val_loss: 0.1744 - lr: 5.6477e-06

Epoch 01601: LearningRateScheduler reducing learning rate to 5.623413251903487e-06.
Epoch 1601/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1670 - lr: 5.6234e-06

Epoch 01602: LearningRateScheduler reducing learning rate to 5.599187358717098e-06.
Epoch 1602/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1749 - lr: 5.5992e-06

Epoch 01603: LearningRateScheduler reducing learning rate to 5.575065831664655e-06.
Epoch 1603/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1718 - lr: 5.5751e-06

Epoch 01604: LearningRateScheduler reducing learning rate to 5.551048221132604e-06.
Epoch 1604/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1795 - lr: 5.5510e-06

Epoch 01605: LearningRateScheduler reducing learning rate to 5.5271340794443455e-06.
Epoch 1605/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1679 - lr: 5.5271e-06

Epoch 01606: LearningRateScheduler reducing learning rate to 5.50332296085189e-06.
Epoch 1606/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1655 - lr: 5.5033e-06

Epoch 01607: LearningRateScheduler reducing learning rate to 5.479614421527544e-06.
Epoch 1607/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1616 - lr: 5.4796e-06

Epoch 01608: LearningRateScheduler reducing learning rate to 5.456008019555648e-06.
Epoch 1608/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1737 - lr: 5.4560e-06

Epoch 01609: LearningRateScheduler reducing learning rate to 5.432503314924329e-06.
Epoch 1609/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1751 - lr: 5.4325e-06

Epoch 01610: LearningRateScheduler reducing learning rate to 5.409099869517305e-06.
Epoch 1610/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1700 - lr: 5.4091e-06

Epoch 01611: LearningRateScheduler reducing learning rate to 5.385797247105716e-06.
Epoch 1611/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1709 - lr: 5.3858e-06

Epoch 01612: LearningRateScheduler reducing learning rate to 5.362595013339993e-06.
Epoch 1612/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1645 - lr: 5.3626e-06

Epoch 01613: LearningRateScheduler reducing learning rate to 5.339492735741764e-06.
Epoch 1613/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1814 - lr: 5.3395e-06

Epoch 01614: LearningRateScheduler reducing learning rate to 5.316489983695791e-06.
Epoch 1614/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1626 - lr: 5.3165e-06

Epoch 01615: LearningRateScheduler reducing learning rate to 5.293586328441943e-06.
Epoch 1615/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1742 - lr: 5.2936e-06

Epoch 01616: LearningRateScheduler reducing learning rate to 5.2707813430672055e-06.
Epoch 1616/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1669 - lr: 5.2708e-06

Epoch 01617: LearningRateScheduler reducing learning rate to 5.248074602497724e-06.
Epoch 1617/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1664 - lr: 5.2481e-06

Epoch 01618: LearningRateScheduler reducing learning rate to 5.225465683490878e-06.
Epoch 1618/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1760 - lr: 5.2255e-06

Epoch 01619: LearningRateScheduler reducing learning rate to 5.202954164627394e-06.
Epoch 1619/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1676 - lr: 5.2030e-06

Epoch 01620: LearningRateScheduler reducing learning rate to 5.18053962630349e-06.
Epoch 1620/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1715 - lr: 5.1805e-06

Epoch 01621: LearningRateScheduler reducing learning rate to 5.158221650723055e-06.
Epoch 1621/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1736 - lr: 5.1582e-06

Epoch 01622: LearningRateScheduler reducing learning rate to 5.135999821889858e-06.
Epoch 1622/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1639 - lr: 5.1360e-06

Epoch 01623: LearningRateScheduler reducing learning rate to 5.113873725599798e-06.
Epoch 1623/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1604 - lr: 5.1139e-06

Epoch 01624: LearningRateScheduler reducing learning rate to 5.091842949433184e-06.
Epoch 1624/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1636 - lr: 5.0918e-06

Epoch 01625: LearningRateScheduler reducing learning rate to 5.069907082747042e-06.
Epoch 1625/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1738 - lr: 5.0699e-06

Epoch 01626: LearningRateScheduler reducing learning rate to 5.048065716667469e-06.
Epoch 1626/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1748 - lr: 5.0481e-06

Epoch 01627: LearningRateScheduler reducing learning rate to 5.0263184440820055e-06.
Epoch 1627/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1740 - lr: 5.0263e-06

Epoch 01628: LearningRateScheduler reducing learning rate to 5.004664859632048e-06.
Epoch 1628/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1692 - lr: 5.0047e-06

Epoch 01629: LearningRateScheduler reducing learning rate to 4.983104559705294e-06.
Epoch 1629/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1724 - lr: 4.9831e-06

Epoch 01630: LearningRateScheduler reducing learning rate to 4.961637142428223e-06.
Epoch 1630/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1722 - lr: 4.9616e-06

Epoch 01631: LearningRateScheduler reducing learning rate to 4.940262207658597e-06.
Epoch 1631/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1778 - lr: 4.9403e-06

Epoch 01632: LearningRateScheduler reducing learning rate to 4.918979356978011e-06.
Epoch 1632/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1718 - lr: 4.9190e-06

Epoch 01633: LearningRateScheduler reducing learning rate to 4.897788193684461e-06.
Epoch 1633/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1703 - lr: 4.8978e-06

Epoch 01634: LearningRateScheduler reducing learning rate to 4.876688322784952e-06.
Epoch 1634/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1728 - lr: 4.8767e-06

Epoch 01635: LearningRateScheduler reducing learning rate to 4.855679350988133e-06.
Epoch 1635/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1714 - lr: 4.8557e-06

Epoch 01636: LearningRateScheduler reducing learning rate to 4.8347608866969705e-06.
Epoch 1636/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1679 - lr: 4.8348e-06

Epoch 01637: LearningRateScheduler reducing learning rate to 4.813932540001447e-06.
Epoch 1637/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1729 - lr: 4.8139e-06

Epoch 01638: LearningRateScheduler reducing learning rate to 4.793193922671291e-06.
Epoch 1638/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1728 - lr: 4.7932e-06

Epoch 01639: LearningRateScheduler reducing learning rate to 4.772544648148744e-06.
Epoch 1639/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1705 - lr: 4.7725e-06

Epoch 01640: LearningRateScheduler reducing learning rate to 4.751984331541355e-06.
Epoch 1640/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1702 - lr: 4.7520e-06

Epoch 01641: LearningRateScheduler reducing learning rate to 4.7315125896148055e-06.
Epoch 1641/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1680 - lr: 4.7315e-06

Epoch 01642: LearningRateScheduler reducing learning rate to 4.711129040785763e-06.
Epoch 1642/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1661 - lr: 4.7111e-06

Epoch 01643: LearningRateScheduler reducing learning rate to 4.690833305114773e-06.
Epoch 1643/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1757 - lr: 4.6908e-06

Epoch 01644: LearningRateScheduler reducing learning rate to 4.670625004299179e-06.
Epoch 1644/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1682 - lr: 4.6706e-06

Epoch 01645: LearningRateScheduler reducing learning rate to 4.6505037616660595e-06.
Epoch 1645/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1715 - lr: 4.6505e-06

Epoch 01646: LearningRateScheduler reducing learning rate to 4.630469202165229e-06.
Epoch 1646/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1670 - lr: 4.6305e-06

Epoch 01647: LearningRateScheduler reducing learning rate to 4.61052095236222e-06.
Epoch 1647/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1698 - lr: 4.6105e-06

Epoch 01648: LearningRateScheduler reducing learning rate to 4.590658640431344e-06.
Epoch 1648/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1705 - lr: 4.5907e-06

Epoch 01649: LearningRateScheduler reducing learning rate to 4.570881896148747e-06.
Epoch 1649/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1699 - lr: 4.5709e-06

Epoch 01650: LearningRateScheduler reducing learning rate to 4.551190350885518e-06.
Epoch 1650/4000
Model saved in ./model/scPDB_1221_pdbid--1650--0.1726--0.0000046.
24/24 - 3s - loss: 0.0628 - val_loss: 0.1726 - lr: 4.5512e-06

Epoch 01651: LearningRateScheduler reducing learning rate to 4.531583637600815e-06.
Epoch 1651/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1716 - lr: 4.5316e-06

Epoch 01652: LearningRateScheduler reducing learning rate to 4.512061390835019e-06.
Epoch 1652/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1772 - lr: 4.5121e-06

Epoch 01653: LearningRateScheduler reducing learning rate to 4.492623246702931e-06.
Epoch 1653/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1661 - lr: 4.4926e-06

Epoch 01654: LearningRateScheduler reducing learning rate to 4.47326884288698e-06.
Epoch 1654/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1696 - lr: 4.4733e-06

Epoch 01655: LearningRateScheduler reducing learning rate to 4.453997818630476e-06.
Epoch 1655/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1717 - lr: 4.4540e-06

Epoch 01656: LearningRateScheduler reducing learning rate to 4.434809814730882e-06.
Epoch 1656/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1737 - lr: 4.4348e-06

Epoch 01657: LearningRateScheduler reducing learning rate to 4.415704473533123e-06.
Epoch 1657/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1750 - lr: 4.4157e-06

Epoch 01658: LearningRateScheduler reducing learning rate to 4.396681438922913e-06.
Epoch 1658/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1611 - lr: 4.3967e-06

Epoch 01659: LearningRateScheduler reducing learning rate to 4.377740356320123e-06.
Epoch 1659/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1745 - lr: 4.3777e-06

Epoch 01660: LearningRateScheduler reducing learning rate to 4.3588808726721714e-06.
Epoch 1660/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1619 - lr: 4.3589e-06

Epoch 01661: LearningRateScheduler reducing learning rate to 4.340102636447436e-06.
Epoch 1661/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1743 - lr: 4.3401e-06

Epoch 01662: LearningRateScheduler reducing learning rate to 4.321405297628713e-06.
Epoch 1662/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1750 - lr: 4.3214e-06

Epoch 01663: LearningRateScheduler reducing learning rate to 4.302788507706683e-06.
Epoch 1663/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1721 - lr: 4.3028e-06

Epoch 01664: LearningRateScheduler reducing learning rate to 4.28425191967342e-06.
Epoch 1664/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1625 - lr: 4.2843e-06

Epoch 01665: LearningRateScheduler reducing learning rate to 4.265795188015925e-06.
Epoch 1665/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1755 - lr: 4.2658e-06

Epoch 01666: LearningRateScheduler reducing learning rate to 4.247417968709678e-06.
Epoch 1666/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1689 - lr: 4.2474e-06

Epoch 01667: LearningRateScheduler reducing learning rate to 4.229119919212235e-06.
Epoch 1667/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1647 - lr: 4.2291e-06

Epoch 01668: LearningRateScheduler reducing learning rate to 4.210900698456836e-06.
Epoch 1668/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1716 - lr: 4.2109e-06

Epoch 01669: LearningRateScheduler reducing learning rate to 4.192759966846053e-06.
Epoch 1669/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1751 - lr: 4.1928e-06

Epoch 01670: LearningRateScheduler reducing learning rate to 4.1746973862454546e-06.
Epoch 1670/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1682 - lr: 4.1747e-06

Epoch 01671: LearningRateScheduler reducing learning rate to 4.156712619977309e-06.
Epoch 1671/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1677 - lr: 4.1567e-06

Epoch 01672: LearningRateScheduler reducing learning rate to 4.138805332814304e-06.
Epoch 1672/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1721 - lr: 4.1388e-06

Epoch 01673: LearningRateScheduler reducing learning rate to 4.120975190973301e-06.
Epoch 1673/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1717 - lr: 4.1210e-06

Epoch 01674: LearningRateScheduler reducing learning rate to 4.103221862109113e-06.
Epoch 1674/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1782 - lr: 4.1032e-06

Epoch 01675: LearningRateScheduler reducing learning rate to 4.085545015308309e-06.
Epoch 1675/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1756 - lr: 4.0855e-06

Epoch 01676: LearningRateScheduler reducing learning rate to 4.067944321083046e-06.
Epoch 1676/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1629 - lr: 4.0679e-06

Epoch 01677: LearningRateScheduler reducing learning rate to 4.05041945136493e-06.
Epoch 1677/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1727 - lr: 4.0504e-06

Epoch 01678: LearningRateScheduler reducing learning rate to 4.032970079498898e-06.
Epoch 1678/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1680 - lr: 4.0330e-06

Epoch 01679: LearningRateScheduler reducing learning rate to 4.01559588023713e-06.
Epoch 1679/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1798 - lr: 4.0156e-06

Epoch 01680: LearningRateScheduler reducing learning rate to 3.998296529732986e-06.
Epoch 1680/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1612 - lr: 3.9983e-06

Epoch 01681: LearningRateScheduler reducing learning rate to 3.981071705534972e-06.
Epoch 1681/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1678 - lr: 3.9811e-06

Epoch 01682: LearningRateScheduler reducing learning rate to 3.963921086580727e-06.
Epoch 1682/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1696 - lr: 3.9639e-06

Epoch 01683: LearningRateScheduler reducing learning rate to 3.946844353191043e-06.
Epoch 1683/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1714 - lr: 3.9468e-06

Epoch 01684: LearningRateScheduler reducing learning rate to 3.929841187063897e-06.
Epoch 1684/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1662 - lr: 3.9298e-06

Epoch 01685: LearningRateScheduler reducing learning rate to 3.912911271268529e-06.
Epoch 1685/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1731 - lr: 3.9129e-06

Epoch 01686: LearningRateScheduler reducing learning rate to 3.896054290239529e-06.
Epoch 1686/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1738 - lr: 3.8961e-06

Epoch 01687: LearningRateScheduler reducing learning rate to 3.879269929770953e-06.
Epoch 1687/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1626 - lr: 3.8793e-06

Epoch 01688: LearningRateScheduler reducing learning rate to 3.862557877010472e-06.
Epoch 1688/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1818 - lr: 3.8626e-06

Epoch 01689: LearningRateScheduler reducing learning rate to 3.845917820453536e-06.
Epoch 1689/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1681 - lr: 3.8459e-06

Epoch 01690: LearningRateScheduler reducing learning rate to 3.829349449937569e-06.
Epoch 1690/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1760 - lr: 3.8293e-06

Epoch 01691: LearningRateScheduler reducing learning rate to 3.812852456636189e-06.
Epoch 1691/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1652 - lr: 3.8129e-06

Epoch 01692: LearningRateScheduler reducing learning rate to 3.7964265330534497e-06.
Epoch 1692/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1699 - lr: 3.7964e-06

Epoch 01693: LearningRateScheduler reducing learning rate to 3.7800713730181115e-06.
Epoch 1693/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1809 - lr: 3.7801e-06

Epoch 01694: LearningRateScheduler reducing learning rate to 3.763786671677928e-06.
Epoch 1694/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1534 - lr: 3.7638e-06

Epoch 01695: LearningRateScheduler reducing learning rate to 3.747572125493978e-06.
Epoch 1695/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1702 - lr: 3.7476e-06

Epoch 01696: LearningRateScheduler reducing learning rate to 3.731427432234991e-06.
Epoch 1696/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1713 - lr: 3.7314e-06

Epoch 01697: LearningRateScheduler reducing learning rate to 3.715352290971723e-06.
Epoch 1697/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1659 - lr: 3.7154e-06

Epoch 01698: LearningRateScheduler reducing learning rate to 3.6993464020713438e-06.
Epoch 1698/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1773 - lr: 3.6993e-06

Epoch 01699: LearningRateScheduler reducing learning rate to 3.6834094671918567e-06.
Epoch 1699/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1630 - lr: 3.6834e-06

Epoch 01700: LearningRateScheduler reducing learning rate to 3.6675411892765324e-06.
Epoch 1700/4000
Model saved in ./model/scPDB_1221_pdbid--1700--0.1723--0.0000037.
24/24 - 3s - loss: 0.0625 - val_loss: 0.1723 - lr: 3.6675e-06

Epoch 01701: LearningRateScheduler reducing learning rate to 3.6517412725483745e-06.
Epoch 1701/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1727 - lr: 3.6517e-06

Epoch 01702: LearningRateScheduler reducing learning rate to 3.6360094225046064e-06.
Epoch 1702/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1699 - lr: 3.6360e-06

Epoch 01703: LearningRateScheduler reducing learning rate to 3.6203453459111812e-06.
Epoch 1703/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1685 - lr: 3.6203e-06

Epoch 01704: LearningRateScheduler reducing learning rate to 3.604748750797316e-06.
Epoch 1704/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1751 - lr: 3.6047e-06

Epoch 01705: LearningRateScheduler reducing learning rate to 3.58921934645005e-06.
Epoch 1705/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1686 - lr: 3.5892e-06

Epoch 01706: LearningRateScheduler reducing learning rate to 3.5737568434088258e-06.
Epoch 1706/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1746 - lr: 3.5738e-06

Epoch 01707: LearningRateScheduler reducing learning rate to 3.558360953460094e-06.
Epoch 1707/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1739 - lr: 3.5584e-06

Epoch 01708: LearningRateScheduler reducing learning rate to 3.54303138963194e-06.
Epoch 1708/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1716 - lr: 3.5430e-06

Epoch 01709: LearningRateScheduler reducing learning rate to 3.527767866188737e-06.
Epoch 1709/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1701 - lr: 3.5278e-06

Epoch 01710: LearningRateScheduler reducing learning rate to 3.5125700986258195e-06.
Epoch 1710/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1699 - lr: 3.5126e-06

Epoch 01711: LearningRateScheduler reducing learning rate to 3.4974378036641774e-06.
Epoch 1711/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1718 - lr: 3.4974e-06

Epoch 01712: LearningRateScheduler reducing learning rate to 3.4823706992451796e-06.
Epoch 1712/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1732 - lr: 3.4824e-06

Epoch 01713: LearningRateScheduler reducing learning rate to 3.467368504525315e-06.
Epoch 1713/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1719 - lr: 3.4674e-06

Epoch 01714: LearningRateScheduler reducing learning rate to 3.4524309398709573e-06.
Epoch 1714/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1774 - lr: 3.4524e-06

Epoch 01715: LearningRateScheduler reducing learning rate to 3.4375577268531545e-06.
Epoch 1715/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1676 - lr: 3.4376e-06

Epoch 01716: LearningRateScheduler reducing learning rate to 3.422748588242436e-06.
Epoch 1716/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1713 - lr: 3.4227e-06

Epoch 01717: LearningRateScheduler reducing learning rate to 3.4080032480036488e-06.
Epoch 1717/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1624 - lr: 3.4080e-06

Epoch 01718: LearningRateScheduler reducing learning rate to 3.3933214312908085e-06.
Epoch 1718/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1814 - lr: 3.3933e-06

Epoch 01719: LearningRateScheduler reducing learning rate to 3.378702864441981e-06.
Epoch 1719/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1646 - lr: 3.3787e-06

Epoch 01720: LearningRateScheduler reducing learning rate to 3.364147274974177e-06.
Epoch 1720/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1711 - lr: 3.3641e-06

Epoch 01721: LearningRateScheduler reducing learning rate to 3.3496543915782755e-06.
Epoch 1721/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1693 - lr: 3.3497e-06

Epoch 01722: LearningRateScheduler reducing learning rate to 3.3352239441139665e-06.
Epoch 1722/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1727 - lr: 3.3352e-06

Epoch 01723: LearningRateScheduler reducing learning rate to 3.320855663604715e-06.
Epoch 1723/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1704 - lr: 3.3209e-06

Epoch 01724: LearningRateScheduler reducing learning rate to 3.306549282232749e-06.
Epoch 1724/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1684 - lr: 3.3065e-06

Epoch 01725: LearningRateScheduler reducing learning rate to 3.2923045333340643e-06.
Epoch 1725/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1691 - lr: 3.2923e-06

Epoch 01726: LearningRateScheduler reducing learning rate to 3.278121151393458e-06.
Epoch 1726/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1698 - lr: 3.2781e-06

Epoch 01727: LearningRateScheduler reducing learning rate to 3.2639988720395765e-06.
Epoch 1727/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1705 - lr: 3.2640e-06

Epoch 01728: LearningRateScheduler reducing learning rate to 3.2499374320399895e-06.
Epoch 1728/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1702 - lr: 3.2499e-06

Epoch 01729: LearningRateScheduler reducing learning rate to 3.235936569296282e-06.
Epoch 1729/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1768 - lr: 3.2359e-06

Epoch 01730: LearningRateScheduler reducing learning rate to 3.22199602283917e-06.
Epoch 1730/4000
24/24 - 3s - loss: 0.0611 - val_loss: 0.1605 - lr: 3.2220e-06

Epoch 01731: LearningRateScheduler reducing learning rate to 3.2081155328236356e-06.
Epoch 1731/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1698 - lr: 3.2081e-06

Epoch 01732: LearningRateScheduler reducing learning rate to 3.194294840524084e-06.
Epoch 1732/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1743 - lr: 3.1943e-06

Epoch 01733: LearningRateScheduler reducing learning rate to 3.1805336883295205e-06.
Epoch 1733/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1626 - lr: 3.1805e-06

Epoch 01734: LearningRateScheduler reducing learning rate to 3.1668318197387493e-06.
Epoch 1734/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1738 - lr: 3.1668e-06

Epoch 01735: LearningRateScheduler reducing learning rate to 3.1531889793555926e-06.
Epoch 1735/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1704 - lr: 3.1532e-06

Epoch 01736: LearningRateScheduler reducing learning rate to 3.139604912884129e-06.
Epoch 1736/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1731 - lr: 3.1396e-06

Epoch 01737: LearningRateScheduler reducing learning rate to 3.126079367123955e-06.
Epoch 1737/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1679 - lr: 3.1261e-06

Epoch 01738: LearningRateScheduler reducing learning rate to 3.112612089965463e-06.
Epoch 1738/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1719 - lr: 3.1126e-06

Epoch 01739: LearningRateScheduler reducing learning rate to 3.099202830385147e-06.
Epoch 1739/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1752 - lr: 3.0992e-06

Epoch 01740: LearningRateScheduler reducing learning rate to 3.0858513384409173e-06.
Epoch 1740/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1702 - lr: 3.0859e-06

Epoch 01741: LearningRateScheduler reducing learning rate to 3.0725573652674467e-06.
Epoch 1741/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1694 - lr: 3.0726e-06

Epoch 01742: LearningRateScheduler reducing learning rate to 3.059320663071527e-06.
Epoch 1742/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1747 - lr: 3.0593e-06

Epoch 01743: LearningRateScheduler reducing learning rate to 3.0461409851274605e-06.
Epoch 1743/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1657 - lr: 3.0461e-06

Epoch 01744: LearningRateScheduler reducing learning rate to 3.033018085772447e-06.
Epoch 1744/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1753 - lr: 3.0330e-06

Epoch 01745: LearningRateScheduler reducing learning rate to 3.019951720402014e-06.
Epoch 1745/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1671 - lr: 3.0200e-06

Epoch 01746: LearningRateScheduler reducing learning rate to 3.0069416454654536e-06.
Epoch 1746/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1726 - lr: 3.0069e-06

Epoch 01747: LearningRateScheduler reducing learning rate to 2.9939876184612868e-06.
Epoch 1747/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1725 - lr: 2.9940e-06

Epoch 01748: LearningRateScheduler reducing learning rate to 2.981089397932738e-06.
Epoch 1748/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1727 - lr: 2.9811e-06

Epoch 01749: LearningRateScheduler reducing learning rate to 2.96824674346324e-06.
Epoch 1749/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1696 - lr: 2.9682e-06

Epoch 01750: LearningRateScheduler reducing learning rate to 2.9554594156719476e-06.
Epoch 1750/4000
Model saved in ./model/scPDB_1221_pdbid--1750--0.1683--0.0000030.
24/24 - 3s - loss: 0.0621 - val_loss: 0.1683 - lr: 2.9555e-06

Epoch 01751: LearningRateScheduler reducing learning rate to 2.94272717620928e-06.
Epoch 1751/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1696 - lr: 2.9427e-06

Epoch 01752: LearningRateScheduler reducing learning rate to 2.930049787752474e-06.
Epoch 1752/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1690 - lr: 2.9300e-06

Epoch 01753: LearningRateScheduler reducing learning rate to 2.9174270140011653e-06.
Epoch 1753/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1691 - lr: 2.9174e-06

Epoch 01754: LearningRateScheduler reducing learning rate to 2.9048586196729777e-06.
Epoch 1754/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1648 - lr: 2.9049e-06

Epoch 01755: LearningRateScheduler reducing learning rate to 2.8923443704991443e-06.
Epoch 1755/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1752 - lr: 2.8923e-06

Epoch 01756: LearningRateScheduler reducing learning rate to 2.8798840332201355e-06.
Epoch 1756/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1678 - lr: 2.8799e-06

Epoch 01757: LearningRateScheduler reducing learning rate to 2.8674773755813143e-06.
Epoch 1757/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1806 - lr: 2.8675e-06

Epoch 01758: LearningRateScheduler reducing learning rate to 2.8551241663286058e-06.
Epoch 1758/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1734 - lr: 2.8551e-06

Epoch 01759: LearningRateScheduler reducing learning rate to 2.8428241752041864e-06.
Epoch 1759/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1739 - lr: 2.8428e-06

Epoch 01760: LearningRateScheduler reducing learning rate to 2.8305771729421944e-06.
Epoch 1760/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1685 - lr: 2.8306e-06

Epoch 01761: LearningRateScheduler reducing learning rate to 2.818382931264452e-06.
Epoch 1761/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1700 - lr: 2.8184e-06

Epoch 01762: LearningRateScheduler reducing learning rate to 2.8062412228762168e-06.
Epoch 1762/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1744 - lr: 2.8062e-06

Epoch 01763: LearningRateScheduler reducing learning rate to 2.794151821461937e-06.
Epoch 1763/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1625 - lr: 2.7942e-06

Epoch 01764: LearningRateScheduler reducing learning rate to 2.7821145016810416e-06.
Epoch 1764/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1687 - lr: 2.7821e-06

Epoch 01765: LearningRateScheduler reducing learning rate to 2.7701290391637323e-06.
Epoch 1765/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1712 - lr: 2.7701e-06

Epoch 01766: LearningRateScheduler reducing learning rate to 2.758195210506808e-06.
Epoch 1766/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1744 - lr: 2.7582e-06

Epoch 01767: LearningRateScheduler reducing learning rate to 2.7463127932694962e-06.
Epoch 1767/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1630 - lr: 2.7463e-06

Epoch 01768: LearningRateScheduler reducing learning rate to 2.7344815659693083e-06.
Epoch 1768/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1703 - lr: 2.7345e-06

Epoch 01769: LearningRateScheduler reducing learning rate to 2.7227013080779117e-06.
Epoch 1769/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1762 - lr: 2.7227e-06

Epoch 01770: LearningRateScheduler reducing learning rate to 2.7109718000170183e-06.
Epoch 1770/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1720 - lr: 2.7110e-06

Epoch 01771: LearningRateScheduler reducing learning rate to 2.699292823154293e-06.
Epoch 1771/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1756 - lr: 2.6993e-06

Epoch 01772: LearningRateScheduler reducing learning rate to 2.687664159799277e-06.
Epoch 1772/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1589 - lr: 2.6877e-06

Epoch 01773: LearningRateScheduler reducing learning rate to 2.6760855931993312e-06.
Epoch 1773/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1660 - lr: 2.6761e-06

Epoch 01774: LearningRateScheduler reducing learning rate to 2.6645569075355954e-06.
Epoch 1774/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1739 - lr: 2.6646e-06

Epoch 01775: LearningRateScheduler reducing learning rate to 2.653077887918967e-06.
Epoch 1775/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1665 - lr: 2.6531e-06

Epoch 01776: LearningRateScheduler reducing learning rate to 2.641648320386092e-06.
Epoch 1776/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1725 - lr: 2.6416e-06

Epoch 01777: LearningRateScheduler reducing learning rate to 2.6302679918953812e-06.
Epoch 1777/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1718 - lr: 2.6303e-06

Epoch 01778: LearningRateScheduler reducing learning rate to 2.618936690323037e-06.
Epoch 1778/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1762 - lr: 2.6189e-06

Epoch 01779: LearningRateScheduler reducing learning rate to 2.6076542044591e-06.
Epoch 1779/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1713 - lr: 2.6077e-06

Epoch 01780: LearningRateScheduler reducing learning rate to 2.59642032400351e-06.
Epoch 1780/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1693 - lr: 2.5964e-06

Epoch 01781: LearningRateScheduler reducing learning rate to 2.5852348395621903e-06.
Epoch 1781/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1764 - lr: 2.5852e-06

Epoch 01782: LearningRateScheduler reducing learning rate to 2.5740975426431413e-06.
Epoch 1782/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1702 - lr: 2.5741e-06

Epoch 01783: LearningRateScheduler reducing learning rate to 2.5630082256525554e-06.
Epoch 1783/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1704 - lr: 2.5630e-06

Epoch 01784: LearningRateScheduler reducing learning rate to 2.5519666818909482e-06.
Epoch 1784/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1826 - lr: 2.5520e-06

Epoch 01785: LearningRateScheduler reducing learning rate to 2.540972705549305e-06.
Epoch 1785/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1684 - lr: 2.5410e-06

Epoch 01786: LearningRateScheduler reducing learning rate to 2.5300260917052432e-06.
Epoch 1786/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1676 - lr: 2.5300e-06

Epoch 01787: LearningRateScheduler reducing learning rate to 2.519126636319196e-06.
Epoch 1787/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1722 - lr: 2.5191e-06

Epoch 01788: LearningRateScheduler reducing learning rate to 2.5082741362306072e-06.
Epoch 1788/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1699 - lr: 2.5083e-06

Epoch 01789: LearningRateScheduler reducing learning rate to 2.4974683891541437e-06.
Epoch 1789/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1706 - lr: 2.4975e-06

Epoch 01790: LearningRateScheduler reducing learning rate to 2.4867091936759256e-06.
Epoch 1790/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1680 - lr: 2.4867e-06

Epoch 01791: LearningRateScheduler reducing learning rate to 2.4759963492497713e-06.
Epoch 1791/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1757 - lr: 2.4760e-06

Epoch 01792: LearningRateScheduler reducing learning rate to 2.4653296561934665e-06.
Epoch 1792/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1729 - lr: 2.4653e-06

Epoch 01793: LearningRateScheduler reducing learning rate to 2.454708915685028e-06.
Epoch 1793/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1750 - lr: 2.4547e-06

Epoch 01794: LearningRateScheduler reducing learning rate to 2.4441339297590107e-06.
Epoch 1794/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1730 - lr: 2.4441e-06

Epoch 01795: LearningRateScheduler reducing learning rate to 2.43360450130281e-06.
Epoch 1795/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1693 - lr: 2.4336e-06

Epoch 01796: LearningRateScheduler reducing learning rate to 2.4231204340529916e-06.
Epoch 1796/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1765 - lr: 2.4231e-06

Epoch 01797: LearningRateScheduler reducing learning rate to 2.412681532591632e-06.
Epoch 1797/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1679 - lr: 2.4127e-06

Epoch 01798: LearningRateScheduler reducing learning rate to 2.402287602342676e-06.
Epoch 1798/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1727 - lr: 2.4023e-06

Epoch 01799: LearningRateScheduler reducing learning rate to 2.391938449568311e-06.
Epoch 1799/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1726 - lr: 2.3919e-06

Epoch 01800: LearningRateScheduler reducing learning rate to 2.381633881365353e-06.
Epoch 1800/4000
Model saved in ./model/scPDB_1221_pdbid--1800--0.1710--0.0000024.
24/24 - 4s - loss: 0.0620 - val_loss: 0.1710 - lr: 2.3816e-06

Epoch 01801: LearningRateScheduler reducing learning rate to 2.3713737056616535e-06.
Epoch 1801/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1713 - lr: 2.3714e-06

Epoch 01802: LearningRateScheduler reducing learning rate to 2.3611577312125193e-06.
Epoch 1802/4000
24/24 - 5s - loss: 0.0618 - val_loss: 0.1695 - lr: 2.3612e-06

Epoch 01803: LearningRateScheduler reducing learning rate to 2.350985767597146e-06.
Epoch 1803/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1716 - lr: 2.3510e-06

Epoch 01804: LearningRateScheduler reducing learning rate to 2.340857625215071e-06.
Epoch 1804/4000
24/24 - 4s - loss: 0.0622 - val_loss: 0.1617 - lr: 2.3409e-06

Epoch 01805: LearningRateScheduler reducing learning rate to 2.3307731152826364e-06.
Epoch 1805/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1819 - lr: 2.3308e-06

Epoch 01806: LearningRateScheduler reducing learning rate to 2.320732049829474e-06.
Epoch 1806/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1679 - lr: 2.3207e-06

Epoch 01807: LearningRateScheduler reducing learning rate to 2.3107342416949988e-06.
Epoch 1807/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1653 - lr: 2.3107e-06

Epoch 01808: LearningRateScheduler reducing learning rate to 2.3007795045249205e-06.
Epoch 1808/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1751 - lr: 2.3008e-06

Epoch 01809: LearningRateScheduler reducing learning rate to 2.290867652767772e-06.
Epoch 1809/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1697 - lr: 2.2909e-06

Epoch 01810: LearningRateScheduler reducing learning rate to 2.2809985016714483e-06.
Epoch 1810/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1679 - lr: 2.2810e-06

Epoch 01811: LearningRateScheduler reducing learning rate to 2.2711718672797645e-06.
Epoch 1811/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1664 - lr: 2.2712e-06

Epoch 01812: LearningRateScheduler reducing learning rate to 2.2613875664290265e-06.
Epoch 1812/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1816 - lr: 2.2614e-06

Epoch 01813: LearningRateScheduler reducing learning rate to 2.2516454167446167e-06.
Epoch 1813/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1668 - lr: 2.2516e-06

Epoch 01814: LearningRateScheduler reducing learning rate to 2.241945236637595e-06.
Epoch 1814/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1675 - lr: 2.2419e-06

Epoch 01815: LearningRateScheduler reducing learning rate to 2.232286845301314e-06.
Epoch 1815/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1719 - lr: 2.2323e-06

Epoch 01816: LearningRateScheduler reducing learning rate to 2.222670062708047e-06.
Epoch 1816/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1725 - lr: 2.2227e-06

Epoch 01817: LearningRateScheduler reducing learning rate to 2.213094709605637e-06.
Epoch 1817/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1640 - lr: 2.2131e-06

Epoch 01818: LearningRateScheduler reducing learning rate to 2.20356060751415e-06.
Epoch 1818/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1752 - lr: 2.2036e-06

Epoch 01819: LearningRateScheduler reducing learning rate to 2.1940675787225528e-06.
Epoch 1819/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1766 - lr: 2.1941e-06

Epoch 01820: LearningRateScheduler reducing learning rate to 2.1846154462853965e-06.
Epoch 1820/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1659 - lr: 2.1846e-06

Epoch 01821: LearningRateScheduler reducing learning rate to 2.175204034019522e-06.
Epoch 1821/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1714 - lr: 2.1752e-06

Epoch 01822: LearningRateScheduler reducing learning rate to 2.1658331665007743e-06.
Epoch 1822/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1691 - lr: 2.1658e-06

Epoch 01823: LearningRateScheduler reducing learning rate to 2.156502669060732e-06.
Epoch 1823/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1686 - lr: 2.1565e-06

Epoch 01824: LearningRateScheduler reducing learning rate to 2.147212367783453e-06.
Epoch 1824/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1628 - lr: 2.1472e-06

Epoch 01825: LearningRateScheduler reducing learning rate to 2.137962089502232e-06.
Epoch 1825/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1673 - lr: 2.1380e-06

Epoch 01826: LearningRateScheduler reducing learning rate to 2.128751661796372e-06.
Epoch 1826/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1801 - lr: 2.1288e-06

Epoch 01827: LearningRateScheduler reducing learning rate to 2.1195809129879735e-06.
Epoch 1827/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1711 - lr: 2.1196e-06

Epoch 01828: LearningRateScheduler reducing learning rate to 2.110449672138731e-06.
Epoch 1828/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1695 - lr: 2.1104e-06

Epoch 01829: LearningRateScheduler reducing learning rate to 2.1013577690467477e-06.
Epoch 1829/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1770 - lr: 2.1014e-06

Epoch 01830: LearningRateScheduler reducing learning rate to 2.0923050342433637e-06.
Epoch 1830/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1714 - lr: 2.0923e-06

Epoch 01831: LearningRateScheduler reducing learning rate to 2.083291298989999e-06.
Epoch 1831/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1648 - lr: 2.0833e-06

Epoch 01832: LearningRateScheduler reducing learning rate to 2.0743163952750033e-06.
Epoch 1832/4000
24/24 - 4s - loss: 0.0626 - val_loss: 0.1764 - lr: 2.0743e-06

Epoch 01833: LearningRateScheduler reducing learning rate to 2.0653801558105295e-06.
Epoch 1833/4000
24/24 - 5s - loss: 0.0620 - val_loss: 0.1775 - lr: 2.0654e-06

Epoch 01834: LearningRateScheduler reducing learning rate to 2.0564824140294116e-06.
Epoch 1834/4000
24/24 - 5s - loss: 0.0616 - val_loss: 0.1766 - lr: 2.0565e-06

Epoch 01835: LearningRateScheduler reducing learning rate to 2.0476230040820636e-06.
Epoch 1835/4000
24/24 - 5s - loss: 0.0621 - val_loss: 0.1711 - lr: 2.0476e-06

Epoch 01836: LearningRateScheduler reducing learning rate to 2.038801760833385e-06.
Epoch 1836/4000
24/24 - 5s - loss: 0.0622 - val_loss: 0.1692 - lr: 2.0388e-06

Epoch 01837: LearningRateScheduler reducing learning rate to 2.030018519859684e-06.
Epoch 1837/4000
24/24 - 5s - loss: 0.0623 - val_loss: 0.1720 - lr: 2.0300e-06

Epoch 01838: LearningRateScheduler reducing learning rate to 2.0212731174456137e-06.
Epoch 1838/4000
24/24 - 5s - loss: 0.0625 - val_loss: 0.1731 - lr: 2.0213e-06

Epoch 01839: LearningRateScheduler reducing learning rate to 2.012565390581119e-06.
Epoch 1839/4000
24/24 - 5s - loss: 0.0620 - val_loss: 0.1682 - lr: 2.0126e-06

Epoch 01840: LearningRateScheduler reducing learning rate to 2.0038951769583965e-06.
Epoch 1840/4000
24/24 - 5s - loss: 0.0615 - val_loss: 0.1700 - lr: 2.0039e-06

Epoch 01841: LearningRateScheduler reducing learning rate to 1.9952623149688783e-06.
Epoch 1841/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1755 - lr: 1.9953e-06

Epoch 01842: LearningRateScheduler reducing learning rate to 1.986666643700205e-06.
Epoch 1842/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1651 - lr: 1.9867e-06

Epoch 01843: LearningRateScheduler reducing learning rate to 1.9781080029332382e-06.
Epoch 1843/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1657 - lr: 1.9781e-06

Epoch 01844: LearningRateScheduler reducing learning rate to 1.969586233139069e-06.
Epoch 1844/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1694 - lr: 1.9696e-06

Epoch 01845: LearningRateScheduler reducing learning rate to 1.9611011754760464e-06.
Epoch 1845/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1737 - lr: 1.9611e-06

Epoch 01846: LearningRateScheduler reducing learning rate to 1.952652671786814e-06.
Epoch 1846/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1658 - lr: 1.9527e-06

Epoch 01847: LearningRateScheduler reducing learning rate to 1.9442405645953656e-06.
Epoch 1847/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1678 - lr: 1.9442e-06

Epoch 01848: LearningRateScheduler reducing learning rate to 1.935864697104107e-06.
Epoch 1848/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1711 - lr: 1.9359e-06

Epoch 01849: LearningRateScheduler reducing learning rate to 1.9275249131909346e-06.
Epoch 1849/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1718 - lr: 1.9275e-06

Epoch 01850: LearningRateScheduler reducing learning rate to 1.9192210574063258e-06.
Epoch 1850/4000
Model saved in ./model/scPDB_1221_pdbid--1850--0.1732--0.0000019.
24/24 - 3s - loss: 0.0626 - val_loss: 0.1732 - lr: 1.9192e-06

Epoch 01851: LearningRateScheduler reducing learning rate to 1.910952974970439e-06.
Epoch 1851/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1704 - lr: 1.9110e-06

Epoch 01852: LearningRateScheduler reducing learning rate to 1.9027205117702333e-06.
Epoch 1852/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1686 - lr: 1.9027e-06

Epoch 01853: LearningRateScheduler reducing learning rate to 1.894523514356591e-06.
Epoch 1853/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1771 - lr: 1.8945e-06

Epoch 01854: LearningRateScheduler reducing learning rate to 1.8863618299414593e-06.
Epoch 1854/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1725 - lr: 1.8864e-06

Epoch 01855: LearningRateScheduler reducing learning rate to 1.8782353063950043e-06.
Epoch 1855/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1747 - lr: 1.8782e-06

Epoch 01856: LearningRateScheduler reducing learning rate to 1.8701437922427714e-06.
Epoch 1856/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1664 - lr: 1.8701e-06

Epoch 01857: LearningRateScheduler reducing learning rate to 1.8620871366628664e-06.
Epoch 1857/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1694 - lr: 1.8621e-06

Epoch 01858: LearningRateScheduler reducing learning rate to 1.8540651894831402e-06.
Epoch 1858/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1718 - lr: 1.8541e-06

Epoch 01859: LearningRateScheduler reducing learning rate to 1.846077801178392e-06.
Epoch 1859/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1712 - lr: 1.8461e-06

Epoch 01860: LearningRateScheduler reducing learning rate to 1.8381248228675818e-06.
Epoch 1860/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1765 - lr: 1.8381e-06

Epoch 01861: LearningRateScheduler reducing learning rate to 1.8302061063110553e-06.
Epoch 1861/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1747 - lr: 1.8302e-06

Epoch 01862: LearningRateScheduler reducing learning rate to 1.82232150390778e-06.
Epoch 1862/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1606 - lr: 1.8223e-06

Epoch 01863: LearningRateScheduler reducing learning rate to 1.8144708686925955e-06.
Epoch 1863/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1708 - lr: 1.8145e-06

Epoch 01864: LearningRateScheduler reducing learning rate to 1.8066540543334726e-06.
Epoch 1864/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1652 - lr: 1.8067e-06

Epoch 01865: LearningRateScheduler reducing learning rate to 1.7988709151287872e-06.
Epoch 1865/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1727 - lr: 1.7989e-06

Epoch 01866: LearningRateScheduler reducing learning rate to 1.7911213060046027e-06.
Epoch 1866/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1669 - lr: 1.7911e-06

Epoch 01867: LearningRateScheduler reducing learning rate to 1.7834050825119678e-06.
Epoch 1867/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1688 - lr: 1.7834e-06

Epoch 01868: LearningRateScheduler reducing learning rate to 1.7757221008242227e-06.
Epoch 1868/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1624 - lr: 1.7757e-06

Epoch 01869: LearningRateScheduler reducing learning rate to 1.7680722177343189e-06.
Epoch 1869/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1729 - lr: 1.7681e-06

Epoch 01870: LearningRateScheduler reducing learning rate to 1.7604552906521497e-06.
Epoch 1870/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1751 - lr: 1.7605e-06

Epoch 01871: LearningRateScheduler reducing learning rate to 1.7528711776018924e-06.
Epoch 1871/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1680 - lr: 1.7529e-06

Epoch 01872: LearningRateScheduler reducing learning rate to 1.7453197372193618e-06.
Epoch 1872/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1732 - lr: 1.7453e-06

Epoch 01873: LearningRateScheduler reducing learning rate to 1.737800828749375e-06.
Epoch 1873/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1743 - lr: 1.7378e-06

Epoch 01874: LearningRateScheduler reducing learning rate to 1.7303143120431292e-06.
Epoch 1874/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1704 - lr: 1.7303e-06

Epoch 01875: LearningRateScheduler reducing learning rate to 1.7228600475555874e-06.
Epoch 1875/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1714 - lr: 1.7229e-06

Epoch 01876: LearningRateScheduler reducing learning rate to 1.7154378963428787e-06.
Epoch 1876/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1751 - lr: 1.7154e-06

Epoch 01877: LearningRateScheduler reducing learning rate to 1.7080477200597077e-06.
Epoch 1877/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1583 - lr: 1.7080e-06

Epoch 01878: LearningRateScheduler reducing learning rate to 1.7006893809567768e-06.
Epoch 1878/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1764 - lr: 1.7007e-06

Epoch 01879: LearningRateScheduler reducing learning rate to 1.6933627418782177e-06.
Epoch 1879/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1746 - lr: 1.6934e-06

Epoch 01880: LearningRateScheduler reducing learning rate to 1.6860676662590346e-06.
Epoch 1880/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1620 - lr: 1.6861e-06

Epoch 01881: LearningRateScheduler reducing learning rate to 1.67880401812256e-06.
Epoch 1881/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1692 - lr: 1.6788e-06

Epoch 01882: LearningRateScheduler reducing learning rate to 1.6715716620779193e-06.
Epoch 1882/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1675 - lr: 1.6716e-06

Epoch 01883: LearningRateScheduler reducing learning rate to 1.6643704633175071e-06.
Epoch 1883/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1716 - lr: 1.6644e-06

Epoch 01884: LearningRateScheduler reducing learning rate to 1.6572002876144746e-06.
Epoch 1884/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1735 - lr: 1.6572e-06

Epoch 01885: LearningRateScheduler reducing learning rate to 1.6500610013202276e-06.
Epoch 1885/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1690 - lr: 1.6501e-06

Epoch 01886: LearningRateScheduler reducing learning rate to 1.6429524713619362e-06.
Epoch 1886/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1795 - lr: 1.6430e-06

Epoch 01887: LearningRateScheduler reducing learning rate to 1.6358745652400528e-06.
Epoch 1887/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1649 - lr: 1.6359e-06

Epoch 01888: LearningRateScheduler reducing learning rate to 1.628827151025844e-06.
Epoch 1888/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1705 - lr: 1.6288e-06

Epoch 01889: LearningRateScheduler reducing learning rate to 1.6218100973589287e-06.
Epoch 1889/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1721 - lr: 1.6218e-06

Epoch 01890: LearningRateScheduler reducing learning rate to 1.614823273444836e-06.
Epoch 1890/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1738 - lr: 1.6148e-06

Epoch 01891: LearningRateScheduler reducing learning rate to 1.6078665490525594e-06.
Epoch 1891/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1706 - lr: 1.6079e-06

Epoch 01892: LearningRateScheduler reducing learning rate to 1.6009397945121334e-06.
Epoch 1892/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1682 - lr: 1.6009e-06

Epoch 01893: LearningRateScheduler reducing learning rate to 1.5940428807122162e-06.
Epoch 1893/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1729 - lr: 1.5940e-06

Epoch 01894: LearningRateScheduler reducing learning rate to 1.5871756790976834e-06.
Epoch 1894/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1738 - lr: 1.5872e-06

Epoch 01895: LearningRateScheduler reducing learning rate to 1.5803380616672308e-06.
Epoch 1895/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1656 - lr: 1.5803e-06

Epoch 01896: LearningRateScheduler reducing learning rate to 1.5735299009709887e-06.
Epoch 1896/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1752 - lr: 1.5735e-06

Epoch 01897: LearningRateScheduler reducing learning rate to 1.566751070108148e-06.
Epoch 1897/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1711 - lr: 1.5668e-06

Epoch 01898: LearningRateScheduler reducing learning rate to 1.5600014427245918e-06.
Epoch 1898/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1764 - lr: 1.5600e-06

Epoch 01899: LearningRateScheduler reducing learning rate to 1.553280893010543e-06.
Epoch 1899/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1709 - lr: 1.5533e-06

Epoch 01900: LearningRateScheduler reducing learning rate to 1.546589295698218e-06.
Epoch 1900/4000
Model saved in ./model/scPDB_1221_pdbid--1900--0.1672--0.0000015.
24/24 - 3s - loss: 0.0622 - val_loss: 0.1672 - lr: 1.5466e-06

Epoch 01901: LearningRateScheduler reducing learning rate to 1.5399265260594909e-06.
Epoch 1901/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1682 - lr: 1.5399e-06

Epoch 01902: LearningRateScheduler reducing learning rate to 1.5332924599035714e-06.
Epoch 1902/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1731 - lr: 1.5333e-06

Epoch 01903: LearningRateScheduler reducing learning rate to 1.5266869735746864e-06.
Epoch 1903/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1752 - lr: 1.5267e-06

Epoch 01904: LearningRateScheduler reducing learning rate to 1.5201099439497779e-06.
Epoch 1904/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1719 - lr: 1.5201e-06

Epoch 01905: LearningRateScheduler reducing learning rate to 1.5135612484362072e-06.
Epoch 1905/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1710 - lr: 1.5136e-06

Epoch 01906: LearningRateScheduler reducing learning rate to 1.5070407649694692e-06.
Epoch 1906/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1725 - lr: 1.5070e-06

Epoch 01907: LearningRateScheduler reducing learning rate to 1.5005483720109178e-06.
Epoch 1907/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1751 - lr: 1.5005e-06

Epoch 01908: LearningRateScheduler reducing learning rate to 1.4940839485455e-06.
Epoch 1908/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1735 - lr: 1.4941e-06

Epoch 01909: LearningRateScheduler reducing learning rate to 1.4876473740795013e-06.
Epoch 1909/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1737 - lr: 1.4876e-06

Epoch 01910: LearningRateScheduler reducing learning rate to 1.4812385286382985e-06.
Epoch 1910/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1677 - lr: 1.4812e-06

Epoch 01911: LearningRateScheduler reducing learning rate to 1.474857292764124e-06.
Epoch 1911/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1707 - lr: 1.4749e-06

Epoch 01912: LearningRateScheduler reducing learning rate to 1.468503547513839e-06.
Epoch 1912/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1752 - lr: 1.4685e-06

Epoch 01913: LearningRateScheduler reducing learning rate to 1.4621771744567176e-06.
Epoch 1913/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1644 - lr: 1.4622e-06

Epoch 01914: LearningRateScheduler reducing learning rate to 1.4558780556722367e-06.
Epoch 1914/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1752 - lr: 1.4559e-06

Epoch 01915: LearningRateScheduler reducing learning rate to 1.4496060737478807e-06.
Epoch 1915/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1727 - lr: 1.4496e-06

Epoch 01916: LearningRateScheduler reducing learning rate to 1.4433611117769516e-06.
Epoch 1916/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1750 - lr: 1.4434e-06

Epoch 01917: LearningRateScheduler reducing learning rate to 1.4371430533563901e-06.
Epoch 1917/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1702 - lr: 1.4371e-06

Epoch 01918: LearningRateScheduler reducing learning rate to 1.4309517825846062e-06.
Epoch 1918/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1675 - lr: 1.4310e-06

Epoch 01919: LearningRateScheduler reducing learning rate to 1.4247871840593186e-06.
Epoch 1919/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1717 - lr: 1.4248e-06

Epoch 01920: LearningRateScheduler reducing learning rate to 1.4186491428754037e-06.
Epoch 1920/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1701 - lr: 1.4186e-06

Epoch 01921: LearningRateScheduler reducing learning rate to 1.412537544622754e-06.
Epoch 1921/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1744 - lr: 1.4125e-06

Epoch 01922: LearningRateScheduler reducing learning rate to 1.4064522753841449e-06.
Epoch 1922/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1644 - lr: 1.4065e-06

Epoch 01923: LearningRateScheduler reducing learning rate to 1.4003932217331126e-06.
Epoch 1923/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1797 - lr: 1.4004e-06

Epoch 01924: LearningRateScheduler reducing learning rate to 1.3943602707318386e-06.
Epoch 1924/4000
24/24 - 4s - loss: 0.0610 - val_loss: 0.1685 - lr: 1.3944e-06

Epoch 01925: LearningRateScheduler reducing learning rate to 1.388353309929045e-06.
Epoch 1925/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1686 - lr: 1.3884e-06

Epoch 01926: LearningRateScheduler reducing learning rate to 1.3823722273578994e-06.
Epoch 1926/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1737 - lr: 1.3824e-06

Epoch 01927: LearningRateScheduler reducing learning rate to 1.3764169115339258e-06.
Epoch 1927/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1727 - lr: 1.3764e-06

Epoch 01928: LearningRateScheduler reducing learning rate to 1.3704872514529293e-06.
Epoch 1928/4000
24/24 - 5s - loss: 0.0622 - val_loss: 0.1650 - lr: 1.3705e-06

Epoch 01929: LearningRateScheduler reducing learning rate to 1.3645831365889245e-06.
Epoch 1929/4000
24/24 - 5s - loss: 0.0621 - val_loss: 0.1761 - lr: 1.3646e-06

Epoch 01930: LearningRateScheduler reducing learning rate to 1.3587044568920763e-06.
Epoch 1930/4000
24/24 - 5s - loss: 0.0623 - val_loss: 0.1674 - lr: 1.3587e-06

Epoch 01931: LearningRateScheduler reducing learning rate to 1.3528511027866504e-06.
Epoch 1931/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1630 - lr: 1.3529e-06

Epoch 01932: LearningRateScheduler reducing learning rate to 1.347022965168967e-06.
Epoch 1932/4000
24/24 - 5s - loss: 0.0617 - val_loss: 0.1734 - lr: 1.3470e-06

Epoch 01933: LearningRateScheduler reducing learning rate to 1.341219935405371e-06.
Epoch 1933/4000
24/24 - 5s - loss: 0.0620 - val_loss: 0.1774 - lr: 1.3412e-06

Epoch 01934: LearningRateScheduler reducing learning rate to 1.335441905330205e-06.
Epoch 1934/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1706 - lr: 1.3354e-06

Epoch 01935: LearningRateScheduler reducing learning rate to 1.3296887672437936e-06.
Epoch 1935/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1739 - lr: 1.3297e-06

Epoch 01936: LearningRateScheduler reducing learning rate to 1.323960413910436e-06.
Epoch 1936/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1721 - lr: 1.3240e-06

Epoch 01937: LearningRateScheduler reducing learning rate to 1.3182567385564061e-06.
Epoch 1937/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1703 - lr: 1.3183e-06

Epoch 01938: LearningRateScheduler reducing learning rate to 1.3125776348679664e-06.
Epoch 1938/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1728 - lr: 1.3126e-06

Epoch 01939: LearningRateScheduler reducing learning rate to 1.306922996989381e-06.
Epoch 1939/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1661 - lr: 1.3069e-06

Epoch 01940: LearningRateScheduler reducing learning rate to 1.3012927195209442e-06.
Epoch 1940/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1716 - lr: 1.3013e-06

Epoch 01941: LearningRateScheduler reducing learning rate to 1.2956866975170184e-06.
Epoch 1941/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1663 - lr: 1.2957e-06

Epoch 01942: LearningRateScheduler reducing learning rate to 1.2901048264840748e-06.
Epoch 1942/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1738 - lr: 1.2901e-06

Epoch 01943: LearningRateScheduler reducing learning rate to 1.2845470023787472e-06.
Epoch 1943/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1670 - lr: 1.2845e-06

Epoch 01944: LearningRateScheduler reducing learning rate to 1.2790131216058928e-06.
Epoch 1944/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1734 - lr: 1.2790e-06

Epoch 01945: LearningRateScheduler reducing learning rate to 1.2735030810166607e-06.
Epoch 1945/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1668 - lr: 1.2735e-06

Epoch 01946: LearningRateScheduler reducing learning rate to 1.2680167779065696e-06.
Epoch 1946/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1707 - lr: 1.2680e-06

Epoch 01947: LearningRateScheduler reducing learning rate to 1.2625541100135927e-06.
Epoch 1947/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1742 - lr: 1.2626e-06

Epoch 01948: LearningRateScheduler reducing learning rate to 1.257114975516253e-06.
Epoch 1948/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1713 - lr: 1.2571e-06

Epoch 01949: LearningRateScheduler reducing learning rate to 1.2516992730317242e-06.
Epoch 1949/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1598 - lr: 1.2517e-06

Epoch 01950: LearningRateScheduler reducing learning rate to 1.2463069016139413e-06.
Epoch 1950/4000
Model saved in ./model/scPDB_1221_pdbid--1950--0.1759--0.0000012.
24/24 - 10s - loss: 0.0627 - val_loss: 0.1759 - lr: 1.2463e-06

Epoch 01951: LearningRateScheduler reducing learning rate to 1.2409377607517187e-06.
Epoch 1951/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1737 - lr: 1.2409e-06

Epoch 01952: LearningRateScheduler reducing learning rate to 1.235591750366878e-06.
Epoch 1952/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1697 - lr: 1.2356e-06

Epoch 01953: LearningRateScheduler reducing learning rate to 1.2302687708123807e-06.
Epoch 1953/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1665 - lr: 1.2303e-06

Epoch 01954: LearningRateScheduler reducing learning rate to 1.2249687228704726e-06.
Epoch 1954/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1728 - lr: 1.2250e-06

Epoch 01955: LearningRateScheduler reducing learning rate to 1.2196915077508328e-06.
Epoch 1955/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1770 - lr: 1.2197e-06

Epoch 01956: LearningRateScheduler reducing learning rate to 1.214437027088734e-06.
Epoch 1956/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1603 - lr: 1.2144e-06

Epoch 01957: LearningRateScheduler reducing learning rate to 1.2092051829432078e-06.
Epoch 1957/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1702 - lr: 1.2092e-06

Epoch 01958: LearningRateScheduler reducing learning rate to 1.2039958777952189e-06.
Epoch 1958/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1743 - lr: 1.2040e-06

Epoch 01959: LearningRateScheduler reducing learning rate to 1.1988090145458487e-06.
Epoch 1959/4000
24/24 - 4s - loss: 0.0626 - val_loss: 0.1685 - lr: 1.1988e-06

Epoch 01960: LearningRateScheduler reducing learning rate to 1.1936444965144848e-06.
Epoch 1960/4000
24/24 - 4s - loss: 0.0618 - val_loss: 0.1686 - lr: 1.1936e-06

Epoch 01961: LearningRateScheduler reducing learning rate to 1.188502227437018e-06.
Epoch 1961/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1689 - lr: 1.1885e-06

Epoch 01962: LearningRateScheduler reducing learning rate to 1.1833821114640493e-06.
Epoch 1962/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1701 - lr: 1.1834e-06

Epoch 01963: LearningRateScheduler reducing learning rate to 1.1782840531591031e-06.
Epoch 1963/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1715 - lr: 1.1783e-06

Epoch 01964: LearningRateScheduler reducing learning rate to 1.1732079574968475e-06.
Epoch 1964/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1758 - lr: 1.1732e-06

Epoch 01965: LearningRateScheduler reducing learning rate to 1.1681537298613242e-06.
Epoch 1965/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1701 - lr: 1.1682e-06

Epoch 01966: LearningRateScheduler reducing learning rate to 1.1631212760441834e-06.
Epoch 1966/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1746 - lr: 1.1631e-06

Epoch 01967: LearningRateScheduler reducing learning rate to 1.1581105022429292e-06.
Epoch 1967/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1671 - lr: 1.1581e-06

Epoch 01968: LearningRateScheduler reducing learning rate to 1.1531213150591713e-06.
Epoch 1968/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1715 - lr: 1.1531e-06

Epoch 01969: LearningRateScheduler reducing learning rate to 1.1481536214968825e-06.
Epoch 1969/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1692 - lr: 1.1482e-06

Epoch 01970: LearningRateScheduler reducing learning rate to 1.1432073289606663e-06.
Epoch 1970/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1762 - lr: 1.1432e-06

Epoch 01971: LearningRateScheduler reducing learning rate to 1.1382823452540317e-06.
Epoch 1971/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1728 - lr: 1.1383e-06

Epoch 01972: LearningRateScheduler reducing learning rate to 1.1333785785776733e-06.
Epoch 1972/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1714 - lr: 1.1334e-06

Epoch 01973: LearningRateScheduler reducing learning rate to 1.1284959375277613e-06.
Epoch 1973/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1686 - lr: 1.1285e-06

Epoch 01974: LearningRateScheduler reducing learning rate to 1.1236343310942367e-06.
Epoch 1974/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1761 - lr: 1.1236e-06

Epoch 01975: LearningRateScheduler reducing learning rate to 1.1187936686591162e-06.
Epoch 1975/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1635 - lr: 1.1188e-06

Epoch 01976: LearningRateScheduler reducing learning rate to 1.1139738599948023e-06.
Epoch 1976/4000
24/24 - 5s - loss: 0.0621 - val_loss: 0.1636 - lr: 1.1140e-06

Epoch 01977: LearningRateScheduler reducing learning rate to 1.109174815262401e-06.
Epoch 1977/4000
24/24 - 5s - loss: 0.0620 - val_loss: 0.1736 - lr: 1.1092e-06

Epoch 01978: LearningRateScheduler reducing learning rate to 1.1043964450100487e-06.
Epoch 1978/4000
24/24 - 5s - loss: 0.0618 - val_loss: 0.1674 - lr: 1.1044e-06

Epoch 01979: LearningRateScheduler reducing learning rate to 1.0996386601712437e-06.
Epoch 1979/4000
24/24 - 5s - loss: 0.0614 - val_loss: 0.1609 - lr: 1.0996e-06

Epoch 01980: LearningRateScheduler reducing learning rate to 1.0949013720631867e-06.
Epoch 1980/4000
24/24 - 5s - loss: 0.0624 - val_loss: 0.1848 - lr: 1.0949e-06

Epoch 01981: LearningRateScheduler reducing learning rate to 1.0901844923851277e-06.
Epoch 1981/4000
24/24 - 5s - loss: 0.0627 - val_loss: 0.1730 - lr: 1.0902e-06

Epoch 01982: LearningRateScheduler reducing learning rate to 1.0854879332167184e-06.
Epoch 1982/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1764 - lr: 1.0855e-06

Epoch 01983: LearningRateScheduler reducing learning rate to 1.0808116070163775e-06.
Epoch 1983/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1692 - lr: 1.0808e-06

Epoch 01984: LearningRateScheduler reducing learning rate to 1.076155426619654e-06.
Epoch 1984/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1662 - lr: 1.0762e-06

Epoch 01985: LearningRateScheduler reducing learning rate to 1.0715193052376064e-06.
Epoch 1985/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1739 - lr: 1.0715e-06

Epoch 01986: LearningRateScheduler reducing learning rate to 1.0669031564551819e-06.
Epoch 1986/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1743 - lr: 1.0669e-06

Epoch 01987: LearningRateScheduler reducing learning rate to 1.0623068942296099e-06.
Epoch 1987/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1731 - lr: 1.0623e-06

Epoch 01988: LearningRateScheduler reducing learning rate to 1.0577304328887937e-06.
Epoch 1988/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1729 - lr: 1.0577e-06

Epoch 01989: LearningRateScheduler reducing learning rate to 1.0531736871297153e-06.
Epoch 1989/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1725 - lr: 1.0532e-06

Epoch 01990: LearningRateScheduler reducing learning rate to 1.0486365720168461e-06.
Epoch 1990/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1732 - lr: 1.0486e-06

Epoch 01991: LearningRateScheduler reducing learning rate to 1.0441190029805637e-06.
Epoch 1991/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1706 - lr: 1.0441e-06

Epoch 01992: LearningRateScheduler reducing learning rate to 1.0396208958155736e-06.
Epoch 1992/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1647 - lr: 1.0396e-06

Epoch 01993: LearningRateScheduler reducing learning rate to 1.035142166679343e-06.
Epoch 1993/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1711 - lr: 1.0351e-06

Epoch 01994: LearningRateScheduler reducing learning rate to 1.0306827320905349e-06.
Epoch 1994/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1607 - lr: 1.0307e-06

Epoch 01995: LearningRateScheduler reducing learning rate to 1.0262425089274535e-06.
Epoch 1995/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1708 - lr: 1.0262e-06

Epoch 01996: LearningRateScheduler reducing learning rate to 1.021821414426495e-06.
Epoch 1996/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1637 - lr: 1.0218e-06

Epoch 01997: LearningRateScheduler reducing learning rate to 1.017419366180604e-06.
Epoch 1997/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1821 - lr: 1.0174e-06

Epoch 01998: LearningRateScheduler reducing learning rate to 1.0130362821377392e-06.
Epoch 1998/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1741 - lr: 1.0130e-06

Epoch 01999: LearningRateScheduler reducing learning rate to 1.008672080599341e-06.
Epoch 1999/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1735 - lr: 1.0087e-06

Epoch 02000: LearningRateScheduler reducing learning rate to 1.0043266802188124e-06.
Epoch 2000/4000
Model saved in ./model/scPDB_1221_pdbid--2000--0.1739--0.0000010.
24/24 - 3s - loss: 0.0617 - val_loss: 0.1739 - lr: 1.0043e-06

Epoch 02001: LearningRateScheduler reducing learning rate to 9.999999999999993e-07.
Epoch 2001/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1755 - lr: 1.0000e-06

Epoch 02002: LearningRateScheduler reducing learning rate to 9.956919592956837e-07.
Epoch 2002/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1751 - lr: 9.9569e-07

Epoch 02003: LearningRateScheduler reducing learning rate to 9.914024778060782e-07.
Epoch 2003/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1668 - lr: 9.9140e-07

Epoch 02004: LearningRateScheduler reducing learning rate to 9.8713147557733e-07.
Epoch 2004/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1738 - lr: 9.8713e-07

Epoch 02005: LearningRateScheduler reducing learning rate to 9.828788730000316e-07.
Epoch 2005/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1696 - lr: 9.8288e-07

Epoch 02006: LearningRateScheduler reducing learning rate to 9.786445908077355e-07.
Epoch 2006/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1724 - lr: 9.7864e-07

Epoch 02007: LearningRateScheduler reducing learning rate to 9.744285500754774e-07.
Epoch 2007/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1740 - lr: 9.7443e-07

Epoch 02008: LearningRateScheduler reducing learning rate to 9.702306722183049e-07.
Epoch 2008/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1740 - lr: 9.7023e-07

Epoch 02009: LearningRateScheduler reducing learning rate to 9.66050878989813e-07.
Epoch 2009/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1779 - lr: 9.6605e-07

Epoch 02010: LearningRateScheduler reducing learning rate to 9.61889092480685e-07.
Epoch 2010/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1671 - lr: 9.6189e-07

Epoch 02011: LearningRateScheduler reducing learning rate to 9.577452351172408e-07.
Epoch 2011/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1749 - lr: 9.5775e-07

Epoch 02012: LearningRateScheduler reducing learning rate to 9.536192296599913e-07.
Epoch 2012/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1721 - lr: 9.5362e-07

Epoch 02013: LearningRateScheduler reducing learning rate to 9.495109992021978e-07.
Epoch 2013/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1640 - lr: 9.4951e-07

Epoch 02014: LearningRateScheduler reducing learning rate to 9.454204671684393e-07.
Epoch 2014/4000
24/24 - 5s - loss: 0.0620 - val_loss: 0.1750 - lr: 9.4542e-07

Epoch 02015: LearningRateScheduler reducing learning rate to 9.413475573131845e-07.
Epoch 2015/4000
24/24 - 5s - loss: 0.0621 - val_loss: 0.1636 - lr: 9.4135e-07

Epoch 02016: LearningRateScheduler reducing learning rate to 9.372921937193712e-07.
Epoch 2016/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1661 - lr: 9.3729e-07

Epoch 02017: LearningRateScheduler reducing learning rate to 9.332543007969907e-07.
Epoch 2017/4000
24/24 - 5s - loss: 0.0618 - val_loss: 0.1736 - lr: 9.3325e-07

Epoch 02018: LearningRateScheduler reducing learning rate to 9.292338032816796e-07.
Epoch 2018/4000
24/24 - 4s - loss: 0.0618 - val_loss: 0.1746 - lr: 9.2923e-07

Epoch 02019: LearningRateScheduler reducing learning rate to 9.25230626233316e-07.
Epoch 2019/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1684 - lr: 9.2523e-07

Epoch 02020: LearningRateScheduler reducing learning rate to 9.212446950346234e-07.
Epoch 2020/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1737 - lr: 9.2124e-07

Epoch 02021: LearningRateScheduler reducing learning rate to 9.172759353897794e-07.
Epoch 2021/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1700 - lr: 9.1728e-07

Epoch 02022: LearningRateScheduler reducing learning rate to 9.133242733230309e-07.
Epoch 2022/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1685 - lr: 9.1332e-07

Epoch 02023: LearningRateScheduler reducing learning rate to 9.093896351773158e-07.
Epoch 2023/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1740 - lr: 9.0939e-07

Epoch 02024: LearningRateScheduler reducing learning rate to 9.05471947612889e-07.
Epoch 2024/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1660 - lr: 9.0547e-07

Epoch 02025: LearningRateScheduler reducing learning rate to 9.015711376059567e-07.
Epoch 2025/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1773 - lr: 9.0157e-07

Epoch 02026: LearningRateScheduler reducing learning rate to 8.976871324473141e-07.
Epoch 2026/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1675 - lr: 8.9769e-07

Epoch 02027: LearningRateScheduler reducing learning rate to 8.938198597409905e-07.
Epoch 2027/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1729 - lr: 8.9382e-07

Epoch 02028: LearningRateScheduler reducing learning rate to 8.899692474029006e-07.
Epoch 2028/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1689 - lr: 8.8997e-07

Epoch 02029: LearningRateScheduler reducing learning rate to 8.861352236594997e-07.
Epoch 2029/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1693 - lr: 8.8614e-07

Epoch 02030: LearningRateScheduler reducing learning rate to 8.823177170464467e-07.
Epoch 2030/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1778 - lr: 8.8232e-07

Epoch 02031: LearningRateScheduler reducing learning rate to 8.785166564072718e-07.
Epoch 2031/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1678 - lr: 8.7852e-07

Epoch 02032: LearningRateScheduler reducing learning rate to 8.747319708920499e-07.
Epoch 2032/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1673 - lr: 8.7473e-07

Epoch 02033: LearningRateScheduler reducing learning rate to 8.709635899560807e-07.
Epoch 2033/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1789 - lr: 8.7096e-07

Epoch 02034: LearningRateScheduler reducing learning rate to 8.672114433585728e-07.
Epoch 2034/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1705 - lr: 8.6721e-07

Epoch 02035: LearningRateScheduler reducing learning rate to 8.63475461161335e-07.
Epoch 2035/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1744 - lr: 8.6348e-07

Epoch 02036: LearningRateScheduler reducing learning rate to 8.597555737274742e-07.
Epoch 2036/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1638 - lr: 8.5976e-07

Epoch 02037: LearningRateScheduler reducing learning rate to 8.56051711720094e-07.
Epoch 2037/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1746 - lr: 8.5605e-07

Epoch 02038: LearningRateScheduler reducing learning rate to 8.523638061010046e-07.
Epoch 2038/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1705 - lr: 8.5236e-07

Epoch 02039: LearningRateScheduler reducing learning rate to 8.48691788129436e-07.
Epoch 2039/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1672 - lr: 8.4869e-07

Epoch 02040: LearningRateScheduler reducing learning rate to 8.450355893607559e-07.
Epoch 2040/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1774 - lr: 8.4504e-07

Epoch 02041: LearningRateScheduler reducing learning rate to 8.413951416451944e-07.
Epoch 2041/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1730 - lr: 8.4140e-07

Epoch 02042: LearningRateScheduler reducing learning rate to 8.377703771265735e-07.
Epoch 2042/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1658 - lr: 8.3777e-07

Epoch 02043: LearningRateScheduler reducing learning rate to 8.341612282410422e-07.
Epoch 2043/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1720 - lr: 8.3416e-07

Epoch 02044: LearningRateScheduler reducing learning rate to 8.305676277158178e-07.
Epoch 2044/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1732 - lr: 8.3057e-07

Epoch 02045: LearningRateScheduler reducing learning rate to 8.269895085679312e-07.
Epoch 2045/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1742 - lr: 8.2699e-07

Epoch 02046: LearningRateScheduler reducing learning rate to 8.234268041029785e-07.
Epoch 2046/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1680 - lr: 8.2343e-07

Epoch 02047: LearningRateScheduler reducing learning rate to 8.198794479138782e-07.
Epoch 2047/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1677 - lr: 8.1988e-07

Epoch 02048: LearningRateScheduler reducing learning rate to 8.163473738796334e-07.
Epoch 2048/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1686 - lr: 8.1635e-07

Epoch 02049: LearningRateScheduler reducing learning rate to 8.128305161640988e-07.
Epoch 2049/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1686 - lr: 8.1283e-07

Epoch 02050: LearningRateScheduler reducing learning rate to 8.093288092147538e-07.
Epoch 2050/4000
Model saved in ./model/scPDB_1221_pdbid--2050--0.1729--0.0000008.
24/24 - 4s - loss: 0.0619 - val_loss: 0.1729 - lr: 8.0933e-07

Epoch 02051: LearningRateScheduler reducing learning rate to 8.058421877614813e-07.
Epoch 2051/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1612 - lr: 8.0584e-07

Epoch 02052: LearningRateScheduler reducing learning rate to 8.023705868153501e-07.
Epoch 2052/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1801 - lr: 8.0237e-07

Epoch 02053: LearningRateScheduler reducing learning rate to 7.989139416674039e-07.
Epoch 2053/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1710 - lr: 7.9891e-07

Epoch 02054: LearningRateScheduler reducing learning rate to 7.954721878874553e-07.
Epoch 2054/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1753 - lr: 7.9547e-07

Epoch 02055: LearningRateScheduler reducing learning rate to 7.920452613228851e-07.
Epoch 2055/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1672 - lr: 7.9205e-07

Epoch 02056: LearningRateScheduler reducing learning rate to 7.886330980974458e-07.
Epoch 2056/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1730 - lr: 7.8863e-07

Epoch 02057: LearningRateScheduler reducing learning rate to 7.852356346100714e-07.
Epoch 2057/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1705 - lr: 7.8524e-07

Epoch 02058: LearningRateScheduler reducing learning rate to 7.818528075336921e-07.
Epoch 2058/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1751 - lr: 7.8185e-07

Epoch 02059: LearningRateScheduler reducing learning rate to 7.784845538140534e-07.
Epoch 2059/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1795 - lr: 7.7848e-07

Epoch 02060: LearningRateScheduler reducing learning rate to 7.751308106685414e-07.
Epoch 2060/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1656 - lr: 7.7513e-07

Epoch 02061: LearningRateScheduler reducing learning rate to 7.717915155850121e-07.
Epoch 2061/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1710 - lr: 7.7179e-07

Epoch 02062: LearningRateScheduler reducing learning rate to 7.684666063206263e-07.
Epoch 2062/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1704 - lr: 7.6847e-07

Epoch 02063: LearningRateScheduler reducing learning rate to 7.651560209006898e-07.
Epoch 2063/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1718 - lr: 7.6516e-07

Epoch 02064: LearningRateScheduler reducing learning rate to 7.618596976174974e-07.
Epoch 2064/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1619 - lr: 7.6186e-07

Epoch 02065: LearningRateScheduler reducing learning rate to 7.585775750291835e-07.
Epoch 2065/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1660 - lr: 7.5858e-07

Epoch 02066: LearningRateScheduler reducing learning rate to 7.553095919585767e-07.
Epoch 2066/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1839 - lr: 7.5531e-07

Epoch 02067: LearningRateScheduler reducing learning rate to 7.520556874920591e-07.
Epoch 2067/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1698 - lr: 7.5206e-07

Epoch 02068: LearningRateScheduler reducing learning rate to 7.48815800978431e-07.
Epoch 2068/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1738 - lr: 7.4882e-07

Epoch 02069: LearningRateScheduler reducing learning rate to 7.455898720277812e-07.
Epoch 2069/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1696 - lr: 7.4559e-07

Epoch 02070: LearningRateScheduler reducing learning rate to 7.4237784051036e-07.
Epoch 2070/4000
24/24 - 4s - loss: 0.0618 - val_loss: 0.1629 - lr: 7.4238e-07

Epoch 02071: LearningRateScheduler reducing learning rate to 7.391796465554594e-07.
Epoch 2071/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1691 - lr: 7.3918e-07

Epoch 02072: LearningRateScheduler reducing learning rate to 7.359952305502967e-07.
Epoch 2072/4000
24/24 - 4s - loss: 0.0615 - val_loss: 0.1680 - lr: 7.3600e-07

Epoch 02073: LearningRateScheduler reducing learning rate to 7.328245331389039e-07.
Epoch 2073/4000
24/24 - 4s - loss: 0.0618 - val_loss: 0.1667 - lr: 7.3282e-07

Epoch 02074: LearningRateScheduler reducing learning rate to 7.296674952210203e-07.
Epoch 2074/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1734 - lr: 7.2967e-07

Epoch 02075: LearningRateScheduler reducing learning rate to 7.265240579509921e-07.
Epoch 2075/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1650 - lr: 7.2652e-07

Epoch 02076: LearningRateScheduler reducing learning rate to 7.233941627366746e-07.
Epoch 2076/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1740 - lr: 7.2339e-07

Epoch 02077: LearningRateScheduler reducing learning rate to 7.202777512383408e-07.
Epoch 2077/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1708 - lr: 7.2028e-07

Epoch 02078: LearningRateScheduler reducing learning rate to 7.171747653675929e-07.
Epoch 2078/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1701 - lr: 7.1717e-07

Epoch 02079: LearningRateScheduler reducing learning rate to 7.140851472862812e-07.
Epoch 2079/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1767 - lr: 7.1409e-07

Epoch 02080: LearningRateScheduler reducing learning rate to 7.110088394054247e-07.
Epoch 2080/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1670 - lr: 7.1101e-07

Epoch 02081: LearningRateScheduler reducing learning rate to 7.079457843841378e-07.
Epoch 2081/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1713 - lr: 7.0795e-07

Epoch 02082: LearningRateScheduler reducing learning rate to 7.048959251285623e-07.
Epoch 2082/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1738 - lr: 7.0490e-07

Epoch 02083: LearningRateScheduler reducing learning rate to 7.018592047908022e-07.
Epoch 2083/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1714 - lr: 7.0186e-07

Epoch 02084: LearningRateScheduler reducing learning rate to 6.988355667678641e-07.
Epoch 2084/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1810 - lr: 6.9884e-07

Epoch 02085: LearningRateScheduler reducing learning rate to 6.958249547006046e-07.
Epoch 2085/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1716 - lr: 6.9582e-07

Epoch 02086: LearningRateScheduler reducing learning rate to 6.928273124726759e-07.
Epoch 2086/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1741 - lr: 6.9283e-07

Epoch 02087: LearningRateScheduler reducing learning rate to 6.898425842094819e-07.
Epoch 2087/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1712 - lr: 6.8984e-07

Epoch 02088: LearningRateScheduler reducing learning rate to 6.86870714277137e-07.
Epoch 2088/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1682 - lr: 6.8687e-07

Epoch 02089: LearningRateScheduler reducing learning rate to 6.839116472814287e-07.
Epoch 2089/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1674 - lr: 6.8391e-07

Epoch 02090: LearningRateScheduler reducing learning rate to 6.809653280667848e-07.
Epoch 2090/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1667 - lr: 6.8097e-07

Epoch 02091: LearningRateScheduler reducing learning rate to 6.780317017152453e-07.
Epoch 2091/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1741 - lr: 6.7803e-07

Epoch 02092: LearningRateScheduler reducing learning rate to 6.751107135454397e-07.
Epoch 2092/4000
24/24 - 3s - loss: 0.0632 - val_loss: 0.1673 - lr: 6.7511e-07

Epoch 02093: LearningRateScheduler reducing learning rate to 6.722023091115662e-07.
Epoch 2093/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1693 - lr: 6.7220e-07

Epoch 02094: LearningRateScheduler reducing learning rate to 6.693064342023787e-07.
Epoch 2094/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1699 - lr: 6.6931e-07

Epoch 02095: LearningRateScheduler reducing learning rate to 6.664230348401743e-07.
Epoch 2095/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1728 - lr: 6.6642e-07

Epoch 02096: LearningRateScheduler reducing learning rate to 6.635520572797893e-07.
Epoch 2096/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1712 - lr: 6.6355e-07

Epoch 02097: LearningRateScheduler reducing learning rate to 6.606934480075955e-07.
Epoch 2097/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1712 - lr: 6.6069e-07

Epoch 02098: LearningRateScheduler reducing learning rate to 6.578471537405041e-07.
Epoch 2098/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1719 - lr: 6.5785e-07

Epoch 02099: LearningRateScheduler reducing learning rate to 6.550131214249718e-07.
Epoch 2099/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1760 - lr: 6.5501e-07

Epoch 02100: LearningRateScheduler reducing learning rate to 6.521912982360121e-07.
Epoch 2100/4000
Model saved in ./model/scPDB_1221_pdbid--2100--0.1717--0.0000007.
24/24 - 3s - loss: 0.0615 - val_loss: 0.1717 - lr: 6.5219e-07

Epoch 02101: LearningRateScheduler reducing learning rate to 6.493816315762109e-07.
Epoch 2101/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1701 - lr: 6.4938e-07

Epoch 02102: LearningRateScheduler reducing learning rate to 6.465840690747457e-07.
Epoch 2102/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1715 - lr: 6.4658e-07

Epoch 02103: LearningRateScheduler reducing learning rate to 6.437985585864095e-07.
Epoch 2103/4000
24/24 - 3s - loss: 0.0630 - val_loss: 0.1739 - lr: 6.4380e-07

Epoch 02104: LearningRateScheduler reducing learning rate to 6.410250481906396e-07.
Epoch 2104/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1736 - lr: 6.4103e-07

Epoch 02105: LearningRateScheduler reducing learning rate to 6.382634861905483e-07.
Epoch 2105/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1677 - lr: 6.3826e-07

Epoch 02106: LearningRateScheduler reducing learning rate to 6.35513821111961e-07.
Epoch 2106/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1649 - lr: 6.3551e-07

Epoch 02107: LearningRateScheduler reducing learning rate to 6.327760017024555e-07.
Epoch 2107/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1734 - lr: 6.3278e-07

Epoch 02108: LearningRateScheduler reducing learning rate to 6.300499769304072e-07.
Epoch 2108/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1747 - lr: 6.3005e-07

Epoch 02109: LearningRateScheduler reducing learning rate to 6.273356959840378e-07.
Epoch 2109/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1748 - lr: 6.2734e-07

Epoch 02110: LearningRateScheduler reducing learning rate to 6.246331082704684e-07.
Epoch 2110/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1705 - lr: 6.2463e-07

Epoch 02111: LearningRateScheduler reducing learning rate to 6.21942163414776e-07.
Epoch 2111/4000
24/24 - 4s - loss: 0.0630 - val_loss: 0.1822 - lr: 6.2194e-07

Epoch 02112: LearningRateScheduler reducing learning rate to 6.192628112590549e-07.
Epoch 2112/4000
24/24 - 4s - loss: 0.0616 - val_loss: 0.1703 - lr: 6.1926e-07

Epoch 02113: LearningRateScheduler reducing learning rate to 6.16595001861482e-07.
Epoch 2113/4000
24/24 - 4s - loss: 0.0622 - val_loss: 0.1696 - lr: 6.1660e-07

Epoch 02114: LearningRateScheduler reducing learning rate to 6.13938685495385e-07.
Epoch 2114/4000
24/24 - 4s - loss: 0.0616 - val_loss: 0.1733 - lr: 6.1394e-07

Epoch 02115: LearningRateScheduler reducing learning rate to 6.112938126483169e-07.
Epoch 2115/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1684 - lr: 6.1129e-07

Epoch 02116: LearningRateScheduler reducing learning rate to 6.086603340211316e-07.
Epoch 2116/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1766 - lr: 6.0866e-07

Epoch 02117: LearningRateScheduler reducing learning rate to 6.060382005270661e-07.
Epoch 2117/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1678 - lr: 6.0604e-07

Epoch 02118: LearningRateScheduler reducing learning rate to 6.034273632908253e-07.
Epoch 2118/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1725 - lr: 6.0343e-07

Epoch 02119: LearningRateScheduler reducing learning rate to 6.008277736476705e-07.
Epoch 2119/4000
24/24 - 4s - loss: 0.0622 - val_loss: 0.1631 - lr: 6.0083e-07

Epoch 02120: LearningRateScheduler reducing learning rate to 5.98239383142513e-07.
Epoch 2120/4000
24/24 - 4s - loss: 0.0622 - val_loss: 0.1781 - lr: 5.9824e-07

Epoch 02121: LearningRateScheduler reducing learning rate to 5.956621435290103e-07.
Epoch 2121/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1758 - lr: 5.9566e-07

Epoch 02122: LearningRateScheduler reducing learning rate to 5.930960067686675e-07.
Epoch 2122/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1714 - lr: 5.9310e-07

Epoch 02123: LearningRateScheduler reducing learning rate to 5.905409250299408e-07.
Epoch 2123/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1708 - lr: 5.9054e-07

Epoch 02124: LearningRateScheduler reducing learning rate to 5.879968506873477e-07.
Epoch 2124/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1710 - lr: 5.8800e-07

Epoch 02125: LearningRateScheduler reducing learning rate to 5.854637363205771e-07.
Epoch 2125/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1735 - lr: 5.8546e-07

Epoch 02126: LearningRateScheduler reducing learning rate to 5.829415347136073e-07.
Epoch 2126/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1625 - lr: 5.8294e-07

Epoch 02127: LearningRateScheduler reducing learning rate to 5.804301988538248e-07.
Epoch 2127/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1684 - lr: 5.8043e-07

Epoch 02128: LearningRateScheduler reducing learning rate to 5.779296819311485e-07.
Epoch 2128/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1769 - lr: 5.7793e-07

Epoch 02129: LearningRateScheduler reducing learning rate to 5.754399373371569e-07.
Epoch 2129/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1663 - lr: 5.7544e-07

Epoch 02130: LearningRateScheduler reducing learning rate to 5.729609186642196e-07.
Epoch 2130/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1767 - lr: 5.7296e-07

Epoch 02131: LearningRateScheduler reducing learning rate to 5.704925797046319e-07.
Epoch 2131/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1678 - lr: 5.7049e-07

Epoch 02132: LearningRateScheduler reducing learning rate to 5.680348744497543e-07.
Epoch 2132/4000
24/24 - 3s - loss: 0.0635 - val_loss: 0.1711 - lr: 5.6803e-07

Epoch 02133: LearningRateScheduler reducing learning rate to 5.655877570891534e-07.
Epoch 2133/4000
24/24 - 3s - loss: 0.0613 - val_loss: 0.1717 - lr: 5.6559e-07

Epoch 02134: LearningRateScheduler reducing learning rate to 5.631511820097507e-07.
Epoch 2134/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1645 - lr: 5.6315e-07

Epoch 02135: LearningRateScheduler reducing learning rate to 5.607251037949692e-07.
Epoch 2135/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1730 - lr: 5.6073e-07

Epoch 02136: LearningRateScheduler reducing learning rate to 5.583094772238889e-07.
Epoch 2136/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1728 - lr: 5.5831e-07

Epoch 02137: LearningRateScheduler reducing learning rate to 5.559042572704031e-07.
Epoch 2137/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1715 - lr: 5.5590e-07

Epoch 02138: LearningRateScheduler reducing learning rate to 5.535093991023798e-07.
Epoch 2138/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1689 - lr: 5.5351e-07

Epoch 02139: LearningRateScheduler reducing learning rate to 5.511248580808254e-07.
Epoch 2139/4000
24/24 - 3s - loss: 0.0615 - val_loss: 0.1775 - lr: 5.5112e-07

Epoch 02140: LearningRateScheduler reducing learning rate to 5.48750589759053e-07.
Epoch 2140/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1756 - lr: 5.4875e-07

Epoch 02141: LearningRateScheduler reducing learning rate to 5.463865498818537e-07.
Epoch 2141/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1718 - lr: 5.4639e-07

Epoch 02142: LearningRateScheduler reducing learning rate to 5.440326943846721e-07.
Epoch 2142/4000
24/24 - 4s - loss: 0.0629 - val_loss: 0.1743 - lr: 5.4403e-07

Epoch 02143: LearningRateScheduler reducing learning rate to 5.416889793927845e-07.
Epoch 2143/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1621 - lr: 5.4169e-07

Epoch 02144: LearningRateScheduler reducing learning rate to 5.393553612204811e-07.
Epoch 2144/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1848 - lr: 5.3936e-07

Epoch 02145: LearningRateScheduler reducing learning rate to 5.370317963702523e-07.
Epoch 2145/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1652 - lr: 5.3703e-07

Epoch 02146: LearningRateScheduler reducing learning rate to 5.347182415319775e-07.
Epoch 2146/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1657 - lr: 5.3472e-07

Epoch 02147: LearningRateScheduler reducing learning rate to 5.324146535821177e-07.
Epoch 2147/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1677 - lr: 5.3241e-07

Epoch 02148: LearningRateScheduler reducing learning rate to 5.301209895829118e-07.
Epoch 2148/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1809 - lr: 5.3012e-07

Epoch 02149: LearningRateScheduler reducing learning rate to 5.278372067815764e-07.
Epoch 2149/4000
24/24 - 4s - loss: 0.0616 - val_loss: 0.1628 - lr: 5.2784e-07

Epoch 02150: LearningRateScheduler reducing learning rate to 5.255632626095091e-07.
Epoch 2150/4000
Model saved in ./model/scPDB_1221_pdbid--2150--0.1767--0.0000005.
24/24 - 5s - loss: 0.0624 - val_loss: 0.1767 - lr: 5.2556e-07

Epoch 02151: LearningRateScheduler reducing learning rate to 5.232991146814944e-07.
Epoch 2151/4000
24/24 - 4s - loss: 0.0611 - val_loss: 0.1766 - lr: 5.2330e-07

Epoch 02152: LearningRateScheduler reducing learning rate to 5.210447207949141e-07.
Epoch 2152/4000
24/24 - 4s - loss: 0.0630 - val_loss: 0.1731 - lr: 5.2104e-07

Epoch 02153: LearningRateScheduler reducing learning rate to 5.188000389289608e-07.
Epoch 2153/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1769 - lr: 5.1880e-07

Epoch 02154: LearningRateScheduler reducing learning rate to 5.165650272438543e-07.
Epoch 2154/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1664 - lr: 5.1657e-07

Epoch 02155: LearningRateScheduler reducing learning rate to 5.143396440800618e-07.
Epoch 2155/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1724 - lr: 5.1434e-07

Epoch 02156: LearningRateScheduler reducing learning rate to 5.121238479575217e-07.
Epoch 2156/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1908 - lr: 5.1212e-07

Epoch 02157: LearningRateScheduler reducing learning rate to 5.099175975748698e-07.
Epoch 2157/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1618 - lr: 5.0992e-07

Epoch 02158: LearningRateScheduler reducing learning rate to 5.077208518086704e-07.
Epoch 2158/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1686 - lr: 5.0772e-07

Epoch 02159: LearningRateScheduler reducing learning rate to 5.055335697126489e-07.
Epoch 2159/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1691 - lr: 5.0553e-07

Epoch 02160: LearningRateScheduler reducing learning rate to 5.033557105169287e-07.
Epoch 2160/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1673 - lr: 5.0336e-07

Epoch 02161: LearningRateScheduler reducing learning rate to 5.011872336272721e-07.
Epoch 2161/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1680 - lr: 5.0119e-07

Epoch 02162: LearningRateScheduler reducing learning rate to 4.990280986243223e-07.
Epoch 2162/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1703 - lr: 4.9903e-07

Epoch 02163: LearningRateScheduler reducing learning rate to 4.968782652628516e-07.
Epoch 2163/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1730 - lr: 4.9688e-07

Epoch 02164: LearningRateScheduler reducing learning rate to 4.947376934710094e-07.
Epoch 2164/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1764 - lr: 4.9474e-07

Epoch 02165: LearningRateScheduler reducing learning rate to 4.92606343349577e-07.
Epoch 2165/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1725 - lr: 4.9261e-07

Epoch 02166: LearningRateScheduler reducing learning rate to 4.904841751712229e-07.
Epoch 2166/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1678 - lr: 4.9048e-07

Epoch 02167: LearningRateScheduler reducing learning rate to 4.883711493797626e-07.
Epoch 2167/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1783 - lr: 4.8837e-07

Epoch 02168: LearningRateScheduler reducing learning rate to 4.862672265894211e-07.
Epoch 2168/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1700 - lr: 4.8627e-07

Epoch 02169: LearningRateScheduler reducing learning rate to 4.841723675840992e-07.
Epoch 2169/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1614 - lr: 4.8417e-07

Epoch 02170: LearningRateScheduler reducing learning rate to 4.82086533316642e-07.
Epoch 2170/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1769 - lr: 4.8209e-07

Epoch 02171: LearningRateScheduler reducing learning rate to 4.800096849081115e-07.
Epoch 2171/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1653 - lr: 4.8001e-07

Epoch 02172: LearningRateScheduler reducing learning rate to 4.779417836470616e-07.
Epoch 2172/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1744 - lr: 4.7794e-07

Epoch 02173: LearningRateScheduler reducing learning rate to 4.758827909888168e-07.
Epoch 2173/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1683 - lr: 4.7588e-07

Epoch 02174: LearningRateScheduler reducing learning rate to 4.738326685547536e-07.
Epoch 2174/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1769 - lr: 4.7383e-07

Epoch 02175: LearningRateScheduler reducing learning rate to 4.717913781315852e-07.
Epoch 2175/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1745 - lr: 4.7179e-07

Epoch 02176: LearningRateScheduler reducing learning rate to 4.6975888167064915e-07.
Epoch 2176/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1757 - lr: 4.6976e-07

Epoch 02177: LearningRateScheduler reducing learning rate to 4.6773514128719815e-07.
Epoch 2177/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1693 - lr: 4.6774e-07

Epoch 02178: LearningRateScheduler reducing learning rate to 4.6572011925969403e-07.
Epoch 2178/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1695 - lr: 4.6572e-07

Epoch 02179: LearningRateScheduler reducing learning rate to 4.6371377802910454e-07.
Epoch 2179/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1746 - lr: 4.6371e-07

Epoch 02180: LearningRateScheduler reducing learning rate to 4.617160801982031e-07.
Epoch 2180/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1675 - lr: 4.6172e-07

Epoch 02181: LearningRateScheduler reducing learning rate to 4.5972698853087174e-07.
Epoch 2181/4000
24/24 - 3s - loss: 0.0631 - val_loss: 0.1761 - lr: 4.5973e-07

Epoch 02182: LearningRateScheduler reducing learning rate to 4.5774646595140823e-07.
Epoch 2182/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1713 - lr: 4.5775e-07

Epoch 02183: LearningRateScheduler reducing learning rate to 4.5577447554383294e-07.
Epoch 2183/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1693 - lr: 4.5577e-07

Epoch 02184: LearningRateScheduler reducing learning rate to 4.5381098055120195e-07.
Epoch 2184/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1732 - lr: 4.5381e-07

Epoch 02185: LearningRateScheduler reducing learning rate to 4.5185594437492196e-07.
Epoch 2185/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1721 - lr: 4.5186e-07

Epoch 02186: LearningRateScheduler reducing learning rate to 4.499093305740678e-07.
Epoch 2186/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1713 - lr: 4.4991e-07

Epoch 02187: LearningRateScheduler reducing learning rate to 4.479711028647033e-07.
Epoch 2187/4000
24/24 - 3s - loss: 0.0629 - val_loss: 0.1686 - lr: 4.4797e-07

Epoch 02188: LearningRateScheduler reducing learning rate to 4.460412251192049e-07.
Epoch 2188/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1698 - lr: 4.4604e-07

Epoch 02189: LearningRateScheduler reducing learning rate to 4.4411966136558855e-07.
Epoch 2189/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1697 - lr: 4.4412e-07

Epoch 02190: LearningRateScheduler reducing learning rate to 4.4220637578683873e-07.
Epoch 2190/4000
24/24 - 3s - loss: 0.0633 - val_loss: 0.1690 - lr: 4.4221e-07

Epoch 02191: LearningRateScheduler reducing learning rate to 4.4030133272024107e-07.
Epoch 2191/4000
24/24 - 3s - loss: 0.0612 - val_loss: 0.1694 - lr: 4.4030e-07

Epoch 02192: LearningRateScheduler reducing learning rate to 4.384044966567178e-07.
Epoch 2192/4000
24/24 - 3s - loss: 0.0626 - val_loss: 0.1691 - lr: 4.3840e-07

Epoch 02193: LearningRateScheduler reducing learning rate to 4.365158322401656e-07.
Epoch 2193/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1756 - lr: 4.3652e-07

Epoch 02194: LearningRateScheduler reducing learning rate to 4.346353042667968e-07.
Epoch 2194/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1754 - lr: 4.3464e-07

Epoch 02195: LearningRateScheduler reducing learning rate to 4.327628776844828e-07.
Epoch 2195/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1661 - lr: 4.3276e-07

Epoch 02196: LearningRateScheduler reducing learning rate to 4.308985175921012e-07.
Epoch 2196/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1799 - lr: 4.3090e-07

Epoch 02197: LearningRateScheduler reducing learning rate to 4.2904218923888514e-07.
Epoch 2197/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1719 - lr: 4.2904e-07

Epoch 02198: LearningRateScheduler reducing learning rate to 4.2719385802377534e-07.
Epoch 2198/4000
24/24 - 3s - loss: 0.0628 - val_loss: 0.1699 - lr: 4.2719e-07

Epoch 02199: LearningRateScheduler reducing learning rate to 4.253534894947752e-07.
Epoch 2199/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1671 - lr: 4.2535e-07

Epoch 02200: LearningRateScheduler reducing learning rate to 4.23521049348309e-07.
Epoch 2200/4000
Model saved in ./model/scPDB_1221_pdbid--2200--0.1741--0.0000004.
24/24 - 4s - loss: 0.0621 - val_loss: 0.1741 - lr: 4.2352e-07

Epoch 02201: LearningRateScheduler reducing learning rate to 4.21696503428582e-07.
Epoch 2201/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1743 - lr: 4.2170e-07

Epoch 02202: LearningRateScheduler reducing learning rate to 4.1987981772694405e-07.
Epoch 2202/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1688 - lr: 4.1988e-07

Epoch 02203: LearningRateScheduler reducing learning rate to 4.180709583812557e-07.
Epoch 2203/4000
24/24 - 4s - loss: 0.0616 - val_loss: 0.1630 - lr: 4.1807e-07

Epoch 02204: LearningRateScheduler reducing learning rate to 4.16269891675257e-07.
Epoch 2204/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1721 - lr: 4.1627e-07

Epoch 02205: LearningRateScheduler reducing learning rate to 4.144765840379389e-07.
Epoch 2205/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1695 - lr: 4.1448e-07

Epoch 02206: LearningRateScheduler reducing learning rate to 4.1269100204291774e-07.
Epoch 2206/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1767 - lr: 4.1269e-07

Epoch 02207: LearningRateScheduler reducing learning rate to 4.1091311240781204e-07.
Epoch 2207/4000
24/24 - 4s - loss: 0.0626 - val_loss: 0.1699 - lr: 4.1091e-07

Epoch 02208: LearningRateScheduler reducing learning rate to 4.091428819936221e-07.
Epoch 2208/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1723 - lr: 4.0914e-07

Epoch 02209: LearningRateScheduler reducing learning rate to 4.0738027780411255e-07.
Epoch 2209/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1744 - lr: 4.0738e-07

Epoch 02210: LearningRateScheduler reducing learning rate to 4.05625266985197e-07.
Epoch 2210/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1713 - lr: 4.0563e-07

Epoch 02211: LearningRateScheduler reducing learning rate to 4.038778168243258e-07.
Epoch 2211/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1715 - lr: 4.0388e-07

Epoch 02212: LearningRateScheduler reducing learning rate to 4.021378947498765e-07.
Epoch 2212/4000
24/24 - 4s - loss: 0.0611 - val_loss: 0.1701 - lr: 4.0214e-07

Epoch 02213: LearningRateScheduler reducing learning rate to 4.004054683305462e-07.
Epoch 2213/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1733 - lr: 4.0041e-07

Epoch 02214: LearningRateScheduler reducing learning rate to 3.9868050527474763e-07.
Epoch 2214/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1694 - lr: 3.9868e-07

Epoch 02215: LearningRateScheduler reducing learning rate to 3.969629734300069e-07.
Epoch 2215/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1735 - lr: 3.9696e-07

Epoch 02216: LearningRateScheduler reducing learning rate to 3.952528407823642e-07.
Epoch 2216/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1657 - lr: 3.9525e-07

Epoch 02217: LearningRateScheduler reducing learning rate to 3.9355007545577735e-07.
Epoch 2217/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1752 - lr: 3.9355e-07

Epoch 02218: LearningRateScheduler reducing learning rate to 3.9185464571152734e-07.
Epoch 2218/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1728 - lr: 3.9185e-07

Epoch 02219: LearningRateScheduler reducing learning rate to 3.901665199476269e-07.
Epoch 2219/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1656 - lr: 3.9017e-07

Epoch 02220: LearningRateScheduler reducing learning rate to 3.884856666982313e-07.
Epoch 2220/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1708 - lr: 3.8849e-07

Epoch 02221: LearningRateScheduler reducing learning rate to 3.868120546330521e-07.
Epoch 2221/4000
24/24 - 3s - loss: 0.0627 - val_loss: 0.1714 - lr: 3.8681e-07

Epoch 02222: LearningRateScheduler reducing learning rate to 3.851456525567729e-07.
Epoch 2222/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1676 - lr: 3.8515e-07

Epoch 02223: LearningRateScheduler reducing learning rate to 3.834864294084681e-07.
Epoch 2223/4000
24/24 - 3s - loss: 0.0617 - val_loss: 0.1726 - lr: 3.8349e-07

Epoch 02224: LearningRateScheduler reducing learning rate to 3.8183435426102373e-07.
Epoch 2224/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1728 - lr: 3.8183e-07

Epoch 02225: LearningRateScheduler reducing learning rate to 3.8018939632056115e-07.
Epoch 2225/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1657 - lr: 3.8019e-07

Epoch 02226: LearningRateScheduler reducing learning rate to 3.7855152492586295e-07.
Epoch 2226/4000
24/24 - 3s - loss: 0.0619 - val_loss: 0.1781 - lr: 3.7855e-07

Epoch 02227: LearningRateScheduler reducing learning rate to 3.7692070954780156e-07.
Epoch 2227/4000
24/24 - 3s - loss: 0.0625 - val_loss: 0.1720 - lr: 3.7692e-07

Epoch 02228: LearningRateScheduler reducing learning rate to 3.752969197887701e-07.
Epoch 2228/4000
24/24 - 3s - loss: 0.0624 - val_loss: 0.1588 - lr: 3.7530e-07

Epoch 02229: LearningRateScheduler reducing learning rate to 3.736801253821157e-07.
Epoch 2229/4000
24/24 - 3s - loss: 0.0614 - val_loss: 0.1750 - lr: 3.7368e-07

Epoch 02230: LearningRateScheduler reducing learning rate to 3.7207029619157544e-07.
Epoch 2230/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1720 - lr: 3.7207e-07

Epoch 02231: LearningRateScheduler reducing learning rate to 3.7046740221071533e-07.
Epoch 2231/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1633 - lr: 3.7047e-07

Epoch 02232: LearningRateScheduler reducing learning rate to 3.6887141356236946e-07.
Epoch 2232/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1756 - lr: 3.6887e-07

Epoch 02233: LearningRateScheduler reducing learning rate to 3.6728230049808435e-07.
Epoch 2233/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1710 - lr: 3.6728e-07

Epoch 02234: LearningRateScheduler reducing learning rate to 3.6570003339756387e-07.
Epoch 2234/4000
24/24 - 4s - loss: 0.0623 - val_loss: 0.1750 - lr: 3.6570e-07

Epoch 02235: LearningRateScheduler reducing learning rate to 3.6412458276811754e-07.
Epoch 2235/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1654 - lr: 3.6412e-07

Epoch 02236: LearningRateScheduler reducing learning rate to 3.6255591924411056e-07.
Epoch 2236/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1784 - lr: 3.6256e-07

Epoch 02237: LearningRateScheduler reducing learning rate to 3.609940135864163e-07.
Epoch 2237/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1583 - lr: 3.6099e-07

Epoch 02238: LearningRateScheduler reducing learning rate to 3.5943883668187175e-07.
Epoch 2238/4000
24/24 - 4s - loss: 0.0616 - val_loss: 0.1719 - lr: 3.5944e-07

Epoch 02239: LearningRateScheduler reducing learning rate to 3.578903595427343e-07.
Epoch 2239/4000
24/24 - 4s - loss: 0.0627 - val_loss: 0.1641 - lr: 3.5789e-07

Epoch 02240: LearningRateScheduler reducing learning rate to 3.5634855330614204e-07.
Epoch 2240/4000
24/24 - 4s - loss: 0.0625 - val_loss: 0.1787 - lr: 3.5635e-07

Epoch 02241: LearningRateScheduler reducing learning rate to 3.5481338923357516e-07.
Epoch 2241/4000
24/24 - 4s - loss: 0.0622 - val_loss: 0.1659 - lr: 3.5481e-07

Epoch 02242: LearningRateScheduler reducing learning rate to 3.5328483871032074e-07.
Epoch 2242/4000
24/24 - 4s - loss: 0.0620 - val_loss: 0.1681 - lr: 3.5328e-07

Epoch 02243: LearningRateScheduler reducing learning rate to 3.5176287324493907e-07.
Epoch 2243/4000
24/24 - 4s - loss: 0.0618 - val_loss: 0.1810 - lr: 3.5176e-07

Epoch 02244: LearningRateScheduler reducing learning rate to 3.5024746446873285e-07.
Epoch 2244/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1712 - lr: 3.5025e-07

Epoch 02245: LearningRateScheduler reducing learning rate to 3.4873858413521815e-07.
Epoch 2245/4000
24/24 - 3s - loss: 0.0623 - val_loss: 0.1638 - lr: 3.4874e-07

Epoch 02246: LearningRateScheduler reducing learning rate to 3.4723620411959817e-07.
Epoch 2246/4000
24/24 - 3s - loss: 0.0616 - val_loss: 0.1779 - lr: 3.4724e-07

Epoch 02247: LearningRateScheduler reducing learning rate to 3.457402964182389e-07.
Epoch 2247/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1733 - lr: 3.4574e-07

Epoch 02248: LearningRateScheduler reducing learning rate to 3.4425083314814694e-07.
Epoch 2248/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1586 - lr: 3.4425e-07

Epoch 02249: LearningRateScheduler reducing learning rate to 3.427677865464502e-07.
Epoch 2249/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1761 - lr: 3.4277e-07

Epoch 02250: LearningRateScheduler reducing learning rate to 3.4129112896987985e-07.
Epoch 2250/4000
Model saved in ./model/scPDB_1221_pdbid--2250--0.1654--0.0000003.
24/24 - 3s - loss: 0.0626 - val_loss: 0.1654 - lr: 3.4129e-07

Epoch 02251: LearningRateScheduler reducing learning rate to 3.3982083289425576e-07.
Epoch 2251/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1691 - lr: 3.3982e-07

Epoch 02252: LearningRateScheduler reducing learning rate to 3.3835687091397284e-07.
Epoch 2252/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1710 - lr: 3.3836e-07

Epoch 02253: LearningRateScheduler reducing learning rate to 3.3689921574149054e-07.
Epoch 2253/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1757 - lr: 3.3690e-07

Epoch 02254: LearningRateScheduler reducing learning rate to 3.3544784020682417e-07.
Epoch 2254/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1683 - lr: 3.3545e-07

Epoch 02255: LearningRateScheduler reducing learning rate to 3.3400271725703835e-07.
Epoch 2255/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1724 - lr: 3.3400e-07

Epoch 02256: LearningRateScheduler reducing learning rate to 3.32563819955743e-07.
Epoch 2256/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1722 - lr: 3.3256e-07

Epoch 02257: LearningRateScheduler reducing learning rate to 3.3113112148259095e-07.
Epoch 2257/4000
24/24 - 3s - loss: 0.0621 - val_loss: 0.1659 - lr: 3.3113e-07

Epoch 02258: LearningRateScheduler reducing learning rate to 3.297045951327782e-07.
Epoch 2258/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1758 - lr: 3.2970e-07

Epoch 02259: LearningRateScheduler reducing learning rate to 3.282842143165463e-07.
Epoch 2259/4000
24/24 - 3s - loss: 0.0618 - val_loss: 0.1723 - lr: 3.2828e-07

Epoch 02260: LearningRateScheduler reducing learning rate to 3.268699525586863e-07.
Epoch 2260/4000
24/24 - 3s - loss: 0.0622 - val_loss: 0.1711 - lr: 3.2687e-07

Epoch 02261: LearningRateScheduler reducing learning rate to 3.2546178349804575e-07.
Epoch 2261/4000
24/24 - 3s - loss: 0.0620 - val_loss: 0.1707 - lr: 3.2546e-07

Epoch 02262: LearningRateScheduler reducing learning rate to 3.24059680887037e-07.
Epoch 2262/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1672 - lr: 3.2406e-07

Epoch 02263: LearningRateScheduler reducing learning rate to 3.226636185911481e-07.
Epoch 2263/4000
24/24 - 4s - loss: 0.0626 - val_loss: 0.1741 - lr: 3.2266e-07

Epoch 02264: LearningRateScheduler reducing learning rate to 3.2127357058845565e-07.
Epoch 2264/4000
24/24 - 4s - loss: 0.0619 - val_loss: 0.1685 - lr: 3.2127e-07

Epoch 02265: LearningRateScheduler reducing learning rate to 3.198895109691397e-07.
Epoch 2265/4000
24/24 - 4s - loss: 0.0621 - val_loss: 0.1745 - lr: 3.1989e-07

Epoch 02266: LearningRateScheduler reducing learning rate to 3.1851141393500097e-07.
Epoch 2266/4000
24/24 - 4s - loss: 0.0624 - val_loss: 0.1755 - lr: 3.1851e-07

Epoch 02267: LearningRateScheduler reducing learning rate to 3.1713925379897985e-07.
Epoch 2267/4000
[09:59:24] Conflicting single bond directions around double bond at index 1.
[09:59:24]   BondStereo set to STEREONONE and single bond directions set to NONE.
Charset: NC(=O)c1[n+]2P-345lH/\S#@oBrsFI678
13937 13937 13937
Initializing model in train mode.
Input type is 'molecular descriptors'.
-------------------
Applying scaling on input.
-------------------
Model received 12543 train samples and 1394 validation samples.
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Latent_Input (InputLayer)       [(None, 255)]        0                                            
__________________________________________________________________________________________________
Decoder_Inputs (InputLayer)     [(None, 249, 37)]    0                                            
__________________________________________________________________________________________________
latent_to_states_model (Functio [(None, 256), (None, 266240      Latent_Input[0][0]               
__________________________________________________________________________________________________
batch_model (Functional)        (None, 249, 37)      839973      Decoder_Inputs[0][0]             
                                                                 latent_to_states_model[0][0]     
                                                                 latent_to_states_model[0][1]     
                                                                 latent_to_states_model[0][2]     
                                                                 latent_to_states_model[0][3]     
==================================================================================================
Total params: 1,106,213
Trainable params: 1,103,141
Non-trainable params: 3,072
__________________________________________________________________________________________________
None
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.

Model trained with dataset scPDB_2021_pdbid that has maxlen=245 and charset=NC(=O)c1[n+]2P-345lH/\S#@oBrsFI678 for 2000 epochs.
noise_std: 0.010000, lstm_dim: 256, dec_layers: 2, td_dense_dim: 0, batch_size: 256, codelayer_dim: 255, lr: 0.001000.
/mnt/home/myxu/anaconda3/envs/ddc/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '
Epoch 1/4000

Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 8s - loss: 1.0608 - val_loss: 2.5478
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.0608324>, 'val_loss': 2.547818899154663}
Epoch 2/4000

Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.4841 - val_loss: 0.5380
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.4840982>, 'val_loss': 0.5380205512046814}
Epoch 3/4000

Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.3856 - val_loss: 0.3573
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.38562986>, 'val_loss': 0.3573475778102875}
Epoch 4/4000

Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 3s - loss: 0.3430 - val_loss: 0.3424
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.3430209>, 'val_loss': 0.3423563539981842}
Epoch 5/4000

Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.3164 - val_loss: 0.2984
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.31641036>, 'val_loss': 0.2983666658401489}
Epoch 6/4000

Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2908 - val_loss: 0.2822
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.29078662>, 'val_loss': 0.2822454869747162}
Epoch 7/4000

Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2751 - val_loss: 0.2671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.27511412>, 'val_loss': 0.2670575678348541}
Epoch 8/4000

Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2617 - val_loss: 0.3255
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.26165864>, 'val_loss': 0.3255419135093689}
Epoch 9/4000

Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2502 - val_loss: 0.2484
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.25021696>, 'val_loss': 0.24844686686992645}
Epoch 10/4000

Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2414 - val_loss: 0.2453
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.24138208>, 'val_loss': 0.2452888935804367}
Epoch 11/4000

Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2313 - val_loss: 0.2326
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.23127992>, 'val_loss': 0.2326236069202423}
Epoch 12/4000

Epoch 00012: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2246 - val_loss: 0.2312
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.22461931>, 'val_loss': 0.23115621507167816}
Epoch 13/4000

Epoch 00013: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2199 - val_loss: 0.2343
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.21989898>, 'val_loss': 0.23428326845169067}
Epoch 14/4000

Epoch 00014: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2139 - val_loss: 0.2160
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.21393943>, 'val_loss': 0.21597225964069366}
Epoch 15/4000

Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2086 - val_loss: 0.2211
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.2085751>, 'val_loss': 0.22108733654022217}
Epoch 16/4000

Epoch 00016: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2029 - val_loss: 0.2345
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.2029111>, 'val_loss': 0.23448027670383453}
Epoch 17/4000

Epoch 00017: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2046 - val_loss: 0.2138
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.20457639>, 'val_loss': 0.21377286314964294}
Epoch 18/4000

Epoch 00018: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.2001 - val_loss: 0.2102
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.20014305>, 'val_loss': 0.21015779674053192}
Epoch 19/4000

Epoch 00019: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1942 - val_loss: 0.2074
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.19421615>, 'val_loss': 0.20735837519168854}
Epoch 20/4000

Epoch 00020: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1922 - val_loss: 0.2088
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.19224082>, 'val_loss': 0.20876802504062653}
Epoch 21/4000

Epoch 00021: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1902 - val_loss: 0.1973
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1901982>, 'val_loss': 0.1972815841436386}
Epoch 22/4000

Epoch 00022: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1883 - val_loss: 0.2041
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.18829805>, 'val_loss': 0.20405447483062744}
Epoch 23/4000

Epoch 00023: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1831 - val_loss: 0.1937
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.18310678>, 'val_loss': 0.19374988973140717}
Epoch 24/4000

Epoch 00024: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1850 - val_loss: 0.2038
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.18496473>, 'val_loss': 0.2037949562072754}
Epoch 25/4000

Epoch 00025: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1807 - val_loss: 0.2017
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.18066531>, 'val_loss': 0.20172971487045288}
Epoch 26/4000

Epoch 00026: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1782 - val_loss: 0.2183
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.17824133>, 'val_loss': 0.2183361053466797}
Epoch 27/4000

Epoch 00027: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1771 - val_loss: 0.2035
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.17713441>, 'val_loss': 0.2034500688314438}
Epoch 28/4000

Epoch 00028: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1753 - val_loss: 0.1806
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.17525242>, 'val_loss': 0.18064887821674347}
Epoch 29/4000

Epoch 00029: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1731 - val_loss: 0.1923
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.17312996>, 'val_loss': 0.19229084253311157}
Epoch 30/4000

Epoch 00030: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1711 - val_loss: 0.1759
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1710962>, 'val_loss': 0.1758652925491333}
Epoch 31/4000

Epoch 00031: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1706 - val_loss: 0.1790
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1705871>, 'val_loss': 0.17904682457447052}
Epoch 32/4000

Epoch 00032: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1699 - val_loss: 0.1823
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1699289>, 'val_loss': 0.18228702247142792}
Epoch 33/4000

Epoch 00033: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1668 - val_loss: 0.1817
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1667533>, 'val_loss': 0.18166208267211914}
Epoch 34/4000

Epoch 00034: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1659 - val_loss: 0.1860
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.16586362>, 'val_loss': 0.1860489845275879}
Epoch 35/4000

Epoch 00035: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1652 - val_loss: 0.1663
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.16521738>, 'val_loss': 0.16629064083099365}
Epoch 36/4000

Epoch 00036: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1654 - val_loss: 0.1740
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1653712>, 'val_loss': 0.174001082777977}
Epoch 37/4000

Epoch 00037: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1637 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.16371442>, 'val_loss': 0.17707102000713348}
Epoch 38/4000

Epoch 00038: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1625 - val_loss: 0.1647
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.16252707>, 'val_loss': 0.16465213894844055}
Epoch 39/4000

Epoch 00039: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1586 - val_loss: 0.1818
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15864152>, 'val_loss': 0.18180103600025177}
Epoch 40/4000

Epoch 00040: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1591 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15909454>, 'val_loss': 0.16978685557842255}
Epoch 41/4000

Epoch 00041: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1593 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15928823>, 'val_loss': 0.16427797079086304}
Epoch 42/4000

Epoch 00042: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1580 - val_loss: 0.1718
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1579971>, 'val_loss': 0.17181509733200073}
Epoch 43/4000

Epoch 00043: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1583 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15830225>, 'val_loss': 0.16809873282909393}
Epoch 44/4000

Epoch 00044: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1558 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15580939>, 'val_loss': 0.1664946973323822}
Epoch 45/4000

Epoch 00045: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1553 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15534037>, 'val_loss': 0.1650562286376953}
Epoch 46/4000

Epoch 00046: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1555 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15545063>, 'val_loss': 0.16645187139511108}
Epoch 47/4000

Epoch 00047: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1519 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15188153>, 'val_loss': 0.1665513664484024}
Epoch 48/4000

Epoch 00048: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1520 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15197249>, 'val_loss': 0.17162710428237915}
Epoch 49/4000

Epoch 00049: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1525 - val_loss: 0.1586
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15249714>, 'val_loss': 0.15856757760047913}
Epoch 50/4000

Epoch 00050: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1498 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14984402>, 'val_loss': 0.16510996222496033}
Model saved in ./model/scPDB_2021_pdbid--50--0.1651.
Epoch 51/4000

Epoch 00051: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1504 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15041107>, 'val_loss': 0.16754519939422607}
Epoch 52/4000

Epoch 00052: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1511 - val_loss: 0.1636
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.15105158>, 'val_loss': 0.163649782538414}
Epoch 53/4000

Epoch 00053: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1485 - val_loss: 0.1585
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1484889>, 'val_loss': 0.15853437781333923}
Epoch 54/4000

Epoch 00054: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1485 - val_loss: 0.1625
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14854918>, 'val_loss': 0.1624698042869568}
Epoch 55/4000

Epoch 00055: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1495 - val_loss: 0.1580
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1494975>, 'val_loss': 0.15797686576843262}
Epoch 56/4000

Epoch 00056: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1465 - val_loss: 0.1572
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14648111>, 'val_loss': 0.15719477832317352}
Epoch 57/4000

Epoch 00057: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1455 - val_loss: 0.1575
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14548138>, 'val_loss': 0.15754342079162598}
Epoch 58/4000

Epoch 00058: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1455 - val_loss: 0.1521
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14545579>, 'val_loss': 0.1521337628364563}
Epoch 59/4000

Epoch 00059: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1452 - val_loss: 0.1578
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14518169>, 'val_loss': 0.15776576101779938}
Epoch 60/4000

Epoch 00060: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1443 - val_loss: 0.1560
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14427061>, 'val_loss': 0.15599365532398224}
Epoch 61/4000

Epoch 00061: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1445 - val_loss: 0.1557
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14445178>, 'val_loss': 0.15573017299175262}
Epoch 62/4000

Epoch 00062: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1440 - val_loss: 0.1556
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14398001>, 'val_loss': 0.15557898581027985}
Epoch 63/4000

Epoch 00063: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1434 - val_loss: 0.1508
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1434036>, 'val_loss': 0.15075254440307617}
Epoch 64/4000

Epoch 00064: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1429 - val_loss: 0.1471
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14289361>, 'val_loss': 0.14712490141391754}
Epoch 65/4000

Epoch 00065: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1414 - val_loss: 0.1497
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14140165>, 'val_loss': 0.1496584415435791}
Epoch 66/4000

Epoch 00066: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1423 - val_loss: 0.1548
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14228673>, 'val_loss': 0.15483522415161133}
Epoch 67/4000

Epoch 00067: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1417 - val_loss: 0.1534
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1416621>, 'val_loss': 0.15343554317951202}
Epoch 68/4000

Epoch 00068: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1407 - val_loss: 0.1589
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.14068772>, 'val_loss': 0.1589270383119583}
Epoch 69/4000

Epoch 00069: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1403 - val_loss: 0.1459
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1402595>, 'val_loss': 0.14591054618358612}
Epoch 70/4000

Epoch 00070: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1398 - val_loss: 0.1504
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13981883>, 'val_loss': 0.1504385769367218}
Epoch 71/4000

Epoch 00071: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1392 - val_loss: 0.1536
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13918816>, 'val_loss': 0.15355950593948364}
Epoch 72/4000

Epoch 00072: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1382 - val_loss: 0.1501
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13822864>, 'val_loss': 0.1500764638185501}
Epoch 73/4000

Epoch 00073: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1380 - val_loss: 0.1545
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13796715>, 'val_loss': 0.1544983685016632}
Epoch 74/4000

Epoch 00074: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1389 - val_loss: 0.1505
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1389045>, 'val_loss': 0.15053421258926392}
Epoch 75/4000

Epoch 00075: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1374 - val_loss: 0.1553
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13740169>, 'val_loss': 0.15530885756015778}
Epoch 76/4000

Epoch 00076: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1369 - val_loss: 0.1536
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.136901>, 'val_loss': 0.1536353975534439}
Epoch 77/4000

Epoch 00077: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1368 - val_loss: 0.1462
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13677363>, 'val_loss': 0.1462160050868988}
Epoch 78/4000

Epoch 00078: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1378 - val_loss: 0.1450
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13779077>, 'val_loss': 0.14500603079795837}
Epoch 79/4000

Epoch 00079: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1375 - val_loss: 0.1462
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13753015>, 'val_loss': 0.1461549550294876}
Epoch 80/4000

Epoch 00080: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1333 - val_loss: 0.1498
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13328141>, 'val_loss': 0.14976297318935394}
Epoch 81/4000

Epoch 00081: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1353 - val_loss: 0.1533
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13529314>, 'val_loss': 0.15334928035736084}
Epoch 82/4000

Epoch 00082: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1354 - val_loss: 0.1404
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13543646>, 'val_loss': 0.1404055655002594}
Epoch 83/4000

Epoch 00083: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1351 - val_loss: 0.1502
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1351244>, 'val_loss': 0.15018285810947418}
Epoch 84/4000

Epoch 00084: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1343 - val_loss: 0.1470
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13428506>, 'val_loss': 0.14701677858829498}
Epoch 85/4000

Epoch 00085: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1345 - val_loss: 0.1427
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13447623>, 'val_loss': 0.14274479448795319}
Epoch 86/4000

Epoch 00086: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1338 - val_loss: 0.1457
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13380295>, 'val_loss': 0.14568328857421875}
Epoch 87/4000

Epoch 00087: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1329 - val_loss: 0.1416
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1329001>, 'val_loss': 0.14163857698440552}
Epoch 88/4000

Epoch 00088: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1341 - val_loss: 0.1470
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13412997>, 'val_loss': 0.14703507721424103}
Epoch 89/4000

Epoch 00089: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1309 - val_loss: 0.1440
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13094242>, 'val_loss': 0.14399220049381256}
Epoch 90/4000

Epoch 00090: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1325 - val_loss: 0.1443
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13248873>, 'val_loss': 0.14433357119560242}
Epoch 91/4000

Epoch 00091: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1322 - val_loss: 0.1440
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13222155>, 'val_loss': 0.1439935714006424}
Epoch 92/4000

Epoch 00092: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1317 - val_loss: 0.1381
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13174231>, 'val_loss': 0.13805674016475677}
Epoch 93/4000

Epoch 00093: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1296 - val_loss: 0.1371
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12958544>, 'val_loss': 0.13706694543361664}
Epoch 94/4000

Epoch 00094: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1314 - val_loss: 0.1441
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1313743>, 'val_loss': 0.14406616985797882}
Epoch 95/4000

Epoch 00095: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1299 - val_loss: 0.1341
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12993778>, 'val_loss': 0.1341104954481125}
Epoch 96/4000

Epoch 00096: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1307 - val_loss: 0.1379
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13074805>, 'val_loss': 0.13786910474300385}
Epoch 97/4000

Epoch 00097: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1302 - val_loss: 0.1456
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.13015114>, 'val_loss': 0.14558637142181396}
Epoch 98/4000

Epoch 00098: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1296 - val_loss: 0.1380
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12955913>, 'val_loss': 0.13801029324531555}
Epoch 99/4000

Epoch 00099: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1286 - val_loss: 0.1374
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12856705>, 'val_loss': 0.13738912343978882}
Epoch 100/4000

Epoch 00100: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1291 - val_loss: 0.1421
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12906417>, 'val_loss': 0.14213408529758453}
Model saved in ./model/scPDB_2021_pdbid--100--0.1421.
Epoch 101/4000

Epoch 00101: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1292 - val_loss: 0.1351
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12921081>, 'val_loss': 0.13507752120494843}
Epoch 102/4000

Epoch 00102: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1275 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12751243>, 'val_loss': 0.1386841982603073}
Epoch 103/4000

Epoch 00103: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1278 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12781611>, 'val_loss': 0.1387331485748291}
Epoch 104/4000

Epoch 00104: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1279 - val_loss: 0.1382
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.127868>, 'val_loss': 0.13815076649188995}
Epoch 105/4000

Epoch 00105: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1271 - val_loss: 0.1362
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12706535>, 'val_loss': 0.13616764545440674}
Epoch 106/4000

Epoch 00106: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1265 - val_loss: 0.1435
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12654911>, 'val_loss': 0.1434769481420517}
Epoch 107/4000

Epoch 00107: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1254 - val_loss: 0.1328
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1254271>, 'val_loss': 0.13280612230300903}
Epoch 108/4000

Epoch 00108: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1279 - val_loss: 0.1420
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12791353>, 'val_loss': 0.14198195934295654}
Epoch 109/4000

Epoch 00109: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1265 - val_loss: 0.1355
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12650162>, 'val_loss': 0.1355474889278412}
Epoch 110/4000

Epoch 00110: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1268 - val_loss: 0.1364
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12675388>, 'val_loss': 0.13636645674705505}
Epoch 111/4000

Epoch 00111: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1259 - val_loss: 0.1395
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12594113>, 'val_loss': 0.13948528468608856}
Epoch 112/4000

Epoch 00112: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1254 - val_loss: 0.1391
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12539062>, 'val_loss': 0.13905133306980133}
Epoch 113/4000

Epoch 00113: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1254 - val_loss: 0.1345
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12542869>, 'val_loss': 0.13454073667526245}
Epoch 114/4000

Epoch 00114: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1251 - val_loss: 0.1364
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12508234>, 'val_loss': 0.13640406727790833}
Epoch 115/4000

Epoch 00115: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1254 - val_loss: 0.1375
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12538484>, 'val_loss': 0.13749833405017853}
Epoch 116/4000

Epoch 00116: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1234 - val_loss: 0.1327
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.123439275>, 'val_loss': 0.13269959390163422}
Epoch 117/4000

Epoch 00117: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1248 - val_loss: 0.1357
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.124766186>, 'val_loss': 0.13573558628559113}
Epoch 118/4000

Epoch 00118: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1247 - val_loss: 0.1354
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.124664366>, 'val_loss': 0.13537481427192688}
Epoch 119/4000

Epoch 00119: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1222 - val_loss: 0.1405
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12221639>, 'val_loss': 0.140475794672966}
Epoch 120/4000

Epoch 00120: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1243 - val_loss: 0.1378
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12430034>, 'val_loss': 0.13780520856380463}
Epoch 121/4000

Epoch 00121: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1219 - val_loss: 0.1364
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12194308>, 'val_loss': 0.1364440768957138}
Epoch 122/4000

Epoch 00122: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1238 - val_loss: 0.1357
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12375423>, 'val_loss': 0.13568831980228424}
Epoch 123/4000

Epoch 00123: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1222 - val_loss: 0.1361
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12218851>, 'val_loss': 0.13606712222099304}
Epoch 124/4000

Epoch 00124: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1228 - val_loss: 0.1284
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12284493>, 'val_loss': 0.12835785746574402}
Epoch 125/4000

Epoch 00125: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1221 - val_loss: 0.1431
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12206931>, 'val_loss': 0.14308016002178192}
Epoch 126/4000

Epoch 00126: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1222 - val_loss: 0.1308
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12220795>, 'val_loss': 0.13075374066829681}
Epoch 127/4000

Epoch 00127: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1224 - val_loss: 0.1267
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12238264>, 'val_loss': 0.12673097848892212}
Epoch 128/4000

Epoch 00128: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1209 - val_loss: 0.1327
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12089506>, 'val_loss': 0.13267546892166138}
Epoch 129/4000

Epoch 00129: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1213 - val_loss: 0.1337
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.121348165>, 'val_loss': 0.13372351229190826}
Epoch 130/4000

Epoch 00130: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1211 - val_loss: 0.1404
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.121094294>, 'val_loss': 0.14038677513599396}
Epoch 131/4000

Epoch 00131: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1197 - val_loss: 0.1280
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11966911>, 'val_loss': 0.1279781013727188}
Epoch 132/4000

Epoch 00132: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1211 - val_loss: 0.1298
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.121147625>, 'val_loss': 0.1297544538974762}
Epoch 133/4000

Epoch 00133: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1214 - val_loss: 0.1363
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12137089>, 'val_loss': 0.13628055155277252}
Epoch 134/4000

Epoch 00134: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1196 - val_loss: 0.1315
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1195951>, 'val_loss': 0.13145564496517181}
Epoch 135/4000

Epoch 00135: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1192 - val_loss: 0.1349
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11916583>, 'val_loss': 0.13486294448375702}
Epoch 136/4000

Epoch 00136: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1198 - val_loss: 0.1303
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11975486>, 'val_loss': 0.13026994466781616}
Epoch 137/4000

Epoch 00137: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1196 - val_loss: 0.1282
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.119626254>, 'val_loss': 0.12819063663482666}
Epoch 138/4000

Epoch 00138: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1191 - val_loss: 0.1367
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.119059>, 'val_loss': 0.1367437243461609}
Epoch 139/4000

Epoch 00139: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1202 - val_loss: 0.1278
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.12015144>, 'val_loss': 0.12782049179077148}
Epoch 140/4000

Epoch 00140: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1191 - val_loss: 0.1286
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11912949>, 'val_loss': 0.1285899132490158}
Epoch 141/4000

Epoch 00141: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1177 - val_loss: 0.1291
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11773214>, 'val_loss': 0.12909455597400665}
Epoch 142/4000

Epoch 00142: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1195 - val_loss: 0.1316
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11946622>, 'val_loss': 0.1315993219614029}
Epoch 143/4000

Epoch 00143: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1176 - val_loss: 0.1321
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.117571086>, 'val_loss': 0.13209415972232819}
Epoch 144/4000

Epoch 00144: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1189 - val_loss: 0.1326
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11894685>, 'val_loss': 0.13263167440891266}
Epoch 145/4000

Epoch 00145: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1174 - val_loss: 0.1272
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11740788>, 'val_loss': 0.12715208530426025}
Epoch 146/4000

Epoch 00146: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1177 - val_loss: 0.1326
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.117743134>, 'val_loss': 0.13257716596126556}
Epoch 147/4000

Epoch 00147: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1176 - val_loss: 0.1280
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.117640115>, 'val_loss': 0.12800605595111847}
Epoch 148/4000

Epoch 00148: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1151 - val_loss: 0.1293
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11505142>, 'val_loss': 0.12927359342575073}
Epoch 149/4000

Epoch 00149: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1183 - val_loss: 0.1247
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11827215>, 'val_loss': 0.12470421195030212}
Epoch 150/4000

Epoch 00150: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1168 - val_loss: 0.1299
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11676059>, 'val_loss': 0.12988024950027466}
Model saved in ./model/scPDB_2021_pdbid--150--0.1299.
Epoch 151/4000

Epoch 00151: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1165 - val_loss: 0.1290
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11646322>, 'val_loss': 0.12901735305786133}
Epoch 152/4000

Epoch 00152: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1169 - val_loss: 0.1303
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11692554>, 'val_loss': 0.13028590381145477}
Epoch 153/4000

Epoch 00153: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1171 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11706579>, 'val_loss': 0.1284671574831009}
Epoch 154/4000

Epoch 00154: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1160 - val_loss: 0.1288
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1160435>, 'val_loss': 0.12878938019275665}
Epoch 155/4000

Epoch 00155: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1153 - val_loss: 0.1291
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11531494>, 'val_loss': 0.1291159689426422}
Epoch 156/4000

Epoch 00156: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1168 - val_loss: 0.1306
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11679762>, 'val_loss': 0.13059376180171967}
Epoch 157/4000

Epoch 00157: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1152 - val_loss: 0.1282
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11522866>, 'val_loss': 0.12822963297367096}
Epoch 158/4000

Epoch 00158: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1152 - val_loss: 0.1366
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11515032>, 'val_loss': 0.13659219443798065}
Epoch 159/4000

Epoch 00159: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1154 - val_loss: 0.1255
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.115393184>, 'val_loss': 0.12547661364078522}
Epoch 160/4000

Epoch 00160: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1150 - val_loss: 0.1314
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.115009025>, 'val_loss': 0.13138744235038757}
Epoch 161/4000

Epoch 00161: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1146 - val_loss: 0.1302
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11460284>, 'val_loss': 0.13018105924129486}
Epoch 162/4000

Epoch 00162: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1144 - val_loss: 0.1332
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11441394>, 'val_loss': 0.1331825852394104}
Epoch 163/4000

Epoch 00163: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1143 - val_loss: 0.1299
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11434325>, 'val_loss': 0.1299012452363968}
Epoch 164/4000

Epoch 00164: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1152 - val_loss: 0.1220
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11519499>, 'val_loss': 0.12199471145868301}
Epoch 165/4000

Epoch 00165: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1141 - val_loss: 0.1302
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.114144094>, 'val_loss': 0.130215123295784}
Epoch 166/4000

Epoch 00166: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1138 - val_loss: 0.1301
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11384186>, 'val_loss': 0.13007329404354095}
Epoch 167/4000

Epoch 00167: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1137 - val_loss: 0.1233
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11367414>, 'val_loss': 0.12333044409751892}
Epoch 168/4000

Epoch 00168: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1136 - val_loss: 0.1291
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11363528>, 'val_loss': 0.1290561407804489}
Epoch 169/4000

Epoch 00169: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1134 - val_loss: 0.1261
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11340339>, 'val_loss': 0.1260852962732315}
Epoch 170/4000

Epoch 00170: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1131 - val_loss: 0.1289
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11306779>, 'val_loss': 0.12888413667678833}
Epoch 171/4000

Epoch 00171: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1133 - val_loss: 0.1254
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11334462>, 'val_loss': 0.12542808055877686}
Epoch 172/4000

Epoch 00172: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1123 - val_loss: 0.1274
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11232488>, 'val_loss': 0.12736837565898895}
Epoch 173/4000

Epoch 00173: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1130 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11302757>, 'val_loss': 0.1267804205417633}
Epoch 174/4000

Epoch 00174: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1125 - val_loss: 0.1280
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11250536>, 'val_loss': 0.12795858085155487}
Epoch 175/4000

Epoch 00175: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1119 - val_loss: 0.1249
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11185797>, 'val_loss': 0.12493676692247391}
Epoch 176/4000

Epoch 00176: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1117 - val_loss: 0.1305
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11172544>, 'val_loss': 0.13053575158119202}
Epoch 177/4000

Epoch 00177: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1113 - val_loss: 0.1235
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11128449>, 'val_loss': 0.12346795946359634}
Epoch 178/4000

Epoch 00178: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1133 - val_loss: 0.1271
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.113271125>, 'val_loss': 0.12708549201488495}
Epoch 179/4000

Epoch 00179: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1110 - val_loss: 0.1300
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11100885>, 'val_loss': 0.1300237774848938}
Epoch 180/4000

Epoch 00180: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1113 - val_loss: 0.1269
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11128702>, 'val_loss': 0.1268623322248459}
Epoch 181/4000

Epoch 00181: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1118 - val_loss: 0.1299
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11179778>, 'val_loss': 0.12989337742328644}
Epoch 182/4000

Epoch 00182: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1113 - val_loss: 0.1278
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11128809>, 'val_loss': 0.12779372930526733}
Epoch 183/4000

Epoch 00183: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1104 - val_loss: 0.1277
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11035051>, 'val_loss': 0.1276863068342209}
Epoch 184/4000

Epoch 00184: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1113 - val_loss: 0.1272
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11130486>, 'val_loss': 0.12723161280155182}
Epoch 185/4000

Epoch 00185: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1100 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10999924>, 'val_loss': 0.12853775918483734}
Epoch 186/4000

Epoch 00186: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1107 - val_loss: 0.1290
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.110666096>, 'val_loss': 0.1290348321199417}
Epoch 187/4000

Epoch 00187: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1100 - val_loss: 0.1259
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10996435>, 'val_loss': 0.12586061656475067}
Epoch 188/4000

Epoch 00188: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1103 - val_loss: 0.1292
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11025574>, 'val_loss': 0.1291741281747818}
Epoch 189/4000

Epoch 00189: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1102 - val_loss: 0.1258
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11019238>, 'val_loss': 0.1258234828710556}
Epoch 190/4000

Epoch 00190: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1094 - val_loss: 0.1243
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10941784>, 'val_loss': 0.12427711486816406}
Epoch 191/4000

Epoch 00191: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1093 - val_loss: 0.1213
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1093055>, 'val_loss': 0.1212875172495842}
Epoch 192/4000

Epoch 00192: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1101 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.11007195>, 'val_loss': 0.12853765487670898}
Epoch 193/4000

Epoch 00193: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1090 - val_loss: 0.1245
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10900819>, 'val_loss': 0.12448365241289139}
Epoch 194/4000

Epoch 00194: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1096 - val_loss: 0.1333
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1096145>, 'val_loss': 0.13329066336154938}
Epoch 195/4000

Epoch 00195: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1098 - val_loss: 0.1212
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1098082>, 'val_loss': 0.12119302153587341}
Epoch 196/4000

Epoch 00196: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1087 - val_loss: 0.1239
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10869509>, 'val_loss': 0.12392199039459229}
Epoch 197/4000

Epoch 00197: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1076 - val_loss: 0.1243
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10759869>, 'val_loss': 0.12432347238063812}
Epoch 198/4000

Epoch 00198: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1092 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10915506>, 'val_loss': 0.12618441879749298}
Epoch 199/4000

Epoch 00199: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1084 - val_loss: 0.1253
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10844536>, 'val_loss': 0.1253209114074707}
Epoch 200/4000

Epoch 00200: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1090 - val_loss: 0.1265
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.108991496>, 'val_loss': 0.12646347284317017}
Model saved in ./model/scPDB_2021_pdbid--200--0.1265.
Epoch 201/4000

Epoch 00201: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1085 - val_loss: 0.1235
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.108510345>, 'val_loss': 0.12345696240663528}
Epoch 202/4000

Epoch 00202: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1074 - val_loss: 0.1246
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10739076>, 'val_loss': 0.12457817792892456}
Epoch 203/4000

Epoch 00203: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1077 - val_loss: 0.1224
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.107665986>, 'val_loss': 0.12238670140504837}
Epoch 204/4000

Epoch 00204: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1080 - val_loss: 0.1265
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10797164>, 'val_loss': 0.12645767629146576}
Epoch 205/4000

Epoch 00205: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1051 - val_loss: 0.1241
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10513054>, 'val_loss': 0.12411612272262573}
Epoch 206/4000

Epoch 00206: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1081 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10809521>, 'val_loss': 0.12560167908668518}
Epoch 207/4000

Epoch 00207: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1077 - val_loss: 0.1241
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10772336>, 'val_loss': 0.12405633181333542}
Epoch 208/4000

Epoch 00208: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1064 - val_loss: 0.1236
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.106397>, 'val_loss': 0.12358804792165756}
Epoch 209/4000

Epoch 00209: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1069 - val_loss: 0.1230
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.106920674>, 'val_loss': 0.12304016947746277}
Epoch 210/4000

Epoch 00210: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1060 - val_loss: 0.1263
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10600516>, 'val_loss': 0.1262965202331543}
Epoch 211/4000

Epoch 00211: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1079 - val_loss: 0.1190
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10791519>, 'val_loss': 0.11896214634180069}
Epoch 212/4000

Epoch 00212: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1060 - val_loss: 0.1247
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.105966054>, 'val_loss': 0.12470954656600952}
Epoch 213/4000

Epoch 00213: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1054 - val_loss: 0.1261
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.105399795>, 'val_loss': 0.12613679468631744}
Epoch 214/4000

Epoch 00214: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1059 - val_loss: 0.1237
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10592801>, 'val_loss': 0.12374284118413925}
Epoch 215/4000

Epoch 00215: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1054 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1054222>, 'val_loss': 0.12681728601455688}
Epoch 216/4000

Epoch 00216: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1062 - val_loss: 0.1242
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10615366>, 'val_loss': 0.12419811636209488}
Epoch 217/4000

Epoch 00217: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1052 - val_loss: 0.1230
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10518763>, 'val_loss': 0.1229867935180664}
Epoch 218/4000

Epoch 00218: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1051 - val_loss: 0.1289
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.105082475>, 'val_loss': 0.12887173891067505}
Epoch 219/4000

Epoch 00219: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1044 - val_loss: 0.1274
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10436826>, 'val_loss': 0.12742091715335846}
Epoch 220/4000

Epoch 00220: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1060 - val_loss: 0.1202
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10595137>, 'val_loss': 0.1201869323849678}
Epoch 221/4000

Epoch 00221: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1045 - val_loss: 0.1282
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10446981>, 'val_loss': 0.128218412399292}
Epoch 222/4000

Epoch 00222: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1056 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10557086>, 'val_loss': 0.1285364180803299}
Epoch 223/4000

Epoch 00223: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1060 - val_loss: 0.1192
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1059951>, 'val_loss': 0.11920247226953506}
Epoch 224/4000

Epoch 00224: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1042 - val_loss: 0.1315
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10421583>, 'val_loss': 0.13151013851165771}
Epoch 225/4000

Epoch 00225: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1048 - val_loss: 0.1247
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10481613>, 'val_loss': 0.12468532472848892}
Epoch 226/4000

Epoch 00226: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1040 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10404128>, 'val_loss': 0.12622295320034027}
Epoch 227/4000

Epoch 00227: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1051 - val_loss: 0.1230
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10513287>, 'val_loss': 0.12297803908586502}
Epoch 228/4000

Epoch 00228: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1037 - val_loss: 0.1248
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.103698134>, 'val_loss': 0.12480086088180542}
Epoch 229/4000

Epoch 00229: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1038 - val_loss: 0.1284
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10377937>, 'val_loss': 0.12837286293506622}
Epoch 230/4000

Epoch 00230: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1036 - val_loss: 0.1244
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10359948>, 'val_loss': 0.12436844408512115}
Epoch 231/4000

Epoch 00231: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1043 - val_loss: 0.1207
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10428822>, 'val_loss': 0.12070795148611069}
Epoch 232/4000

Epoch 00232: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1038 - val_loss: 0.1274
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10377467>, 'val_loss': 0.1274297684431076}
Epoch 233/4000

Epoch 00233: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1033 - val_loss: 0.1201
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.103338666>, 'val_loss': 0.12007661163806915}
Epoch 234/4000

Epoch 00234: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1024 - val_loss: 0.1276
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10241979>, 'val_loss': 0.12760478258132935}
Epoch 235/4000

Epoch 00235: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1041 - val_loss: 0.1238
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1040596>, 'val_loss': 0.12376251071691513}
Epoch 236/4000

Epoch 00236: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1031 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.103148915>, 'val_loss': 0.1261889487504959}
Epoch 237/4000

Epoch 00237: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1019 - val_loss: 0.1235
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10193968>, 'val_loss': 0.12350983172655106}
Epoch 238/4000

Epoch 00238: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1026 - val_loss: 0.1244
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10259035>, 'val_loss': 0.12437789887189865}
Epoch 239/4000

Epoch 00239: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1032 - val_loss: 0.1275
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.103162855>, 'val_loss': 0.1274758130311966}
Epoch 240/4000

Epoch 00240: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1019 - val_loss: 0.1198
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10192803>, 'val_loss': 0.1197768822312355}
Epoch 241/4000

Epoch 00241: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1032 - val_loss: 0.1248
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10317488>, 'val_loss': 0.12483575940132141}
Epoch 242/4000

Epoch 00242: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1024 - val_loss: 0.1224
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.102363385>, 'val_loss': 0.12235502898693085}
Epoch 243/4000

Epoch 00243: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1012 - val_loss: 0.1227
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10124239>, 'val_loss': 0.12269837409257889}
Epoch 244/4000

Epoch 00244: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1017 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10168511>, 'val_loss': 0.12560266256332397}
Epoch 245/4000

Epoch 00245: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1024 - val_loss: 0.1209
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10242388>, 'val_loss': 0.12085799127817154}
Epoch 246/4000

Epoch 00246: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1009 - val_loss: 0.1264
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.1008872>, 'val_loss': 0.12643609941005707}
Epoch 247/4000

Epoch 00247: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1025 - val_loss: 0.1172
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.102496944>, 'val_loss': 0.11717686802148819}
Epoch 248/4000

Epoch 00248: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0999 - val_loss: 0.1217
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09990057>, 'val_loss': 0.12167404592037201}
Epoch 249/4000

Epoch 00249: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1017 - val_loss: 0.1251
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10168045>, 'val_loss': 0.12513671815395355}
Epoch 250/4000

Epoch 00250: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1010 - val_loss: 0.1235
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10097914>, 'val_loss': 0.12353309988975525}
Model saved in ./model/scPDB_2021_pdbid--250--0.1235.
Epoch 251/4000

Epoch 00251: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1005 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.100533776>, 'val_loss': 0.12850306928157806}
Epoch 252/4000

Epoch 00252: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1005 - val_loss: 0.1221
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10049761>, 'val_loss': 0.12206727266311646}
Epoch 253/4000

Epoch 00253: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1015 - val_loss: 0.1245
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10146996>, 'val_loss': 0.12448257952928543}
Epoch 254/4000

Epoch 00254: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0995 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09948861>, 'val_loss': 0.12562258541584015}
Epoch 255/4000

Epoch 00255: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1020 - val_loss: 0.1304
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10200723>, 'val_loss': 0.13039171695709229}
Epoch 256/4000

Epoch 00256: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1009 - val_loss: 0.1244
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10093791>, 'val_loss': 0.124424047768116}
Epoch 257/4000

Epoch 00257: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0990 - val_loss: 0.1196
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09897866>, 'val_loss': 0.11960297077894211}
Epoch 258/4000

Epoch 00258: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0997 - val_loss: 0.1178
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09970204>, 'val_loss': 0.11775937676429749}
Epoch 259/4000

Epoch 00259: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.1001 - val_loss: 0.1263
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.10014439>, 'val_loss': 0.12627844512462616}
Epoch 260/4000

Epoch 00260: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0996 - val_loss: 0.1224
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09958787>, 'val_loss': 0.12235813587903976}
Epoch 261/4000

Epoch 00261: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0997 - val_loss: 0.1259
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.099687226>, 'val_loss': 0.1258925050497055}
Epoch 262/4000

Epoch 00262: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0998 - val_loss: 0.1252
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09982853>, 'val_loss': 0.12518954277038574}
Epoch 263/4000

Epoch 00263: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0992 - val_loss: 0.1217
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.099197365>, 'val_loss': 0.12167119234800339}
Epoch 264/4000

Epoch 00264: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0990 - val_loss: 0.1253
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09901055>, 'val_loss': 0.12532822787761688}
Epoch 265/4000

Epoch 00265: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0992 - val_loss: 0.1233
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09922818>, 'val_loss': 0.12331205606460571}
Epoch 266/4000

Epoch 00266: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0991 - val_loss: 0.1195
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09909928>, 'val_loss': 0.11953882873058319}
Epoch 267/4000

Epoch 00267: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0986 - val_loss: 0.1251
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09858935>, 'val_loss': 0.12513326108455658}
Epoch 268/4000

Epoch 00268: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0989 - val_loss: 0.1258
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09893841>, 'val_loss': 0.12584288418293}
Epoch 269/4000

Epoch 00269: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0984 - val_loss: 0.1231
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.098421246>, 'val_loss': 0.1231432631611824}
Epoch 270/4000

Epoch 00270: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0992 - val_loss: 0.1217
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09920196>, 'val_loss': 0.12169995158910751}
Epoch 271/4000

Epoch 00271: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0989 - val_loss: 0.1281
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.098940104>, 'val_loss': 0.12808506190776825}
Epoch 272/4000

Epoch 00272: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0993 - val_loss: 0.1197
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09930385>, 'val_loss': 0.11972931027412415}
Epoch 273/4000

Epoch 00273: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0974 - val_loss: 0.1235
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.097374946>, 'val_loss': 0.12346235662698746}
Epoch 274/4000

Epoch 00274: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0993 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09929092>, 'val_loss': 0.1267794817686081}
Epoch 275/4000

Epoch 00275: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0968 - val_loss: 0.1249
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09683778>, 'val_loss': 0.12487570941448212}
Epoch 276/4000

Epoch 00276: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0982 - val_loss: 0.1264
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.098174706>, 'val_loss': 0.12637917697429657}
Epoch 277/4000

Epoch 00277: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0980 - val_loss: 0.1242
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09802402>, 'val_loss': 0.12417414039373398}
Epoch 278/4000

Epoch 00278: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0964 - val_loss: 0.1285
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09641854>, 'val_loss': 0.1284504532814026}
Epoch 279/4000

Epoch 00279: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0979 - val_loss: 0.1226
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09792758>, 'val_loss': 0.122613824903965}
Epoch 280/4000

Epoch 00280: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0978 - val_loss: 0.1228
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.097771764>, 'val_loss': 0.1228158101439476}
Epoch 281/4000

Epoch 00281: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0976 - val_loss: 0.1282
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09756384>, 'val_loss': 0.12820330262184143}
Epoch 282/4000

Epoch 00282: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0974 - val_loss: 0.1267
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.097408205>, 'val_loss': 0.12671184539794922}
Epoch 283/4000

Epoch 00283: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0968 - val_loss: 0.1250
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.096843034>, 'val_loss': 0.1249522939324379}
Epoch 284/4000

Epoch 00284: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0968 - val_loss: 0.1189
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.096839055>, 'val_loss': 0.11893710494041443}
Epoch 285/4000

Epoch 00285: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0963 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09628815>, 'val_loss': 0.1262081116437912}
Epoch 286/4000

Epoch 00286: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0970 - val_loss: 0.1240
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.097019486>, 'val_loss': 0.12401231378316879}
Epoch 287/4000

Epoch 00287: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0963 - val_loss: 0.1228
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0963026>, 'val_loss': 0.12284418195486069}
Epoch 288/4000

Epoch 00288: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0969 - val_loss: 0.1242
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09689926>, 'val_loss': 0.12420255690813065}
Epoch 289/4000

Epoch 00289: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0950 - val_loss: 0.1226
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09503076>, 'val_loss': 0.12259882688522339}
Epoch 290/4000

Epoch 00290: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0971 - val_loss: 0.1205
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09712201>, 'val_loss': 0.12047739326953888}
Epoch 291/4000

Epoch 00291: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0959 - val_loss: 0.1261
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.095938064>, 'val_loss': 0.12607042491436005}
Epoch 292/4000

Epoch 00292: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0965 - val_loss: 0.1246
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09651651>, 'val_loss': 0.12460774183273315}
Epoch 293/4000

Epoch 00293: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0960 - val_loss: 0.1287
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.095965385>, 'val_loss': 0.1287008672952652}
Epoch 294/4000

Epoch 00294: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0959 - val_loss: 0.1234
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09591331>, 'val_loss': 0.12341898679733276}
Epoch 295/4000

Epoch 00295: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0952 - val_loss: 0.1225
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09519667>, 'val_loss': 0.12251826375722885}
Epoch 296/4000

Epoch 00296: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0960 - val_loss: 0.1214
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.095992066>, 'val_loss': 0.12136424332857132}
Epoch 297/4000

Epoch 00297: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0954 - val_loss: 0.1271
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.095377125>, 'val_loss': 0.12705640494823456}
Epoch 298/4000

Epoch 00298: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0947 - val_loss: 0.1254
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09469951>, 'val_loss': 0.12536287307739258}
Epoch 299/4000

Epoch 00299: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0946 - val_loss: 0.1247
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09455269>, 'val_loss': 0.12466681748628616}
Epoch 300/4000

Epoch 00300: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0959 - val_loss: 0.1245
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09591902>, 'val_loss': 0.12454696744680405}
Model saved in ./model/scPDB_2021_pdbid--300--0.1245.
Epoch 301/4000

Epoch 00301: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0938 - val_loss: 0.1218
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.093834035>, 'val_loss': 0.12181075662374496}
Epoch 302/4000

Epoch 00302: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0957 - val_loss: 0.1202
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09568405>, 'val_loss': 0.12016641348600388}
Epoch 303/4000

Epoch 00303: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0947 - val_loss: 0.1238
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09468364>, 'val_loss': 0.1237676739692688}
Epoch 304/4000

Epoch 00304: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0947 - val_loss: 0.1290
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09465655>, 'val_loss': 0.12897036969661713}
Epoch 305/4000

Epoch 00305: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0951 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09514374>, 'val_loss': 0.12555275857448578}
Epoch 306/4000

Epoch 00306: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0947 - val_loss: 0.1263
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09473621>, 'val_loss': 0.12626729905605316}
Epoch 307/4000

Epoch 00307: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0933 - val_loss: 0.1260
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.093255185>, 'val_loss': 0.1259898990392685}
Epoch 308/4000

Epoch 00308: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0953 - val_loss: 0.1243
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09526058>, 'val_loss': 0.12434785813093185}
Epoch 309/4000

Epoch 00309: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0933 - val_loss: 0.1240
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09330571>, 'val_loss': 0.1240411028265953}
Epoch 310/4000

Epoch 00310: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0944 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09437651>, 'val_loss': 0.12683437764644623}
Epoch 311/4000

Epoch 00311: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0944 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09437691>, 'val_loss': 0.12561722099781036}
Epoch 312/4000

Epoch 00312: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0942 - val_loss: 0.1270
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09424406>, 'val_loss': 0.12698973715305328}
Epoch 313/4000

Epoch 00313: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0935 - val_loss: 0.1250
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09346156>, 'val_loss': 0.12502725422382355}
Epoch 314/4000

Epoch 00314: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0932 - val_loss: 0.1199
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09320974>, 'val_loss': 0.11992371082305908}
Epoch 315/4000

Epoch 00315: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0933 - val_loss: 0.1258
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.093321405>, 'val_loss': 0.12576355040073395}
Epoch 316/4000

Epoch 00316: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0926 - val_loss: 0.1291
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09257177>, 'val_loss': 0.1291343718767166}
Epoch 317/4000

Epoch 00317: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0936 - val_loss: 0.1270
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09359349>, 'val_loss': 0.1270146518945694}
Epoch 318/4000

Epoch 00318: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0933 - val_loss: 0.1252
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09331673>, 'val_loss': 0.12518958747386932}
Epoch 319/4000

Epoch 00319: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0925 - val_loss: 0.1249
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09246919>, 'val_loss': 0.12486354261636734}
Epoch 320/4000

Epoch 00320: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0932 - val_loss: 0.1251
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09320167>, 'val_loss': 0.1250721961259842}
Epoch 321/4000

Epoch 00321: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0938 - val_loss: 0.1249
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09381398>, 'val_loss': 0.12486030906438828}
Epoch 322/4000

Epoch 00322: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0924 - val_loss: 0.1243
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09240523>, 'val_loss': 0.12433993071317673}
Epoch 323/4000

Epoch 00323: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0930 - val_loss: 0.1261
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09301459>, 'val_loss': 0.12612216174602509}
Epoch 324/4000

Epoch 00324: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0934 - val_loss: 0.1223
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09343768>, 'val_loss': 0.12230373173952103}
Epoch 325/4000

Epoch 00325: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0918 - val_loss: 0.1266
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0918037>, 'val_loss': 0.12655659019947052}
Epoch 326/4000

Epoch 00326: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0914 - val_loss: 0.1222
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09141296>, 'val_loss': 0.1222243383526802}
Epoch 327/4000

Epoch 00327: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0914 - val_loss: 0.1289
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09140356>, 'val_loss': 0.12891945242881775}
Epoch 328/4000

Epoch 00328: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0926 - val_loss: 0.1244
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.092588834>, 'val_loss': 0.12435108423233032}
Epoch 329/4000

Epoch 00329: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0919 - val_loss: 0.1319
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09189208>, 'val_loss': 0.1318567991256714}
Epoch 330/4000

Epoch 00330: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0922 - val_loss: 0.1303
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09222451>, 'val_loss': 0.13029123842716217}
Epoch 331/4000

Epoch 00331: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0911 - val_loss: 0.1347
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09112472>, 'val_loss': 0.13469474017620087}
Epoch 332/4000

Epoch 00332: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0915 - val_loss: 0.1222
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09147772>, 'val_loss': 0.12215013056993484}
Epoch 333/4000

Epoch 00333: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0923 - val_loss: 0.1256
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09231709>, 'val_loss': 0.12559819221496582}
Epoch 334/4000

Epoch 00334: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0910 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09101317>, 'val_loss': 0.12677858769893646}
Epoch 335/4000

Epoch 00335: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0924 - val_loss: 0.1249
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.092447616>, 'val_loss': 0.12494112551212311}
Epoch 336/4000

Epoch 00336: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0917 - val_loss: 0.1245
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09166536>, 'val_loss': 0.12445074319839478}
Epoch 337/4000

Epoch 00337: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0911 - val_loss: 0.1260
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09110732>, 'val_loss': 0.12598161399364471}
Epoch 338/4000

Epoch 00338: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0903 - val_loss: 0.1264
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09029239>, 'val_loss': 0.1263832300901413}
Epoch 339/4000

Epoch 00339: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0913 - val_loss: 0.1284
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.091338105>, 'val_loss': 0.1284390091896057}
Epoch 340/4000

Epoch 00340: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0901 - val_loss: 0.1243
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.090146475>, 'val_loss': 0.12428230792284012}
Epoch 341/4000

Epoch 00341: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0920 - val_loss: 0.1311
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09201388>, 'val_loss': 0.13113847374916077}
Epoch 342/4000

Epoch 00342: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0911 - val_loss: 0.1241
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09105445>, 'val_loss': 0.12408097833395004}
Epoch 343/4000

Epoch 00343: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0906 - val_loss: 0.1275
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.09059979>, 'val_loss': 0.1275387406349182}
Epoch 344/4000

Epoch 00344: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0908 - val_loss: 0.1237
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.090831764>, 'val_loss': 0.1236555352807045}
Epoch 345/4000

Epoch 00345: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0900 - val_loss: 0.1293
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08997297>, 'val_loss': 0.12925474345684052}
Epoch 346/4000

Epoch 00346: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0888 - val_loss: 0.1266
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08883483>, 'val_loss': 0.126630499958992}
Epoch 347/4000

Epoch 00347: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0913 - val_loss: 0.1272
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.091348566>, 'val_loss': 0.12722867727279663}
Epoch 348/4000

Epoch 00348: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0900 - val_loss: 0.1270
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.089954354>, 'val_loss': 0.12702667713165283}
Epoch 349/4000

Epoch 00349: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0899 - val_loss: 0.1239
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08986346>, 'val_loss': 0.12390121072530746}
Epoch 350/4000

Epoch 00350: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0896 - val_loss: 0.1292
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.089612596>, 'val_loss': 0.12918774783611298}
Model saved in ./model/scPDB_2021_pdbid--350--0.1292.
Epoch 351/4000

Epoch 00351: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0895 - val_loss: 0.1255
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08948812>, 'val_loss': 0.12546414136886597}
Epoch 352/4000

Epoch 00352: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0894 - val_loss: 0.1289
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.089351>, 'val_loss': 0.12893462181091309}
Epoch 353/4000

Epoch 00353: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0895 - val_loss: 0.1349
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08952701>, 'val_loss': 0.13487206399440765}
Epoch 354/4000

Epoch 00354: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0884 - val_loss: 0.1232
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08840678>, 'val_loss': 0.12316177040338516}
Epoch 355/4000

Epoch 00355: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0900 - val_loss: 0.1267
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08997329>, 'val_loss': 0.12666398286819458}
Epoch 356/4000

Epoch 00356: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0898 - val_loss: 0.1230
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0897831>, 'val_loss': 0.12297991663217545}
Epoch 357/4000

Epoch 00357: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0898 - val_loss: 0.1283
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08984055>, 'val_loss': 0.12829096615314484}
Epoch 358/4000

Epoch 00358: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0895 - val_loss: 0.1309
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08945135>, 'val_loss': 0.1308879852294922}
Epoch 359/4000

Epoch 00359: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0881 - val_loss: 0.1317
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08810299>, 'val_loss': 0.13169114291667938}
Epoch 360/4000

Epoch 00360: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0896 - val_loss: 0.1276
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.089600645>, 'val_loss': 0.1276281476020813}
Epoch 361/4000

Epoch 00361: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0892 - val_loss: 0.1307
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08919344>, 'val_loss': 0.13065926730632782}
Epoch 362/4000

Epoch 00362: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0878 - val_loss: 0.1270
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08781645>, 'val_loss': 0.12702703475952148}
Epoch 363/4000

Epoch 00363: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0886 - val_loss: 0.1274
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08856959>, 'val_loss': 0.12738513946533203}
Epoch 364/4000

Epoch 00364: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0882 - val_loss: 0.1259
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08815781>, 'val_loss': 0.12593518197536469}
Epoch 365/4000

Epoch 00365: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0903 - val_loss: 0.1295
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.090304084>, 'val_loss': 0.12952300906181335}
Epoch 366/4000

Epoch 00366: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0893 - val_loss: 0.1248
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.089340486>, 'val_loss': 0.12479057163000107}
Epoch 367/4000

Epoch 00367: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0876 - val_loss: 0.1339
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0876319>, 'val_loss': 0.13393016159534454}
Epoch 368/4000

Epoch 00368: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0894 - val_loss: 0.1281
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08939252>, 'val_loss': 0.1280723363161087}
Epoch 369/4000

Epoch 00369: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0885 - val_loss: 0.1254
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08847823>, 'val_loss': 0.1253868043422699}
Epoch 370/4000

Epoch 00370: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0880 - val_loss: 0.1323
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.087960295>, 'val_loss': 0.13228757679462433}
Epoch 371/4000

Epoch 00371: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0866 - val_loss: 0.1269
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08659545>, 'val_loss': 0.12687933444976807}
Epoch 372/4000

Epoch 00372: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0889 - val_loss: 0.1307
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08888796>, 'val_loss': 0.13068489730358124}
Epoch 373/4000

Epoch 00373: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0874 - val_loss: 0.1308
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.087421365>, 'val_loss': 0.13081632554531097}
Epoch 374/4000

Epoch 00374: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0889 - val_loss: 0.1307
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.088916644>, 'val_loss': 0.13074710965156555}
Epoch 375/4000

Epoch 00375: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0874 - val_loss: 0.1315
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08742168>, 'val_loss': 0.13154639303684235}
Epoch 376/4000

Epoch 00376: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0889 - val_loss: 0.1295
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08887132>, 'val_loss': 0.12952981889247894}
Epoch 377/4000

Epoch 00377: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0865 - val_loss: 0.1247
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08647504>, 'val_loss': 0.12468492984771729}
Epoch 378/4000

Epoch 00378: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0875 - val_loss: 0.1311
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0875422>, 'val_loss': 0.13106055557727814}
Epoch 379/4000

Epoch 00379: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0876 - val_loss: 0.1271
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08758684>, 'val_loss': 0.12708628177642822}
Epoch 380/4000

Epoch 00380: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0876 - val_loss: 0.1313
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08761508>, 'val_loss': 0.13125263154506683}
Epoch 381/4000

Epoch 00381: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0864 - val_loss: 0.1292
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08644593>, 'val_loss': 0.12922285497188568}
Epoch 382/4000

Epoch 00382: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0876 - val_loss: 0.1287
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08759548>, 'val_loss': 0.12871748208999634}
Epoch 383/4000

Epoch 00383: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0873 - val_loss: 0.1348
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08729836>, 'val_loss': 0.13478849828243256}
Epoch 384/4000

Epoch 00384: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0867 - val_loss: 0.1264
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08670012>, 'val_loss': 0.12637226283550262}
Epoch 385/4000

Epoch 00385: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0868 - val_loss: 0.1313
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0867846>, 'val_loss': 0.1313481628894806}
Epoch 386/4000

Epoch 00386: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0868 - val_loss: 0.1284
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.086803995>, 'val_loss': 0.12841841578483582}
Epoch 387/4000

Epoch 00387: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0864 - val_loss: 0.1295
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.086363345>, 'val_loss': 0.12947313487529755}
Epoch 388/4000

Epoch 00388: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0869 - val_loss: 0.1306
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08688008>, 'val_loss': 0.1305769979953766}
Epoch 389/4000

Epoch 00389: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0867 - val_loss: 0.1348
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.086681366>, 'val_loss': 0.13480886816978455}
Epoch 390/4000

Epoch 00390: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0870 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0869967>, 'val_loss': 0.12619222700595856}
Epoch 391/4000

Epoch 00391: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0856 - val_loss: 0.1326
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08564571>, 'val_loss': 0.13259421288967133}
Epoch 392/4000

Epoch 00392: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0868 - val_loss: 0.1252
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08675858>, 'val_loss': 0.1252080351114273}
Epoch 393/4000

Epoch 00393: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0854 - val_loss: 0.1325
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08538211>, 'val_loss': 0.13250739872455597}
Epoch 394/4000

Epoch 00394: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0865 - val_loss: 0.1310
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08650499>, 'val_loss': 0.1309833526611328}
Epoch 395/4000

Epoch 00395: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0861 - val_loss: 0.1319
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08611586>, 'val_loss': 0.13187658786773682}
Epoch 396/4000

Epoch 00396: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0854 - val_loss: 0.1254
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0854421>, 'val_loss': 0.12540464103221893}
Epoch 397/4000

Epoch 00397: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0856 - val_loss: 0.1328
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.085644804>, 'val_loss': 0.13278478384017944}
Epoch 398/4000

Epoch 00398: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0861 - val_loss: 0.1269
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08605517>, 'val_loss': 0.12691015005111694}
Epoch 399/4000

Epoch 00399: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0855 - val_loss: 0.1333
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08554753>, 'val_loss': 0.1332557052373886}
Epoch 400/4000

Epoch 00400: LearningRateScheduler reducing learning rate to 0.0010000000474974513.
24/24 - 2s - loss: 0.0853 - val_loss: 0.1316
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08529637>, 'val_loss': 0.13162292540073395}
Model saved in ./model/scPDB_2021_pdbid--400--0.1316.
Epoch 401/4000

Epoch 00401: LearningRateScheduler reducing learning rate to 0.001.
24/24 - 2s - loss: 0.0854 - val_loss: 0.1272
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08536857>, 'val_loss': 0.1272294968366623}
Epoch 402/4000

Epoch 00402: LearningRateScheduler reducing learning rate to 0.0009956919592956843.
24/24 - 2s - loss: 0.0856 - val_loss: 0.1328
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.085641444>, 'val_loss': 0.13275273144245148}
Epoch 403/4000

Epoch 00403: LearningRateScheduler reducing learning rate to 0.0009914024778060787.
24/24 - 2s - loss: 0.0850 - val_loss: 0.1349
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08500034>, 'val_loss': 0.13493303954601288}
Epoch 404/4000

Epoch 00404: LearningRateScheduler reducing learning rate to 0.0009871314755773306.
24/24 - 2s - loss: 0.0858 - val_loss: 0.1268
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08577874>, 'val_loss': 0.1267736554145813}
Epoch 405/4000

Epoch 00405: LearningRateScheduler reducing learning rate to 0.0009828788730000323.
24/24 - 2s - loss: 0.0857 - val_loss: 0.1316
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.085652165>, 'val_loss': 0.1316063553094864}
Epoch 406/4000

Epoch 00406: LearningRateScheduler reducing learning rate to 0.0009786445908077362.
24/24 - 2s - loss: 0.0848 - val_loss: 0.1307
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08476934>, 'val_loss': 0.13073623180389404}
Epoch 407/4000

Epoch 00407: LearningRateScheduler reducing learning rate to 0.000974428550075478.
24/24 - 2s - loss: 0.0849 - val_loss: 0.1314
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08488892>, 'val_loss': 0.1313837468624115}
Epoch 408/4000

Epoch 00408: LearningRateScheduler reducing learning rate to 0.0009702306722183054.
24/24 - 2s - loss: 0.0852 - val_loss: 0.1286
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08515216>, 'val_loss': 0.12863506376743317}
Epoch 409/4000

Epoch 00409: LearningRateScheduler reducing learning rate to 0.0009660508789898133.
24/24 - 2s - loss: 0.0842 - val_loss: 0.1331
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084226936>, 'val_loss': 0.13310976326465607}
Epoch 410/4000

Epoch 00410: LearningRateScheduler reducing learning rate to 0.0009618890924806854.
24/24 - 2s - loss: 0.0842 - val_loss: 0.1262
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084192>, 'val_loss': 0.12623243033885956}
Epoch 411/4000

Epoch 00411: LearningRateScheduler reducing learning rate to 0.0009577452351172412.
24/24 - 2s - loss: 0.0846 - val_loss: 0.1315
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084570155>, 'val_loss': 0.13147366046905518}
Epoch 412/4000

Epoch 00412: LearningRateScheduler reducing learning rate to 0.0009536192296599917.
24/24 - 2s - loss: 0.0840 - val_loss: 0.1313
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08404642>, 'val_loss': 0.13127672672271729}
Epoch 413/4000

Epoch 00413: LearningRateScheduler reducing learning rate to 0.0009495109992021982.
24/24 - 2s - loss: 0.0836 - val_loss: 0.1308
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08361632>, 'val_loss': 0.13078254461288452}
Epoch 414/4000

Epoch 00414: LearningRateScheduler reducing learning rate to 0.0009454204671684397.
24/24 - 2s - loss: 0.0846 - val_loss: 0.1315
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084552996>, 'val_loss': 0.1315012127161026}
Epoch 415/4000

Epoch 00415: LearningRateScheduler reducing learning rate to 0.0009413475573131849.
24/24 - 2s - loss: 0.0841 - val_loss: 0.1330
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084104985>, 'val_loss': 0.13297778367996216}
Epoch 416/4000

Epoch 00416: LearningRateScheduler reducing learning rate to 0.0009372921937193714.
24/24 - 2s - loss: 0.0846 - val_loss: 0.1275
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084560804>, 'val_loss': 0.127454936504364}
Epoch 417/4000

Epoch 00417: LearningRateScheduler reducing learning rate to 0.000933254300796991.
24/24 - 2s - loss: 0.0834 - val_loss: 0.1294
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08341999>, 'val_loss': 0.12944439053535461}
Epoch 418/4000

Epoch 00418: LearningRateScheduler reducing learning rate to 0.0009292338032816799.
24/24 - 2s - loss: 0.0841 - val_loss: 0.1338
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084112115>, 'val_loss': 0.13375206291675568}
Epoch 419/4000

Epoch 00419: LearningRateScheduler reducing learning rate to 0.0009252306262333164.
24/24 - 2s - loss: 0.0837 - val_loss: 0.1274
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08374774>, 'val_loss': 0.12739746272563934}
Epoch 420/4000

Epoch 00420: LearningRateScheduler reducing learning rate to 0.0009212446950346237.
24/24 - 2s - loss: 0.0845 - val_loss: 0.1292
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08450291>, 'val_loss': 0.12917913496494293}
Epoch 421/4000

Epoch 00421: LearningRateScheduler reducing learning rate to 0.0009172759353897796.
24/24 - 2s - loss: 0.0828 - val_loss: 0.1294
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08276711>, 'val_loss': 0.12943468987941742}
Epoch 422/4000

Epoch 00422: LearningRateScheduler reducing learning rate to 0.0009133242733230312.
24/24 - 2s - loss: 0.0819 - val_loss: 0.1389
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08194106>, 'val_loss': 0.138875812292099}
Epoch 423/4000

Epoch 00423: LearningRateScheduler reducing learning rate to 0.0009093896351773159.
24/24 - 2s - loss: 0.0842 - val_loss: 0.1296
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.084182374>, 'val_loss': 0.1295827478170395}
Epoch 424/4000

Epoch 00424: LearningRateScheduler reducing learning rate to 0.0009054719476128893.
24/24 - 2s - loss: 0.0821 - val_loss: 0.1366
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08208249>, 'val_loss': 0.13661634922027588}
Epoch 425/4000

Epoch 00425: LearningRateScheduler reducing learning rate to 0.0009015711376059569.
24/24 - 2s - loss: 0.0836 - val_loss: 0.1354
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08357>, 'val_loss': 0.13535746932029724}
Epoch 426/4000

Epoch 00426: LearningRateScheduler reducing learning rate to 0.0008976871324473143.
24/24 - 2s - loss: 0.0828 - val_loss: 0.1259
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08281007>, 'val_loss': 0.1259385198354721}
Epoch 427/4000

Epoch 00427: LearningRateScheduler reducing learning rate to 0.0008938198597409907.
24/24 - 2s - loss: 0.0830 - val_loss: 0.1273
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08303884>, 'val_loss': 0.12734955549240112}
Epoch 428/4000

Epoch 00428: LearningRateScheduler reducing learning rate to 0.0008899692474029008.
24/24 - 2s - loss: 0.0833 - val_loss: 0.1270
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08327238>, 'val_loss': 0.12701934576034546}
Epoch 429/4000

Epoch 00429: LearningRateScheduler reducing learning rate to 0.0008861352236594998.
24/24 - 2s - loss: 0.0816 - val_loss: 0.1298
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08164833>, 'val_loss': 0.1298380196094513}
Epoch 430/4000

Epoch 00430: LearningRateScheduler reducing learning rate to 0.0008823177170464468.
24/24 - 2s - loss: 0.0832 - val_loss: 0.1323
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08316844>, 'val_loss': 0.13230669498443604}
Epoch 431/4000

Epoch 00431: LearningRateScheduler reducing learning rate to 0.0008785166564072717.
24/24 - 2s - loss: 0.0826 - val_loss: 0.1337
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08260159>, 'val_loss': 0.13374601304531097}
Epoch 432/4000

Epoch 00432: LearningRateScheduler reducing learning rate to 0.0008747319708920499.
24/24 - 2s - loss: 0.0826 - val_loss: 0.1360
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08255989>, 'val_loss': 0.1359582543373108}
Epoch 433/4000

Epoch 00433: LearningRateScheduler reducing learning rate to 0.0008709635899560806.
24/24 - 2s - loss: 0.0816 - val_loss: 0.1327
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08162245>, 'val_loss': 0.13273277878761292}
Epoch 434/4000

Epoch 00434: LearningRateScheduler reducing learning rate to 0.000867211443358573.
24/24 - 2s - loss: 0.0826 - val_loss: 0.1337
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08259965>, 'val_loss': 0.13370221853256226}
Epoch 435/4000

Epoch 00435: LearningRateScheduler reducing learning rate to 0.0008634754611613358.
24/24 - 2s - loss: 0.0820 - val_loss: 0.1312
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08203081>, 'val_loss': 0.13116811215877533}
Epoch 436/4000

Epoch 00436: LearningRateScheduler reducing learning rate to 0.000859755573727475.
24/24 - 2s - loss: 0.0813 - val_loss: 0.1319
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.081319965>, 'val_loss': 0.1319095343351364}
Epoch 437/4000

Epoch 00437: LearningRateScheduler reducing learning rate to 0.0008560517117200947.
24/24 - 2s - loss: 0.0818 - val_loss: 0.1371
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.081838705>, 'val_loss': 0.1371273547410965}
Epoch 438/4000

Epoch 00438: LearningRateScheduler reducing learning rate to 0.0008523638061010054.
24/24 - 2s - loss: 0.0818 - val_loss: 0.1297
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08182967>, 'val_loss': 0.12967099249362946}
Epoch 439/4000

Epoch 00439: LearningRateScheduler reducing learning rate to 0.0008486917881294368.
24/24 - 2s - loss: 0.0816 - val_loss: 0.1340
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08158499>, 'val_loss': 0.13396257162094116}
Epoch 440/4000

Epoch 00440: LearningRateScheduler reducing learning rate to 0.0008450355893607567.
24/24 - 2s - loss: 0.0821 - val_loss: 0.1384
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.082119815>, 'val_loss': 0.13840416073799133}
Epoch 441/4000

Epoch 00441: LearningRateScheduler reducing learning rate to 0.0008413951416451951.
24/24 - 2s - loss: 0.0814 - val_loss: 0.1363
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08144425>, 'val_loss': 0.13629023730754852}
Epoch 442/4000

Epoch 00442: LearningRateScheduler reducing learning rate to 0.0008377703771265742.
24/24 - 2s - loss: 0.0816 - val_loss: 0.1365
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08158114>, 'val_loss': 0.1364515870809555}
Epoch 443/4000

Epoch 00443: LearningRateScheduler reducing learning rate to 0.0008341612282410429.
24/24 - 2s - loss: 0.0812 - val_loss: 0.1320
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08118439>, 'val_loss': 0.13198770582675934}
Epoch 444/4000

Epoch 00444: LearningRateScheduler reducing learning rate to 0.0008305676277158185.
24/24 - 2s - loss: 0.0808 - val_loss: 0.1319
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08080991>, 'val_loss': 0.131891667842865}
Epoch 445/4000

Epoch 00445: LearningRateScheduler reducing learning rate to 0.0008269895085679318.
24/24 - 2s - loss: 0.0815 - val_loss: 0.1338
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08148465>, 'val_loss': 0.13378606736660004}
Epoch 446/4000

Epoch 00446: LearningRateScheduler reducing learning rate to 0.0008234268041029791.
24/24 - 2s - loss: 0.0801 - val_loss: 0.1423
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08012107>, 'val_loss': 0.14230890572071075}
Epoch 447/4000

Epoch 00447: LearningRateScheduler reducing learning rate to 0.0008198794479138788.
24/24 - 2s - loss: 0.0817 - val_loss: 0.1354
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.081702694>, 'val_loss': 0.13540972769260406}
Epoch 448/4000

Epoch 00448: LearningRateScheduler reducing learning rate to 0.000816347373879634.
24/24 - 2s - loss: 0.0803 - val_loss: 0.1355
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08027534>, 'val_loss': 0.13549555838108063}
Epoch 449/4000

Epoch 00449: LearningRateScheduler reducing learning rate to 0.0008128305161640992.
24/24 - 2s - loss: 0.0813 - val_loss: 0.1336
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.081299394>, 'val_loss': 0.1335894614458084}
Epoch 450/4000

Epoch 00450: LearningRateScheduler reducing learning rate to 0.0008093288092147543.
24/24 - 2s - loss: 0.0800 - val_loss: 0.1348
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07997878>, 'val_loss': 0.13477326929569244}
Model saved in ./model/scPDB_2021_pdbid--450--0.1348.
Epoch 451/4000

Epoch 00451: LearningRateScheduler reducing learning rate to 0.0008058421877614818.
24/24 - 2s - loss: 0.0820 - val_loss: 0.1305
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08199034>, 'val_loss': 0.1304730325937271}
Epoch 452/4000

Epoch 00452: LearningRateScheduler reducing learning rate to 0.0008023705868153506.
24/24 - 2s - loss: 0.0801 - val_loss: 0.1377
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.080121376>, 'val_loss': 0.13773201406002045}
Epoch 453/4000

Epoch 00453: LearningRateScheduler reducing learning rate to 0.0007989139416674043.
24/24 - 2s - loss: 0.0803 - val_loss: 0.1333
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08030107>, 'val_loss': 0.13328732550144196}
Epoch 454/4000

Epoch 00454: LearningRateScheduler reducing learning rate to 0.0007954721878874558.
24/24 - 2s - loss: 0.0811 - val_loss: 0.1281
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08106906>, 'val_loss': 0.12812717258930206}
Epoch 455/4000

Epoch 00455: LearningRateScheduler reducing learning rate to 0.0007920452613228855.
24/24 - 2s - loss: 0.0802 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08022801>, 'val_loss': 0.13872015476226807}
Epoch 456/4000

Epoch 00456: LearningRateScheduler reducing learning rate to 0.0007886330980974462.
24/24 - 2s - loss: 0.0808 - val_loss: 0.1367
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08081239>, 'val_loss': 0.13665999472141266}
Epoch 457/4000

Epoch 00457: LearningRateScheduler reducing learning rate to 0.0007852356346100718.
24/24 - 2s - loss: 0.0797 - val_loss: 0.1327
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07965041>, 'val_loss': 0.13268952071666718}
Epoch 458/4000

Epoch 00458: LearningRateScheduler reducing learning rate to 0.0007818528075336923.
24/24 - 2s - loss: 0.0803 - val_loss: 0.1394
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08034995>, 'val_loss': 0.13938874006271362}
Epoch 459/4000

Epoch 00459: LearningRateScheduler reducing learning rate to 0.0007784845538140537.
24/24 - 2s - loss: 0.0801 - val_loss: 0.1363
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08011013>, 'val_loss': 0.13627292215824127}
Epoch 460/4000

Epoch 00460: LearningRateScheduler reducing learning rate to 0.0007751308106685417.
24/24 - 2s - loss: 0.0793 - val_loss: 0.1356
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07934388>, 'val_loss': 0.1355607509613037}
Epoch 461/4000

Epoch 00461: LearningRateScheduler reducing learning rate to 0.0007717915155850124.
24/24 - 2s - loss: 0.0810 - val_loss: 0.1318
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.08098268>, 'val_loss': 0.13177312910556793}
Epoch 462/4000

Epoch 00462: LearningRateScheduler reducing learning rate to 0.0007684666063206267.
24/24 - 2s - loss: 0.0793 - val_loss: 0.1389
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07930776>, 'val_loss': 0.13885287940502167}
Epoch 463/4000

Epoch 00463: LearningRateScheduler reducing learning rate to 0.00076515602090069.
24/24 - 2s - loss: 0.0798 - val_loss: 0.1360
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07982657>, 'val_loss': 0.13600455224514008}
Epoch 464/4000

Epoch 00464: LearningRateScheduler reducing learning rate to 0.0007618596976174977.
24/24 - 2s - loss: 0.0790 - val_loss: 0.1349
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07897777>, 'val_loss': 0.13487829267978668}
Epoch 465/4000

Epoch 00465: LearningRateScheduler reducing learning rate to 0.0007585775750291837.
24/24 - 2s - loss: 0.0807 - val_loss: 0.1322
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.080690175>, 'val_loss': 0.13215142488479614}
Epoch 466/4000

Epoch 00466: LearningRateScheduler reducing learning rate to 0.000755309591958577.
24/24 - 2s - loss: 0.0790 - val_loss: 0.1360
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07898832>, 'val_loss': 0.1359880119562149}
Epoch 467/4000

Epoch 00467: LearningRateScheduler reducing learning rate to 0.0007520556874920593.
24/24 - 2s - loss: 0.0799 - val_loss: 0.1300
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07993855>, 'val_loss': 0.1300380676984787}
Epoch 468/4000

Epoch 00468: LearningRateScheduler reducing learning rate to 0.0007488158009784314.
24/24 - 2s - loss: 0.0798 - val_loss: 0.1357
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07978559>, 'val_loss': 0.13567811250686646}
Epoch 469/4000

Epoch 00469: LearningRateScheduler reducing learning rate to 0.0007455898720277815.
24/24 - 2s - loss: 0.0797 - val_loss: 0.1326
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.079724945>, 'val_loss': 0.13263839483261108}
Epoch 470/4000

Epoch 00470: LearningRateScheduler reducing learning rate to 0.0007423778405103603.
24/24 - 2s - loss: 0.0790 - val_loss: 0.1409
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.078983024>, 'val_loss': 0.14091140031814575}
Epoch 471/4000

Epoch 00471: LearningRateScheduler reducing learning rate to 0.0007391796465554596.
24/24 - 2s - loss: 0.0793 - val_loss: 0.1342
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0793312>, 'val_loss': 0.13424938917160034}
Epoch 472/4000

Epoch 00472: LearningRateScheduler reducing learning rate to 0.0007359952305502971.
24/24 - 2s - loss: 0.0787 - val_loss: 0.1333
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07873716>, 'val_loss': 0.1333036571741104}
Epoch 473/4000

Epoch 00473: LearningRateScheduler reducing learning rate to 0.0007328245331389041.
24/24 - 2s - loss: 0.0796 - val_loss: 0.1390
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0795872>, 'val_loss': 0.1389814168214798}
Epoch 474/4000

Epoch 00474: LearningRateScheduler reducing learning rate to 0.0007296674952210205.
24/24 - 2s - loss: 0.0784 - val_loss: 0.1370
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.078370206>, 'val_loss': 0.1370394080877304}
Epoch 475/4000

Epoch 00475: LearningRateScheduler reducing learning rate to 0.0007265240579509923.
24/24 - 2s - loss: 0.0787 - val_loss: 0.1390
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07870213>, 'val_loss': 0.13896764814853668}
Epoch 476/4000

Epoch 00476: LearningRateScheduler reducing learning rate to 0.0007233941627366748.
24/24 - 2s - loss: 0.0782 - val_loss: 0.1338
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07817045>, 'val_loss': 0.13378269970417023}
Epoch 477/4000

Epoch 00477: LearningRateScheduler reducing learning rate to 0.0007202777512383407.
24/24 - 2s - loss: 0.0787 - val_loss: 0.1361
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07872101>, 'val_loss': 0.13605642318725586}
Epoch 478/4000

Epoch 00478: LearningRateScheduler reducing learning rate to 0.0007171747653675931.
24/24 - 2s - loss: 0.0784 - val_loss: 0.1391
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07838665>, 'val_loss': 0.13914816081523895}
Epoch 479/4000

Epoch 00479: LearningRateScheduler reducing learning rate to 0.0007140851472862814.
24/24 - 2s - loss: 0.0786 - val_loss: 0.1381
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.078637965>, 'val_loss': 0.13807249069213867}
Epoch 480/4000

Epoch 00480: LearningRateScheduler reducing learning rate to 0.0007110088394054247.
24/24 - 2s - loss: 0.0785 - val_loss: 0.1362
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07851106>, 'val_loss': 0.13624460995197296}
Epoch 481/4000

Epoch 00481: LearningRateScheduler reducing learning rate to 0.0007079457843841379.
24/24 - 2s - loss: 0.0775 - val_loss: 0.1388
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07746924>, 'val_loss': 0.13878233730793}
Epoch 482/4000

Epoch 00482: LearningRateScheduler reducing learning rate to 0.0007048959251285623.
24/24 - 2s - loss: 0.0793 - val_loss: 0.1414
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07930766>, 'val_loss': 0.1414177268743515}
Epoch 483/4000

Epoch 00483: LearningRateScheduler reducing learning rate to 0.0007018592047908023.
24/24 - 2s - loss: 0.0781 - val_loss: 0.1363
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07810497>, 'val_loss': 0.1363099366426468}
Epoch 484/4000

Epoch 00484: LearningRateScheduler reducing learning rate to 0.0006988355667678647.
24/24 - 2s - loss: 0.0779 - val_loss: 0.1332
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07792039>, 'val_loss': 0.13316844403743744}
Epoch 485/4000

Epoch 00485: LearningRateScheduler reducing learning rate to 0.0006958249547006053.
24/24 - 2s - loss: 0.0775 - val_loss: 0.1418
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07754403>, 'val_loss': 0.14180730283260345}
Epoch 486/4000

Epoch 00486: LearningRateScheduler reducing learning rate to 0.0006928273124726763.
24/24 - 2s - loss: 0.0789 - val_loss: 0.1356
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07888725>, 'val_loss': 0.1356164813041687}
Epoch 487/4000

Epoch 00487: LearningRateScheduler reducing learning rate to 0.0006898425842094824.
24/24 - 2s - loss: 0.0772 - val_loss: 0.1357
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.077168025>, 'val_loss': 0.135744109749794}
Epoch 488/4000

Epoch 00488: LearningRateScheduler reducing learning rate to 0.0006868707142771377.
24/24 - 2s - loss: 0.0785 - val_loss: 0.1384
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07845808>, 'val_loss': 0.13838478922843933}
Epoch 489/4000

Epoch 00489: LearningRateScheduler reducing learning rate to 0.0006839116472814293.
24/24 - 2s - loss: 0.0773 - val_loss: 0.1361
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07734612>, 'val_loss': 0.1360781341791153}
Epoch 490/4000

Epoch 00490: LearningRateScheduler reducing learning rate to 0.0006809653280667854.
24/24 - 2s - loss: 0.0779 - val_loss: 0.1408
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07791834>, 'val_loss': 0.1408102959394455}
Epoch 491/4000

Epoch 00491: LearningRateScheduler reducing learning rate to 0.0006780317017152459.
24/24 - 2s - loss: 0.0770 - val_loss: 0.1386
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07704767>, 'val_loss': 0.13856548070907593}
Epoch 492/4000

Epoch 00492: LearningRateScheduler reducing learning rate to 0.0006751107135454402.
24/24 - 2s - loss: 0.0780 - val_loss: 0.1414
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07802699>, 'val_loss': 0.14136378467082977}
Epoch 493/4000

Epoch 00493: LearningRateScheduler reducing learning rate to 0.0006722023091115667.
24/24 - 2s - loss: 0.0772 - val_loss: 0.1444
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.077237986>, 'val_loss': 0.1443595290184021}
Epoch 494/4000

Epoch 00494: LearningRateScheduler reducing learning rate to 0.0006693064342023792.
24/24 - 2s - loss: 0.0773 - val_loss: 0.1352
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07728196>, 'val_loss': 0.13519558310508728}
Epoch 495/4000

Epoch 00495: LearningRateScheduler reducing learning rate to 0.0006664230348401749.
24/24 - 2s - loss: 0.0784 - val_loss: 0.1372
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07835881>, 'val_loss': 0.13722781836986542}
Epoch 496/4000

Epoch 00496: LearningRateScheduler reducing learning rate to 0.0006635520572797897.
24/24 - 2s - loss: 0.0770 - val_loss: 0.1354
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07700348>, 'val_loss': 0.13539241254329681}
Epoch 497/4000

Epoch 00497: LearningRateScheduler reducing learning rate to 0.000660693448007596.
24/24 - 2s - loss: 0.0767 - val_loss: 0.1392
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07667526>, 'val_loss': 0.1392143964767456}
Epoch 498/4000

Epoch 00498: LearningRateScheduler reducing learning rate to 0.0006578471537405045.
24/24 - 2s - loss: 0.0780 - val_loss: 0.1380
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07798828>, 'val_loss': 0.1380062848329544}
Epoch 499/4000

Epoch 00499: LearningRateScheduler reducing learning rate to 0.0006550131214249723.
24/24 - 2s - loss: 0.0771 - val_loss: 0.1430
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07712799>, 'val_loss': 0.14298951625823975}
Epoch 500/4000

Epoch 00500: LearningRateScheduler reducing learning rate to 0.0006521912982360125.
24/24 - 2s - loss: 0.0777 - val_loss: 0.1414
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.077654324>, 'val_loss': 0.14136531949043274}
Model saved in ./model/scPDB_2021_pdbid--500--0.1414.
Epoch 501/4000

Epoch 00501: LearningRateScheduler reducing learning rate to 0.0006493816315762113.
24/24 - 2s - loss: 0.0763 - val_loss: 0.1362
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.076335065>, 'val_loss': 0.1362268477678299}
Epoch 502/4000

Epoch 00502: LearningRateScheduler reducing learning rate to 0.0006465840690747461.
24/24 - 2s - loss: 0.0774 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07741942>, 'val_loss': 0.13865076005458832}
Epoch 503/4000

Epoch 00503: LearningRateScheduler reducing learning rate to 0.00064379855858641.
24/24 - 2s - loss: 0.0763 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07627235>, 'val_loss': 0.13872171938419342}
Epoch 504/4000

Epoch 00504: LearningRateScheduler reducing learning rate to 0.0006410250481906399.
24/24 - 2s - loss: 0.0764 - val_loss: 0.1418
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07641045>, 'val_loss': 0.14179043471813202}
Epoch 505/4000

Epoch 00505: LearningRateScheduler reducing learning rate to 0.0006382634861905487.
24/24 - 2s - loss: 0.0767 - val_loss: 0.1362
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07672575>, 'val_loss': 0.13623671233654022}
Epoch 506/4000

Epoch 00506: LearningRateScheduler reducing learning rate to 0.0006355138211119613.
24/24 - 2s - loss: 0.0769 - val_loss: 0.1426
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07693864>, 'val_loss': 0.14263847470283508}
Epoch 507/4000

Epoch 00507: LearningRateScheduler reducing learning rate to 0.0006327760017024557.
24/24 - 2s - loss: 0.0770 - val_loss: 0.1421
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07697615>, 'val_loss': 0.14208276569843292}
Epoch 508/4000

Epoch 00508: LearningRateScheduler reducing learning rate to 0.0006300499769304075.
24/24 - 2s - loss: 0.0765 - val_loss: 0.1379
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07654015>, 'val_loss': 0.13794445991516113}
Epoch 509/4000

Epoch 00509: LearningRateScheduler reducing learning rate to 0.000627335695984038.
24/24 - 2s - loss: 0.0760 - val_loss: 0.1479
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0759526>, 'val_loss': 0.14785823225975037}
Epoch 510/4000

Epoch 00510: LearningRateScheduler reducing learning rate to 0.0006246331082704686.
24/24 - 2s - loss: 0.0760 - val_loss: 0.1392
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07604756>, 'val_loss': 0.1391923576593399}
Epoch 511/4000

Epoch 00511: LearningRateScheduler reducing learning rate to 0.0006219421634147762.
24/24 - 2s - loss: 0.0761 - val_loss: 0.1377
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07607565>, 'val_loss': 0.13772086799144745}
Epoch 512/4000

Epoch 00512: LearningRateScheduler reducing learning rate to 0.0006192628112590551.
24/24 - 2s - loss: 0.0761 - val_loss: 0.1346
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07606021>, 'val_loss': 0.13458769023418427}
Epoch 513/4000

Epoch 00513: LearningRateScheduler reducing learning rate to 0.000616595001861482.
24/24 - 2s - loss: 0.0772 - val_loss: 0.1410
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07717309>, 'val_loss': 0.14097736775875092}
Epoch 514/4000

Epoch 00514: LearningRateScheduler reducing learning rate to 0.0006139386854953852.
24/24 - 2s - loss: 0.0760 - val_loss: 0.1364
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07596353>, 'val_loss': 0.1363726407289505}
Epoch 515/4000

Epoch 00515: LearningRateScheduler reducing learning rate to 0.0006112938126483171.
24/24 - 2s - loss: 0.0755 - val_loss: 0.1407
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07546161>, 'val_loss': 0.14068503677845}
Epoch 516/4000

Epoch 00516: LearningRateScheduler reducing learning rate to 0.0006086603340211317.
24/24 - 2s - loss: 0.0760 - val_loss: 0.1395
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.076004185>, 'val_loss': 0.13949862122535706}
Epoch 517/4000

Epoch 00517: LearningRateScheduler reducing learning rate to 0.0006060382005270663.
24/24 - 2s - loss: 0.0766 - val_loss: 0.1428
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07663284>, 'val_loss': 0.14284129440784454}
Epoch 518/4000

Epoch 00518: LearningRateScheduler reducing learning rate to 0.0006034273632908255.
24/24 - 2s - loss: 0.0761 - val_loss: 0.1413
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0761379>, 'val_loss': 0.14132285118103027}
Epoch 519/4000

Epoch 00519: LearningRateScheduler reducing learning rate to 0.0006008277736476707.
24/24 - 2s - loss: 0.0763 - val_loss: 0.1375
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.076309755>, 'val_loss': 0.13752631843090057}
Epoch 520/4000

Epoch 00520: LearningRateScheduler reducing learning rate to 0.0005982393831425131.
24/24 - 2s - loss: 0.0747 - val_loss: 0.1426
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07470755>, 'val_loss': 0.14255253970623016}
Epoch 521/4000

Epoch 00521: LearningRateScheduler reducing learning rate to 0.0005956621435290103.
24/24 - 2s - loss: 0.0761 - val_loss: 0.1346
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.076091684>, 'val_loss': 0.13456442952156067}
Epoch 522/4000

Epoch 00522: LearningRateScheduler reducing learning rate to 0.0005930960067686675.
24/24 - 2s - loss: 0.0764 - val_loss: 0.1402
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07644847>, 'val_loss': 0.14023709297180176}
Epoch 523/4000

Epoch 00523: LearningRateScheduler reducing learning rate to 0.000590540925029941.
24/24 - 2s - loss: 0.0751 - val_loss: 0.1364
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07513829>, 'val_loss': 0.1364460587501526}
Epoch 524/4000

Epoch 00524: LearningRateScheduler reducing learning rate to 0.0005879968506873477.
24/24 - 2s - loss: 0.0756 - val_loss: 0.1486
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.075587936>, 'val_loss': 0.14857958257198334}
Epoch 525/4000

Epoch 00525: LearningRateScheduler reducing learning rate to 0.0005854637363205773.
24/24 - 2s - loss: 0.0754 - val_loss: 0.1372
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07543139>, 'val_loss': 0.1371982842683792}
Epoch 526/4000

Epoch 00526: LearningRateScheduler reducing learning rate to 0.0005829415347136073.
24/24 - 2s - loss: 0.0752 - val_loss: 0.1384
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07523789>, 'val_loss': 0.13836438953876495}
Epoch 527/4000

Epoch 00527: LearningRateScheduler reducing learning rate to 0.0005804301988538248.
24/24 - 2s - loss: 0.0751 - val_loss: 0.1486
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07511416>, 'val_loss': 0.1486247032880783}
Epoch 528/4000

Epoch 00528: LearningRateScheduler reducing learning rate to 0.0005779296819311486.
24/24 - 2s - loss: 0.0747 - val_loss: 0.1421
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07468837>, 'val_loss': 0.142068013548851}
Epoch 529/4000

Epoch 00529: LearningRateScheduler reducing learning rate to 0.000575439937337157.
24/24 - 2s - loss: 0.0757 - val_loss: 0.1381
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.075704664>, 'val_loss': 0.1381191611289978}
Epoch 530/4000

Epoch 00530: LearningRateScheduler reducing learning rate to 0.0005729609186642196.
24/24 - 2s - loss: 0.0754 - val_loss: 0.1460
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07543942>, 'val_loss': 0.14600250124931335}
Epoch 531/4000

Epoch 00531: LearningRateScheduler reducing learning rate to 0.000570492579704632.
24/24 - 2s - loss: 0.0754 - val_loss: 0.1383
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07541685>, 'val_loss': 0.13826537132263184}
Epoch 532/4000

Epoch 00532: LearningRateScheduler reducing learning rate to 0.0005680348744497543.
24/24 - 2s - loss: 0.0750 - val_loss: 0.1396
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.075021304>, 'val_loss': 0.13958759605884552}
Epoch 533/4000

Epoch 00533: LearningRateScheduler reducing learning rate to 0.0005655877570891538.
24/24 - 2s - loss: 0.0757 - val_loss: 0.1371
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.075740494>, 'val_loss': 0.1371089518070221}
Epoch 534/4000

Epoch 00534: LearningRateScheduler reducing learning rate to 0.0005631511820097513.
24/24 - 2s - loss: 0.0751 - val_loss: 0.1391
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.075053535>, 'val_loss': 0.13913875818252563}
Epoch 535/4000

Epoch 00535: LearningRateScheduler reducing learning rate to 0.0005607251037949697.
24/24 - 2s - loss: 0.0749 - val_loss: 0.1457
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07486516>, 'val_loss': 0.1456982046365738}
Epoch 536/4000

Epoch 00536: LearningRateScheduler reducing learning rate to 0.0005583094772238893.
24/24 - 2s - loss: 0.0750 - val_loss: 0.1410
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07497807>, 'val_loss': 0.1410120725631714}
Epoch 537/4000

Epoch 00537: LearningRateScheduler reducing learning rate to 0.0005559042572704036.
24/24 - 2s - loss: 0.0740 - val_loss: 0.1401
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07401934>, 'val_loss': 0.1401265412569046}
Epoch 538/4000

Epoch 00538: LearningRateScheduler reducing learning rate to 0.0005535093991023803.
24/24 - 2s - loss: 0.0746 - val_loss: 0.1392
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07456341>, 'val_loss': 0.13922785222530365}
Epoch 539/4000

Epoch 00539: LearningRateScheduler reducing learning rate to 0.000551124858080826.
24/24 - 2s - loss: 0.0745 - val_loss: 0.1441
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07449358>, 'val_loss': 0.14410161972045898}
Epoch 540/4000

Epoch 00540: LearningRateScheduler reducing learning rate to 0.0005487505897590534.
24/24 - 2s - loss: 0.0740 - val_loss: 0.1425
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07403735>, 'val_loss': 0.14248977601528168}
Epoch 541/4000

Epoch 00541: LearningRateScheduler reducing learning rate to 0.0005463865498818542.
24/24 - 2s - loss: 0.0748 - val_loss: 0.1458
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07477439>, 'val_loss': 0.14578916132450104}
Epoch 542/4000

Epoch 00542: LearningRateScheduler reducing learning rate to 0.0005440326943846725.
24/24 - 2s - loss: 0.0744 - val_loss: 0.1430
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074420355>, 'val_loss': 0.14298538863658905}
Epoch 543/4000

Epoch 00543: LearningRateScheduler reducing learning rate to 0.0005416889793927849.
24/24 - 2s - loss: 0.0744 - val_loss: 0.1456
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07435048>, 'val_loss': 0.14562512934207916}
Epoch 544/4000

Epoch 00544: LearningRateScheduler reducing learning rate to 0.0005393553612204814.
24/24 - 2s - loss: 0.0743 - val_loss: 0.1406
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074274495>, 'val_loss': 0.14058512449264526}
Epoch 545/4000

Epoch 00545: LearningRateScheduler reducing learning rate to 0.0005370317963702527.
24/24 - 2s - loss: 0.0747 - val_loss: 0.1387
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07465947>, 'val_loss': 0.13865415751934052}
Epoch 546/4000

Epoch 00546: LearningRateScheduler reducing learning rate to 0.0005347182415319779.
24/24 - 2s - loss: 0.0746 - val_loss: 0.1447
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07458606>, 'val_loss': 0.1447029709815979}
Epoch 547/4000

Epoch 00547: LearningRateScheduler reducing learning rate to 0.0005324146535821179.
24/24 - 2s - loss: 0.0740 - val_loss: 0.1389
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07402059>, 'val_loss': 0.1388782113790512}
Epoch 548/4000

Epoch 00548: LearningRateScheduler reducing learning rate to 0.0005301209895829121.
24/24 - 2s - loss: 0.0744 - val_loss: 0.1434
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07437596>, 'val_loss': 0.14343883097171783}
Epoch 549/4000

Epoch 00549: LearningRateScheduler reducing learning rate to 0.0005278372067815767.
24/24 - 2s - loss: 0.0740 - val_loss: 0.1446
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07401759>, 'val_loss': 0.1445566862821579}
Epoch 550/4000

Epoch 00550: LearningRateScheduler reducing learning rate to 0.0005255632626095095.
24/24 - 2s - loss: 0.0740 - val_loss: 0.1455
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07400755>, 'val_loss': 0.14549846947193146}
Model saved in ./model/scPDB_2021_pdbid--550--0.1455.
Epoch 551/4000

Epoch 00551: LearningRateScheduler reducing learning rate to 0.0005232991146814946.
24/24 - 2s - loss: 0.0742 - val_loss: 0.1454
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074228235>, 'val_loss': 0.1453767716884613}
Epoch 552/4000

Epoch 00552: LearningRateScheduler reducing learning rate to 0.0005210447207949143.
24/24 - 2s - loss: 0.0742 - val_loss: 0.1434
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074179284>, 'val_loss': 0.14340496063232422}
Epoch 553/4000

Epoch 00553: LearningRateScheduler reducing learning rate to 0.0005188000389289611.
24/24 - 2s - loss: 0.0741 - val_loss: 0.1410
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074054204>, 'val_loss': 0.1410072296857834}
Epoch 554/4000

Epoch 00554: LearningRateScheduler reducing learning rate to 0.0005165650272438546.
24/24 - 2s - loss: 0.0729 - val_loss: 0.1445
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07294393>, 'val_loss': 0.1445089876651764}
Epoch 555/4000

Epoch 00555: LearningRateScheduler reducing learning rate to 0.000514339644080062.
24/24 - 2s - loss: 0.0733 - val_loss: 0.1440
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07327852>, 'val_loss': 0.1440391093492508}
Epoch 556/4000

Epoch 00556: LearningRateScheduler reducing learning rate to 0.000512123847957522.
24/24 - 2s - loss: 0.0742 - val_loss: 0.1444
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07416088>, 'val_loss': 0.14444811642169952}
Epoch 557/4000

Epoch 00557: LearningRateScheduler reducing learning rate to 0.0005099175975748702.
24/24 - 2s - loss: 0.0737 - val_loss: 0.1396
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07368881>, 'val_loss': 0.1396464854478836}
Epoch 558/4000

Epoch 00558: LearningRateScheduler reducing learning rate to 0.0005077208518086707.
24/24 - 2s - loss: 0.0736 - val_loss: 0.1470
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07355411>, 'val_loss': 0.14702242612838745}
Epoch 559/4000

Epoch 00559: LearningRateScheduler reducing learning rate to 0.0005055335697126491.
24/24 - 3s - loss: 0.0743 - val_loss: 0.1432
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07433718>, 'val_loss': 0.14315296709537506}
Epoch 560/4000

Epoch 00560: LearningRateScheduler reducing learning rate to 0.000503355710516929.
24/24 - 2s - loss: 0.0731 - val_loss: 0.1358
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07306917>, 'val_loss': 0.1357862949371338}
Epoch 561/4000

Epoch 00561: LearningRateScheduler reducing learning rate to 0.0005011872336272722.
24/24 - 2s - loss: 0.0737 - val_loss: 0.1488
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07373411>, 'val_loss': 0.1488076001405716}
Epoch 562/4000

Epoch 00562: LearningRateScheduler reducing learning rate to 0.0004990280986243227.
24/24 - 2s - loss: 0.0731 - val_loss: 0.1408
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07312817>, 'val_loss': 0.14075487852096558}
Epoch 563/4000

Epoch 00563: LearningRateScheduler reducing learning rate to 0.0004968782652628517.
24/24 - 2s - loss: 0.0738 - val_loss: 0.1437
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.073754795>, 'val_loss': 0.14366373419761658}
Epoch 564/4000

Epoch 00564: LearningRateScheduler reducing learning rate to 0.0004947376934710095.
24/24 - 2s - loss: 0.0743 - val_loss: 0.1451
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.074335925>, 'val_loss': 0.14511507749557495}
Epoch 565/4000

Epoch 00565: LearningRateScheduler reducing learning rate to 0.0004926063433495772.
24/24 - 2s - loss: 0.0729 - val_loss: 0.1419
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07292123>, 'val_loss': 0.14193351566791534}
Epoch 566/4000

Epoch 00566: LearningRateScheduler reducing learning rate to 0.0004904841751712231.
24/24 - 2s - loss: 0.0734 - val_loss: 0.1430
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07335343>, 'val_loss': 0.14304028451442719}
Epoch 567/4000

Epoch 00567: LearningRateScheduler reducing learning rate to 0.0004883711493797627.
24/24 - 2s - loss: 0.0732 - val_loss: 0.1476
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07324716>, 'val_loss': 0.1476224809885025}
Epoch 568/4000

Epoch 00568: LearningRateScheduler reducing learning rate to 0.0004862672265894213.
24/24 - 2s - loss: 0.0733 - val_loss: 0.1429
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07330905>, 'val_loss': 0.1428930163383484}
Epoch 569/4000

Epoch 00569: LearningRateScheduler reducing learning rate to 0.00048417236758409933.
24/24 - 2s - loss: 0.0725 - val_loss: 0.1395
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07250296>, 'val_loss': 0.1394670605659485}
Epoch 570/4000

Epoch 00570: LearningRateScheduler reducing learning rate to 0.0004820865333166421.
24/24 - 2s - loss: 0.0738 - val_loss: 0.1458
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07384639>, 'val_loss': 0.1457533985376358}
Epoch 571/4000

Epoch 00571: LearningRateScheduler reducing learning rate to 0.00048000968490811155.
24/24 - 2s - loss: 0.0724 - val_loss: 0.1518
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07237704>, 'val_loss': 0.15182779729366302}
Epoch 572/4000

Epoch 00572: LearningRateScheduler reducing learning rate to 0.00047794178364706164.
24/24 - 2s - loss: 0.0739 - val_loss: 0.1365
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07389499>, 'val_loss': 0.13646014034748077}
Epoch 573/4000

Epoch 00573: LearningRateScheduler reducing learning rate to 0.0004758827909888169.
24/24 - 2s - loss: 0.0726 - val_loss: 0.1454
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0726454>, 'val_loss': 0.14535270631313324}
Epoch 574/4000

Epoch 00574: LearningRateScheduler reducing learning rate to 0.0004738326685547537.
24/24 - 2s - loss: 0.0726 - val_loss: 0.1466
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07256196>, 'val_loss': 0.14661331474781036}
Epoch 575/4000

Epoch 00575: LearningRateScheduler reducing learning rate to 0.00047179137813158523.
24/24 - 2s - loss: 0.0729 - val_loss: 0.1471
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07290395>, 'val_loss': 0.14711040258407593}
Epoch 576/4000

Epoch 00576: LearningRateScheduler reducing learning rate to 0.00046975888167064917.
24/24 - 2s - loss: 0.0729 - val_loss: 0.1453
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07294236>, 'val_loss': 0.14529791474342346}
Epoch 577/4000

Epoch 00577: LearningRateScheduler reducing learning rate to 0.0004677351412871982.
24/24 - 2s - loss: 0.0721 - val_loss: 0.1419
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.072118245>, 'val_loss': 0.14193348586559296}
Epoch 578/4000

Epoch 00578: LearningRateScheduler reducing learning rate to 0.00046572011925969406.
24/24 - 2s - loss: 0.0739 - val_loss: 0.1434
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07391202>, 'val_loss': 0.14338819682598114}
Epoch 579/4000

Epoch 00579: LearningRateScheduler reducing learning rate to 0.0004637137780291045.
24/24 - 2s - loss: 0.0717 - val_loss: 0.1461
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07166011>, 'val_loss': 0.1460808515548706}
Epoch 580/4000

Epoch 00580: LearningRateScheduler reducing learning rate to 0.00046171608019820315.
24/24 - 2s - loss: 0.0733 - val_loss: 0.1427
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.073312506>, 'val_loss': 0.1427202969789505}
Epoch 581/4000

Epoch 00581: LearningRateScheduler reducing learning rate to 0.00045972698853087216.
24/24 - 2s - loss: 0.0728 - val_loss: 0.1503
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07275649>, 'val_loss': 0.15025146305561066}
Epoch 582/4000

Epoch 00582: LearningRateScheduler reducing learning rate to 0.0004577464659514087.
24/24 - 2s - loss: 0.0726 - val_loss: 0.1414
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07258732>, 'val_loss': 0.14144743978977203}
Epoch 583/4000

Epoch 00583: LearningRateScheduler reducing learning rate to 0.00045577447554383336.
24/24 - 2s - loss: 0.0723 - val_loss: 0.1464
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07231667>, 'val_loss': 0.14636220037937164}
Epoch 584/4000

Epoch 00584: LearningRateScheduler reducing learning rate to 0.0004538109805512023.
24/24 - 2s - loss: 0.0726 - val_loss: 0.1518
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07262767>, 'val_loss': 0.15179194509983063}
Epoch 585/4000

Epoch 00585: LearningRateScheduler reducing learning rate to 0.0004518559443749223.
24/24 - 2s - loss: 0.0724 - val_loss: 0.1404
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07236713>, 'val_loss': 0.14043541252613068}
Epoch 586/4000

Epoch 00586: LearningRateScheduler reducing learning rate to 0.0004499093305740682.
24/24 - 2s - loss: 0.0730 - val_loss: 0.1445
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.072969355>, 'val_loss': 0.1445431411266327}
Epoch 587/4000

Epoch 00587: LearningRateScheduler reducing learning rate to 0.0004479711028647036.
24/24 - 2s - loss: 0.0721 - val_loss: 0.1456
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07210811>, 'val_loss': 0.14559848606586456}
Epoch 588/4000

Epoch 00588: LearningRateScheduler reducing learning rate to 0.0004460412251192052.
24/24 - 2s - loss: 0.0723 - val_loss: 0.1497
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07230548>, 'val_loss': 0.14966259896755219}
Epoch 589/4000

Epoch 00589: LearningRateScheduler reducing learning rate to 0.0004441196613655889.
24/24 - 2s - loss: 0.0719 - val_loss: 0.1476
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07191659>, 'val_loss': 0.14760679006576538}
Epoch 590/4000

Epoch 00590: LearningRateScheduler reducing learning rate to 0.00044220637578683904.
24/24 - 3s - loss: 0.0725 - val_loss: 0.1496
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.072499745>, 'val_loss': 0.1495777666568756}
Epoch 591/4000

Epoch 00591: LearningRateScheduler reducing learning rate to 0.0004403013327202414.
24/24 - 2s - loss: 0.0711 - val_loss: 0.1473
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07114713>, 'val_loss': 0.1472882777452469}
Epoch 592/4000

Epoch 00592: LearningRateScheduler reducing learning rate to 0.0004384044966567182.
24/24 - 2s - loss: 0.0729 - val_loss: 0.1554
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.072853856>, 'val_loss': 0.1554153561592102}
Epoch 593/4000

Epoch 00593: LearningRateScheduler reducing learning rate to 0.00043651583224016595.
24/24 - 2s - loss: 0.0720 - val_loss: 0.1422
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071985096>, 'val_loss': 0.1422228366136551}
Epoch 594/4000

Epoch 00594: LearningRateScheduler reducing learning rate to 0.00043463530426679704.
24/24 - 2s - loss: 0.0719 - val_loss: 0.1466
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07194705>, 'val_loss': 0.1465718299150467}
Epoch 595/4000

Epoch 00595: LearningRateScheduler reducing learning rate to 0.00043276287768448304.
24/24 - 2s - loss: 0.0710 - val_loss: 0.1487
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07100503>, 'val_loss': 0.1487429291009903}
Epoch 596/4000

Epoch 00596: LearningRateScheduler reducing learning rate to 0.0004308985175921015.
24/24 - 2s - loss: 0.0728 - val_loss: 0.1465
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.072750114>, 'val_loss': 0.14653976261615753}
Epoch 597/4000

Epoch 00597: LearningRateScheduler reducing learning rate to 0.00042904218923888544.
24/24 - 2s - loss: 0.0716 - val_loss: 0.1523
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0715582>, 'val_loss': 0.15230947732925415}
Epoch 598/4000

Epoch 00598: LearningRateScheduler reducing learning rate to 0.0004271938580237756.
24/24 - 2s - loss: 0.0721 - val_loss: 0.1501
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07206309>, 'val_loss': 0.1500510573387146}
Epoch 599/4000

Epoch 00599: LearningRateScheduler reducing learning rate to 0.0004253534894947755.
24/24 - 2s - loss: 0.0715 - val_loss: 0.1415
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07147803>, 'val_loss': 0.14148053526878357}
Epoch 600/4000

Epoch 00600: LearningRateScheduler reducing learning rate to 0.00042352104934830924.
24/24 - 2s - loss: 0.0723 - val_loss: 0.1501
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07225032>, 'val_loss': 0.1501275897026062}
Model saved in ./model/scPDB_2021_pdbid--600--0.1501.
Epoch 601/4000

Epoch 00601: LearningRateScheduler reducing learning rate to 0.00042169650342858224.
24/24 - 2s - loss: 0.0711 - val_loss: 0.1435
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071112126>, 'val_loss': 0.14352299273014069}
Epoch 602/4000

Epoch 00602: LearningRateScheduler reducing learning rate to 0.00041987981772694427.
24/24 - 2s - loss: 0.0718 - val_loss: 0.1512
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07179261>, 'val_loss': 0.1512066125869751}
Epoch 603/4000

Epoch 00603: LearningRateScheduler reducing learning rate to 0.00041807095838125596.
24/24 - 2s - loss: 0.0715 - val_loss: 0.1458
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071530245>, 'val_loss': 0.14579468965530396}
Epoch 604/4000

Epoch 00604: LearningRateScheduler reducing learning rate to 0.00041626989167525727.
24/24 - 2s - loss: 0.0718 - val_loss: 0.1490
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071763694>, 'val_loss': 0.1490442007780075}
Epoch 605/4000

Epoch 00605: LearningRateScheduler reducing learning rate to 0.00041447658403793915.
24/24 - 2s - loss: 0.0716 - val_loss: 0.1500
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07162862>, 'val_loss': 0.1499861478805542}
Epoch 606/4000

Epoch 00606: LearningRateScheduler reducing learning rate to 0.00041269100204291794.
24/24 - 2s - loss: 0.0714 - val_loss: 0.1474
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07138508>, 'val_loss': 0.1474108248949051}
Epoch 607/4000

Epoch 00607: LearningRateScheduler reducing learning rate to 0.0004109131124078122.
24/24 - 2s - loss: 0.0716 - val_loss: 0.1507
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07157982>, 'val_loss': 0.15068314969539642}
Epoch 608/4000

Epoch 00608: LearningRateScheduler reducing learning rate to 0.00040914288199362227.
24/24 - 2s - loss: 0.0711 - val_loss: 0.1456
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07111231>, 'val_loss': 0.14555643498897552}
Epoch 609/4000

Epoch 00609: LearningRateScheduler reducing learning rate to 0.00040738027780411277.
24/24 - 2s - loss: 0.0718 - val_loss: 0.1491
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071844526>, 'val_loss': 0.14909331500530243}
Epoch 610/4000

Epoch 00610: LearningRateScheduler reducing learning rate to 0.00040562526698519714.
24/24 - 2s - loss: 0.0709 - val_loss: 0.1464
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07087465>, 'val_loss': 0.14636419713497162}
Epoch 611/4000

Epoch 00611: LearningRateScheduler reducing learning rate to 0.00040387781682432603.
24/24 - 2s - loss: 0.0706 - val_loss: 0.1478
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070597716>, 'val_loss': 0.14783167839050293}
Epoch 612/4000

Epoch 00612: LearningRateScheduler reducing learning rate to 0.0004021378947498766.
24/24 - 2s - loss: 0.0712 - val_loss: 0.1476
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07118336>, 'val_loss': 0.14758364856243134}
Epoch 613/4000

Epoch 00613: LearningRateScheduler reducing learning rate to 0.0004004054683305463.
24/24 - 2s - loss: 0.0719 - val_loss: 0.1444
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071905635>, 'val_loss': 0.1443859338760376}
Epoch 614/4000

Epoch 00614: LearningRateScheduler reducing learning rate to 0.00039868050527474777.
24/24 - 2s - loss: 0.0716 - val_loss: 0.1538
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071640916>, 'val_loss': 0.15376016497612}
Epoch 615/4000

Epoch 00615: LearningRateScheduler reducing learning rate to 0.00039696297343000696.
24/24 - 2s - loss: 0.0707 - val_loss: 0.1491
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07069449>, 'val_loss': 0.14910516142845154}
Epoch 616/4000

Epoch 00616: LearningRateScheduler reducing learning rate to 0.00039525284078236427.
24/24 - 2s - loss: 0.0716 - val_loss: 0.1515
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07158496>, 'val_loss': 0.15153782069683075}
Epoch 617/4000

Epoch 00617: LearningRateScheduler reducing learning rate to 0.0003935500754557775.
24/24 - 2s - loss: 0.0702 - val_loss: 0.1451
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07024143>, 'val_loss': 0.14513450860977173}
Epoch 618/4000

Epoch 00618: LearningRateScheduler reducing learning rate to 0.0003918546457115274.
24/24 - 2s - loss: 0.0711 - val_loss: 0.1499
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071079135>, 'val_loss': 0.14994792640209198}
Epoch 619/4000

Epoch 00619: LearningRateScheduler reducing learning rate to 0.00039016651994762695.
24/24 - 2s - loss: 0.0715 - val_loss: 0.1550
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071540296>, 'val_loss': 0.1549925059080124}
Epoch 620/4000

Epoch 00620: LearningRateScheduler reducing learning rate to 0.0003884856666982314.
24/24 - 2s - loss: 0.0705 - val_loss: 0.1415
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07047402>, 'val_loss': 0.14149470627307892}
Epoch 621/4000

Epoch 00621: LearningRateScheduler reducing learning rate to 0.00038681205463305215.
24/24 - 2s - loss: 0.0706 - val_loss: 0.1479
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07064185>, 'val_loss': 0.14791227877140045}
Epoch 622/4000

Epoch 00622: LearningRateScheduler reducing learning rate to 0.000385145652556773.
24/24 - 2s - loss: 0.0720 - val_loss: 0.1455
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07200739>, 'val_loss': 0.1455359309911728}
Epoch 623/4000

Epoch 00623: LearningRateScheduler reducing learning rate to 0.0003834864294084682.
24/24 - 2s - loss: 0.0694 - val_loss: 0.1506
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06944546>, 'val_loss': 0.15062926709651947}
Epoch 624/4000

Epoch 00624: LearningRateScheduler reducing learning rate to 0.00038183435426102373.
24/24 - 2s - loss: 0.0707 - val_loss: 0.1529
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07074787>, 'val_loss': 0.1529129296541214}
Epoch 625/4000

Epoch 00625: LearningRateScheduler reducing learning rate to 0.00038018939632056113.
24/24 - 2s - loss: 0.0713 - val_loss: 0.1492
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071338356>, 'val_loss': 0.14919663965702057}
Epoch 626/4000

Epoch 00626: LearningRateScheduler reducing learning rate to 0.00037855152492586295.
24/24 - 2s - loss: 0.0703 - val_loss: 0.1488
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07027572>, 'val_loss': 0.14883752167224884}
Epoch 627/4000

Epoch 00627: LearningRateScheduler reducing learning rate to 0.0003769207095478016.
24/24 - 2s - loss: 0.0711 - val_loss: 0.1462
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.071144484>, 'val_loss': 0.1461540013551712}
Epoch 628/4000

Epoch 00628: LearningRateScheduler reducing learning rate to 0.0003752969197887701.
24/24 - 2s - loss: 0.0701 - val_loss: 0.1504
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07007371>, 'val_loss': 0.15035699307918549}
Epoch 629/4000

Epoch 00629: LearningRateScheduler reducing learning rate to 0.00037368012538211575.
24/24 - 2s - loss: 0.0709 - val_loss: 0.1517
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0709291>, 'val_loss': 0.1517060548067093}
Epoch 630/4000

Epoch 00630: LearningRateScheduler reducing learning rate to 0.0003720702961915758.
24/24 - 2s - loss: 0.0707 - val_loss: 0.1539
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07072648>, 'val_loss': 0.15391133725643158}
Epoch 631/4000

Epoch 00631: LearningRateScheduler reducing learning rate to 0.00037046740221071566.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1521
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06995027>, 'val_loss': 0.15214323997497559}
Epoch 632/4000

Epoch 00632: LearningRateScheduler reducing learning rate to 0.0003688714135623698.
24/24 - 2s - loss: 0.0701 - val_loss: 0.1460
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07007984>, 'val_loss': 0.1460004448890686}
Epoch 633/4000

Epoch 00633: LearningRateScheduler reducing learning rate to 0.00036728230049808467.
24/24 - 2s - loss: 0.0712 - val_loss: 0.1513
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07121079>, 'val_loss': 0.15126465260982513}
Epoch 634/4000

Epoch 00634: LearningRateScheduler reducing learning rate to 0.00036570003339756417.
24/24 - 2s - loss: 0.0701 - val_loss: 0.1500
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07012134>, 'val_loss': 0.14996862411499023}
Epoch 635/4000

Epoch 00635: LearningRateScheduler reducing learning rate to 0.0003641245827681179.
24/24 - 2s - loss: 0.0707 - val_loss: 0.1498
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070717975>, 'val_loss': 0.14976470172405243}
Epoch 636/4000

Epoch 00636: LearningRateScheduler reducing learning rate to 0.00036255591924411087.
24/24 - 2s - loss: 0.0701 - val_loss: 0.1511
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0700547>, 'val_loss': 0.1511409729719162}
Epoch 637/4000

Epoch 00637: LearningRateScheduler reducing learning rate to 0.0003609940135864166.
24/24 - 2s - loss: 0.0703 - val_loss: 0.1503
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070338674>, 'val_loss': 0.15032801032066345}
Epoch 638/4000

Epoch 00638: LearningRateScheduler reducing learning rate to 0.00035943883668187207.
24/24 - 2s - loss: 0.0701 - val_loss: 0.1456
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07011495>, 'val_loss': 0.14564865827560425}
Epoch 639/4000

Epoch 00639: LearningRateScheduler reducing learning rate to 0.0003578903595427346.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1549
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07000505>, 'val_loss': 0.15488682687282562}
Epoch 640/4000

Epoch 00640: LearningRateScheduler reducing learning rate to 0.0003563485533061423.
24/24 - 2s - loss: 0.0704 - val_loss: 0.1567
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07041771>, 'val_loss': 0.15667229890823364}
Epoch 641/4000

Epoch 00641: LearningRateScheduler reducing learning rate to 0.00035481338923357543.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1446
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07003512>, 'val_loss': 0.14463898539543152}
Epoch 642/4000

Epoch 00642: LearningRateScheduler reducing learning rate to 0.00035328483871032096.
24/24 - 2s - loss: 0.0706 - val_loss: 0.1547
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07062026>, 'val_loss': 0.154668927192688}
Epoch 643/4000

Epoch 00643: LearningRateScheduler reducing learning rate to 0.0003517628732449393.
24/24 - 2s - loss: 0.0697 - val_loss: 0.1517
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06965896>, 'val_loss': 0.15167412161827087}
Epoch 644/4000

Epoch 00644: LearningRateScheduler reducing learning rate to 0.00035024746446873304.
24/24 - 2s - loss: 0.0708 - val_loss: 0.1480
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070832424>, 'val_loss': 0.14800941944122314}
Epoch 645/4000

Epoch 00645: LearningRateScheduler reducing learning rate to 0.00034873858413521835.
24/24 - 2s - loss: 0.0697 - val_loss: 0.1534
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069735445>, 'val_loss': 0.15339338779449463}
Epoch 646/4000

Epoch 00646: LearningRateScheduler reducing learning rate to 0.00034723620411959846.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1537
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07003459>, 'val_loss': 0.15367545187473297}
Epoch 647/4000

Epoch 00647: LearningRateScheduler reducing learning rate to 0.0003457402964182391.
24/24 - 2s - loss: 0.0693 - val_loss: 0.1409
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06931734>, 'val_loss': 0.14085283875465393}
Epoch 648/4000

Epoch 00648: LearningRateScheduler reducing learning rate to 0.0003442508331481472.
24/24 - 2s - loss: 0.0699 - val_loss: 0.1567
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0699157>, 'val_loss': 0.1566525250673294}
Epoch 649/4000

Epoch 00649: LearningRateScheduler reducing learning rate to 0.0003427677865464504.
24/24 - 2s - loss: 0.0703 - val_loss: 0.1551
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07033833>, 'val_loss': 0.1550534963607788}
Epoch 650/4000

Epoch 00650: LearningRateScheduler reducing learning rate to 0.00034129112896988005.
24/24 - 2s - loss: 0.0697 - val_loss: 0.1439
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06974935>, 'val_loss': 0.14388760924339294}
Model saved in ./model/scPDB_2021_pdbid--650--0.1439.
Epoch 651/4000

Epoch 00651: LearningRateScheduler reducing learning rate to 0.00033982083289425585.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1574
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.07004615>, 'val_loss': 0.15743251144886017}
Epoch 652/4000

Epoch 00652: LearningRateScheduler reducing learning rate to 0.00033835687091397294.
24/24 - 2s - loss: 0.0694 - val_loss: 0.1463
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069387205>, 'val_loss': 0.14633850753307343}
Epoch 653/4000

Epoch 00653: LearningRateScheduler reducing learning rate to 0.0003368992157414907.
24/24 - 2s - loss: 0.0704 - val_loss: 0.1533
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070380695>, 'val_loss': 0.1533188670873642}
Epoch 654/4000

Epoch 00654: LearningRateScheduler reducing learning rate to 0.0003354478402068243.
24/24 - 2s - loss: 0.0696 - val_loss: 0.1484
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06958442>, 'val_loss': 0.14838643372058868}
Epoch 655/4000

Epoch 00655: LearningRateScheduler reducing learning rate to 0.0003340027172570385.
24/24 - 2s - loss: 0.0698 - val_loss: 0.1491
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06976277>, 'val_loss': 0.14914797246456146}
Epoch 656/4000

Epoch 00656: LearningRateScheduler reducing learning rate to 0.00033256381995574314.
24/24 - 2s - loss: 0.0692 - val_loss: 0.1600
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06920051>, 'val_loss': 0.15996405482292175}
Epoch 657/4000

Epoch 00657: LearningRateScheduler reducing learning rate to 0.00033113112148259105.
24/24 - 2s - loss: 0.0696 - val_loss: 0.1513
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06955301>, 'val_loss': 0.15130053460597992}
Epoch 658/4000

Epoch 00658: LearningRateScheduler reducing learning rate to 0.00032970459513277834.
24/24 - 2s - loss: 0.0700 - val_loss: 0.1554
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06998258>, 'val_loss': 0.15537764132022858}
Epoch 659/4000

Epoch 00659: LearningRateScheduler reducing learning rate to 0.0003282842143165464.
24/24 - 2s - loss: 0.0695 - val_loss: 0.1551
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06947992>, 'val_loss': 0.15513847768306732}
Epoch 660/4000

Epoch 00660: LearningRateScheduler reducing learning rate to 0.0003268699525586865.
24/24 - 2s - loss: 0.0696 - val_loss: 0.1579
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06957876>, 'val_loss': 0.1579480916261673}
Epoch 661/4000

Epoch 00661: LearningRateScheduler reducing learning rate to 0.0003254617834980459.
24/24 - 2s - loss: 0.0688 - val_loss: 0.1540
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068840645>, 'val_loss': 0.1539653092622757}
Epoch 662/4000

Epoch 00662: LearningRateScheduler reducing learning rate to 0.00032405968088703715.
24/24 - 2s - loss: 0.0699 - val_loss: 0.1573
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06989566>, 'val_loss': 0.15732762217521667}
Epoch 663/4000

Epoch 00663: LearningRateScheduler reducing learning rate to 0.0003226636185911482.
24/24 - 2s - loss: 0.0698 - val_loss: 0.1496
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069757365>, 'val_loss': 0.14959301054477692}
Epoch 664/4000

Epoch 00664: LearningRateScheduler reducing learning rate to 0.0003212735705884557.
24/24 - 2s - loss: 0.0693 - val_loss: 0.1485
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069325864>, 'val_loss': 0.1485266089439392}
Epoch 665/4000

Epoch 00665: LearningRateScheduler reducing learning rate to 0.0003198895109691398.
24/24 - 2s - loss: 0.0695 - val_loss: 0.1591
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06953233>, 'val_loss': 0.1590881645679474}
Epoch 666/4000

Epoch 00666: LearningRateScheduler reducing learning rate to 0.000318511413935001.
24/24 - 2s - loss: 0.0702 - val_loss: 0.1556
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.070178345>, 'val_loss': 0.15559951961040497}
Epoch 667/4000

Epoch 00667: LearningRateScheduler reducing learning rate to 0.00031713925379897996.
24/24 - 2s - loss: 0.0699 - val_loss: 0.1538
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06987822>, 'val_loss': 0.15379929542541504}
Epoch 668/4000

Epoch 00668: LearningRateScheduler reducing learning rate to 0.0003157730049846776.
24/24 - 2s - loss: 0.0695 - val_loss: 0.1473
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0694569>, 'val_loss': 0.1472967267036438}
Epoch 669/4000

Epoch 00669: LearningRateScheduler reducing learning rate to 0.00031441264202587953.
24/24 - 2s - loss: 0.0687 - val_loss: 0.1514
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06867751>, 'val_loss': 0.1513785570859909}
Epoch 670/4000

Epoch 00670: LearningRateScheduler reducing learning rate to 0.0003130581395660806.
24/24 - 2s - loss: 0.0694 - val_loss: 0.1555
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069448546>, 'val_loss': 0.15551288425922394}
Epoch 671/4000

Epoch 00671: LearningRateScheduler reducing learning rate to 0.00031170947235801253.
24/24 - 2s - loss: 0.0689 - val_loss: 0.1594
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068925895>, 'val_loss': 0.15936905145645142}
Epoch 672/4000

Epoch 00672: LearningRateScheduler reducing learning rate to 0.0003103666152631735.
24/24 - 2s - loss: 0.0689 - val_loss: 0.1502
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06886524>, 'val_loss': 0.15021051466464996}
Epoch 673/4000

Epoch 00673: LearningRateScheduler reducing learning rate to 0.00030902954325135904.
24/24 - 2s - loss: 0.0694 - val_loss: 0.1554
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06937357>, 'val_loss': 0.15538769960403442}
Epoch 674/4000

Epoch 00674: LearningRateScheduler reducing learning rate to 0.0003076982314001961.
24/24 - 2s - loss: 0.0689 - val_loss: 0.1553
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068932705>, 'val_loss': 0.15531538426876068}
Epoch 675/4000

Epoch 00675: LearningRateScheduler reducing learning rate to 0.00030637265489467816.
24/24 - 2s - loss: 0.0695 - val_loss: 0.1544
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069490805>, 'val_loss': 0.15437793731689453}
Epoch 676/4000

Epoch 00676: LearningRateScheduler reducing learning rate to 0.00030505278902670253.
24/24 - 2s - loss: 0.0691 - val_loss: 0.1564
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06907905>, 'val_loss': 0.15644322335720062}
Epoch 677/4000

Epoch 00677: LearningRateScheduler reducing learning rate to 0.00030373860919461046.
24/24 - 2s - loss: 0.0696 - val_loss: 0.1536
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06964354>, 'val_loss': 0.15362775325775146}
Epoch 678/4000

Epoch 00678: LearningRateScheduler reducing learning rate to 0.00030243009090272785.
24/24 - 2s - loss: 0.0687 - val_loss: 0.1509
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06874658>, 'val_loss': 0.15085701644420624}
Epoch 679/4000

Epoch 00679: LearningRateScheduler reducing learning rate to 0.00030112720976090894.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1515
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06859801>, 'val_loss': 0.15150998532772064}
Epoch 680/4000

Epoch 00680: LearningRateScheduler reducing learning rate to 0.00029982994148408193.
24/24 - 2s - loss: 0.0691 - val_loss: 0.1566
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06906254>, 'val_loss': 0.1566201150417328}
Epoch 681/4000

Epoch 00681: LearningRateScheduler reducing learning rate to 0.00029853826189179595.
24/24 - 2s - loss: 0.0690 - val_loss: 0.1527
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06898955>, 'val_loss': 0.15272124111652374}
Epoch 682/4000

Epoch 00682: LearningRateScheduler reducing learning rate to 0.0002972521469077704.
24/24 - 2s - loss: 0.0693 - val_loss: 0.1561
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069282174>, 'val_loss': 0.15614397823810577}
Epoch 683/4000

Epoch 00683: LearningRateScheduler reducing learning rate to 0.0002959715725594465.
24/24 - 2s - loss: 0.0687 - val_loss: 0.1563
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068656005>, 'val_loss': 0.15625010430812836}
Epoch 684/4000

Epoch 00684: LearningRateScheduler reducing learning rate to 0.0002946965149775401.
24/24 - 2s - loss: 0.0692 - val_loss: 0.1504
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06917817>, 'val_loss': 0.15044596791267395}
Epoch 685/4000

Epoch 00685: LearningRateScheduler reducing learning rate to 0.00029342695039559686.
24/24 - 2s - loss: 0.0687 - val_loss: 0.1540
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06868983>, 'val_loss': 0.15398208796977997}
Epoch 686/4000

Epoch 00686: LearningRateScheduler reducing learning rate to 0.0002921628551495494.
24/24 - 2s - loss: 0.0688 - val_loss: 0.1529
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06877251>, 'val_loss': 0.15288567543029785}
Epoch 687/4000

Epoch 00687: LearningRateScheduler reducing learning rate to 0.000290904205677276.
24/24 - 2s - loss: 0.0691 - val_loss: 0.1523
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069078274>, 'val_loss': 0.1523277312517166}
Epoch 688/4000

Epoch 00688: LearningRateScheduler reducing learning rate to 0.0002896509785181617.
24/24 - 2s - loss: 0.0682 - val_loss: 0.1534
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06824227>, 'val_loss': 0.15339623391628265}
Epoch 689/4000

Epoch 00689: LearningRateScheduler reducing learning rate to 0.00028840315031266055.
24/24 - 2s - loss: 0.0682 - val_loss: 0.1529
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068233356>, 'val_loss': 0.15294423699378967}
Epoch 690/4000

Epoch 00690: LearningRateScheduler reducing learning rate to 0.00028716069780186074.
24/24 - 2s - loss: 0.0687 - val_loss: 0.1565
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06867621>, 'val_loss': 0.15646903216838837}
Epoch 691/4000

Epoch 00691: LearningRateScheduler reducing learning rate to 0.0002859235978270506.
24/24 - 2s - loss: 0.0685 - val_loss: 0.1556
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0684581>, 'val_loss': 0.15556584298610687}
Epoch 692/4000

Epoch 00692: LearningRateScheduler reducing learning rate to 0.0002846918273292873.
24/24 - 2s - loss: 0.0689 - val_loss: 0.1512
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06894495>, 'val_loss': 0.15118515491485596}
Epoch 693/4000

Epoch 00693: LearningRateScheduler reducing learning rate to 0.00028346536334896674.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1526
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06863891>, 'val_loss': 0.152592271566391}
Epoch 694/4000

Epoch 00694: LearningRateScheduler reducing learning rate to 0.00028224418302539575.
24/24 - 2s - loss: 0.0683 - val_loss: 0.1579
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06827574>, 'val_loss': 0.1579255610704422}
Epoch 695/4000

Epoch 00695: LearningRateScheduler reducing learning rate to 0.000281028263596366.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1503
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06805486>, 'val_loss': 0.15033695101737976}
Epoch 696/4000

Epoch 00696: LearningRateScheduler reducing learning rate to 0.0002798175823977296.
24/24 - 2s - loss: 0.0692 - val_loss: 0.1572
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06916713>, 'val_loss': 0.15723703801631927}
Epoch 697/4000

Epoch 00697: LearningRateScheduler reducing learning rate to 0.00027861211686297705.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1544
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06858054>, 'val_loss': 0.15444496273994446}
Epoch 698/4000

Epoch 00698: LearningRateScheduler reducing learning rate to 0.00027741184452281575.
24/24 - 2s - loss: 0.0682 - val_loss: 0.1569
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06817483>, 'val_loss': 0.15686963498592377}
Epoch 699/4000

Epoch 00699: LearningRateScheduler reducing learning rate to 0.0002762167430047522.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1557
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06861439>, 'val_loss': 0.1557139754295349}
Epoch 700/4000

Epoch 00700: LearningRateScheduler reducing learning rate to 0.0002750267900326741.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1612
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06861017>, 'val_loss': 0.161202073097229}
Model saved in ./model/scPDB_2021_pdbid--700--0.1612.
Epoch 701/4000

Epoch 00701: LearningRateScheduler reducing learning rate to 0.0002738419634264361.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1491
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06809825>, 'val_loss': 0.14905542135238647}
Epoch 702/4000

Epoch 00702: LearningRateScheduler reducing learning rate to 0.0002726622411014453.
24/24 - 2s - loss: 0.0685 - val_loss: 0.1563
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068549894>, 'val_loss': 0.15627892315387726}
Epoch 703/4000

Epoch 00703: LearningRateScheduler reducing learning rate to 0.00027148760106825035.
24/24 - 2s - loss: 0.0677 - val_loss: 0.1572
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067679934>, 'val_loss': 0.15717510879039764}
Epoch 704/4000

Epoch 00704: LearningRateScheduler reducing learning rate to 0.00027031802143213127.
24/24 - 2s - loss: 0.0691 - val_loss: 0.1563
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06912014>, 'val_loss': 0.15630099177360535}
Epoch 705/4000

Epoch 00705: LearningRateScheduler reducing learning rate to 0.00026915348039269156.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1564
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06748279>, 'val_loss': 0.156394824385643}
Epoch 706/4000

Epoch 00706: LearningRateScheduler reducing learning rate to 0.00026799395624345156.
24/24 - 2s - loss: 0.0692 - val_loss: 0.1530
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.069228314>, 'val_loss': 0.15301141142845154}
Epoch 707/4000

Epoch 00707: LearningRateScheduler reducing learning rate to 0.0002668394273714442.
24/24 - 2s - loss: 0.0680 - val_loss: 0.1505
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06797517>, 'val_loss': 0.15047110617160797}
Epoch 708/4000

Epoch 00708: LearningRateScheduler reducing learning rate to 0.00026568987225681175.
24/24 - 2s - loss: 0.0688 - val_loss: 0.1575
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068835706>, 'val_loss': 0.15747223794460297}
Epoch 709/4000

Epoch 00709: LearningRateScheduler reducing learning rate to 0.00026454526947240493.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1627
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068091415>, 'val_loss': 0.16273200511932373}
Epoch 710/4000

Epoch 00710: LearningRateScheduler reducing learning rate to 0.00026340559768338366.
24/24 - 2s - loss: 0.0683 - val_loss: 0.1524
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06832707>, 'val_loss': 0.15236327052116394}
Epoch 711/4000

Epoch 00711: LearningRateScheduler reducing learning rate to 0.00026227083564681904.
24/24 - 2s - loss: 0.0683 - val_loss: 0.1509
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06831596>, 'val_loss': 0.15092498064041138}
Epoch 712/4000

Epoch 00712: LearningRateScheduler reducing learning rate to 0.00026114096221129755.
24/24 - 2s - loss: 0.0678 - val_loss: 0.1608
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06776319>, 'val_loss': 0.16083888709545135}
Epoch 713/4000

Epoch 00713: LearningRateScheduler reducing learning rate to 0.00026001595631652716.
24/24 - 2s - loss: 0.0679 - val_loss: 0.1547
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067943946>, 'val_loss': 0.15471993386745453}
Epoch 714/4000

Epoch 00714: LearningRateScheduler reducing learning rate to 0.00025889579699294395.
24/24 - 2s - loss: 0.0688 - val_loss: 0.1538
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06877137>, 'val_loss': 0.15384432673454285}
Epoch 715/4000

Epoch 00715: LearningRateScheduler reducing learning rate to 0.0002577804633613221.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1543
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067228936>, 'val_loss': 0.15430296957492828}
Epoch 716/4000

Epoch 00716: LearningRateScheduler reducing learning rate to 0.0002566699346323842.
24/24 - 2s - loss: 0.0676 - val_loss: 0.1524
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06763746>, 'val_loss': 0.15239045023918152}
Epoch 717/4000

Epoch 00717: LearningRateScheduler reducing learning rate to 0.0002555641901064138.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1556
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06861057>, 'val_loss': 0.15556752681732178}
Epoch 718/4000

Epoch 00718: LearningRateScheduler reducing learning rate to 0.0002544632091728699.
24/24 - 2s - loss: 0.0686 - val_loss: 0.1492
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068575546>, 'val_loss': 0.14920562505722046}
Epoch 719/4000

Epoch 00719: LearningRateScheduler reducing learning rate to 0.0002533669713100024.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1663
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0671933>, 'val_loss': 0.1662791669368744}
Epoch 720/4000

Epoch 00720: LearningRateScheduler reducing learning rate to 0.0002522754560844697.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1522
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06806296>, 'val_loss': 0.1522459238767624}
Epoch 721/4000

Epoch 00721: LearningRateScheduler reducing learning rate to 0.000251188643150958.
24/24 - 2s - loss: 0.0678 - val_loss: 0.1581
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06779557>, 'val_loss': 0.15810240805149078}
Epoch 722/4000

Epoch 00722: LearningRateScheduler reducing learning rate to 0.00025010651225180184.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1568
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0672487>, 'val_loss': 0.15683937072753906}
Epoch 723/4000

Epoch 00723: LearningRateScheduler reducing learning rate to 0.0002490290432166067.
24/24 - 2s - loss: 0.0680 - val_loss: 0.1556
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0679806>, 'val_loss': 0.15557193756103516}
Epoch 724/4000

Epoch 00724: LearningRateScheduler reducing learning rate to 0.0002479562159618727.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1541
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068119854>, 'val_loss': 0.1541285365819931}
Epoch 725/4000

Epoch 00725: LearningRateScheduler reducing learning rate to 0.0002468880104906208.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1628
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068078786>, 'val_loss': 0.16282370686531067}
Epoch 726/4000

Epoch 00726: LearningRateScheduler reducing learning rate to 0.0002458244068920197.
24/24 - 2s - loss: 0.0677 - val_loss: 0.1555
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067716934>, 'val_loss': 0.15546423196792603}
Epoch 727/4000

Epoch 00727: LearningRateScheduler reducing learning rate to 0.0002447653853410146.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1486
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067543976>, 'val_loss': 0.14859499037265778}
Epoch 728/4000

Epoch 00728: LearningRateScheduler reducing learning rate to 0.00024371092609795801.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1601
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06748607>, 'val_loss': 0.1601162552833557}
Epoch 729/4000

Epoch 00729: LearningRateScheduler reducing learning rate to 0.00024266100950824152.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1521
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06811329>, 'val_loss': 0.1521453857421875}
Epoch 730/4000

Epoch 00730: LearningRateScheduler reducing learning rate to 0.00024161561600192968.
24/24 - 2s - loss: 0.0676 - val_loss: 0.1570
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06761985>, 'val_loss': 0.15700699388980865}
Epoch 731/4000

Epoch 00731: LearningRateScheduler reducing learning rate to 0.00024057472609339506.
24/24 - 2s - loss: 0.0680 - val_loss: 0.1606
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06800764>, 'val_loss': 0.16055914759635925}
Epoch 732/4000

Epoch 00732: LearningRateScheduler reducing learning rate to 0.0002395383203809551.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1593
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06750574>, 'val_loss': 0.15931576490402222}
Epoch 733/4000

Epoch 00733: LearningRateScheduler reducing learning rate to 0.00023850637954651055.
24/24 - 2s - loss: 0.0673 - val_loss: 0.1595
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06727279>, 'val_loss': 0.15945641696453094}
Epoch 734/4000

Epoch 00734: LearningRateScheduler reducing learning rate to 0.0002374788843551852.
24/24 - 2s - loss: 0.0674 - val_loss: 0.1541
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06744695>, 'val_loss': 0.1541159451007843}
Epoch 735/4000

Epoch 00735: LearningRateScheduler reducing learning rate to 0.00023645581565496758.
24/24 - 2s - loss: 0.0685 - val_loss: 0.1589
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06847594>, 'val_loss': 0.15894488990306854}
Epoch 736/4000

Epoch 00736: LearningRateScheduler reducing learning rate to 0.0002354371543763538.
24/24 - 2s - loss: 0.0680 - val_loss: 0.1549
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06796061>, 'val_loss': 0.15488235652446747}
Epoch 737/4000

Epoch 00737: LearningRateScheduler reducing learning rate to 0.00023442288153199218.
24/24 - 2s - loss: 0.0670 - val_loss: 0.1601
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06697265>, 'val_loss': 0.1600923091173172}
Epoch 738/4000

Epoch 00738: LearningRateScheduler reducing learning rate to 0.00023341297821632937.
24/24 - 2s - loss: 0.0673 - val_loss: 0.1611
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06732314>, 'val_loss': 0.16106528043746948}
Epoch 739/4000

Epoch 00739: LearningRateScheduler reducing learning rate to 0.00023240742560525786.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1580
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06748413>, 'val_loss': 0.15804900228977203}
Epoch 740/4000

Epoch 00740: LearningRateScheduler reducing learning rate to 0.0002314062049557652.
24/24 - 2s - loss: 0.0674 - val_loss: 0.1518
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067436405>, 'val_loss': 0.151807501912117}
Epoch 741/4000

Epoch 00741: LearningRateScheduler reducing learning rate to 0.00023040929760558454.
24/24 - 2s - loss: 0.0671 - val_loss: 0.1591
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067140274>, 'val_loss': 0.15905436873435974}
Epoch 742/4000

Epoch 00742: LearningRateScheduler reducing learning rate to 0.0002294166849728469.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1568
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067227624>, 'val_loss': 0.15678177773952484}
Epoch 743/4000

Epoch 00743: LearningRateScheduler reducing learning rate to 0.00022842834855573468.
24/24 - 2s - loss: 0.0673 - val_loss: 0.1562
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067338794>, 'val_loss': 0.1562134176492691}
Epoch 744/4000

Epoch 00744: LearningRateScheduler reducing learning rate to 0.00022744426993213696.
24/24 - 2s - loss: 0.0676 - val_loss: 0.1606
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06758348>, 'val_loss': 0.16058874130249023}
Epoch 745/4000

Epoch 00745: LearningRateScheduler reducing learning rate to 0.00022646443075930594.
24/24 - 2s - loss: 0.0674 - val_loss: 0.1568
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06739842>, 'val_loss': 0.15682625770568848}
Epoch 746/4000

Epoch 00746: LearningRateScheduler reducing learning rate to 0.0002254888127735152.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1586
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0666545>, 'val_loss': 0.1586141288280487}
Epoch 747/4000

Epoch 00747: LearningRateScheduler reducing learning rate to 0.00022451739778971906.
24/24 - 2s - loss: 0.0681 - val_loss: 0.1598
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.068111606>, 'val_loss': 0.15975822508335114}
Epoch 748/4000

Epoch 00748: LearningRateScheduler reducing learning rate to 0.00022355016770121393.
24/24 - 2s - loss: 0.0674 - val_loss: 0.1568
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06743873>, 'val_loss': 0.1567576378583908}
Epoch 749/4000

Epoch 00749: LearningRateScheduler reducing learning rate to 0.00022258710447930043.
24/24 - 2s - loss: 0.0677 - val_loss: 0.1638
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067662574>, 'val_loss': 0.1638282984495163}
Epoch 750/4000

Epoch 00750: LearningRateScheduler reducing learning rate to 0.00022162819017294784.
24/24 - 2s - loss: 0.0671 - val_loss: 0.1572
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0671176>, 'val_loss': 0.15722359716892242}
Model saved in ./model/scPDB_2021_pdbid--750--0.1572.
Epoch 751/4000

Epoch 00751: LearningRateScheduler reducing learning rate to 0.00022067340690845895.
24/24 - 2s - loss: 0.0671 - val_loss: 0.1564
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06713841>, 'val_loss': 0.15638412535190582}
Epoch 752/4000

Epoch 00752: LearningRateScheduler reducing learning rate to 0.00021972273688913727.
24/24 - 2s - loss: 0.0666 - val_loss: 0.1585
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06656471>, 'val_loss': 0.15853065252304077}
Epoch 753/4000

Epoch 00753: LearningRateScheduler reducing learning rate to 0.00021877616239495524.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1566
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06721037>, 'val_loss': 0.1565866470336914}
Epoch 754/4000

Epoch 00754: LearningRateScheduler reducing learning rate to 0.00021783366578222377.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1592
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066504516>, 'val_loss': 0.15924519300460815}
Epoch 755/4000

Epoch 00755: LearningRateScheduler reducing learning rate to 0.00021689522948326365.
24/24 - 2s - loss: 0.0683 - val_loss: 0.1495
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06825868>, 'val_loss': 0.14952391386032104}
Epoch 756/4000

Epoch 00756: LearningRateScheduler reducing learning rate to 0.00021596083600607785.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06749558>, 'val_loss': 0.16711990535259247}
Epoch 757/4000

Epoch 00757: LearningRateScheduler reducing learning rate to 0.00021503046793402565.
24/24 - 2s - loss: 0.0669 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06688998>, 'val_loss': 0.16305406391620636}
Epoch 758/4000

Epoch 00758: LearningRateScheduler reducing learning rate to 0.0002141041079254978.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1601
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06651549>, 'val_loss': 0.1600801795721054}
Epoch 759/4000

Epoch 00759: LearningRateScheduler reducing learning rate to 0.00021318173871359355.
24/24 - 2s - loss: 0.0674 - val_loss: 0.1572
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06737725>, 'val_loss': 0.1571706086397171}
Epoch 760/4000

Epoch 00760: LearningRateScheduler reducing learning rate to 0.0002122633431057986.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1640
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06665428>, 'val_loss': 0.16398485004901886}
Epoch 761/4000

Epoch 00761: LearningRateScheduler reducing learning rate to 0.00021134890398366463.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1463
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06652749>, 'val_loss': 0.1462559849023819}
Epoch 762/4000

Epoch 00762: LearningRateScheduler reducing learning rate to 0.00021043840430249051.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1583
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06748709>, 'val_loss': 0.1582670658826828}
Epoch 763/4000

Epoch 00763: LearningRateScheduler reducing learning rate to 0.00020953182709100413.
24/24 - 2s - loss: 0.0668 - val_loss: 0.1578
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066761784>, 'val_loss': 0.1577547937631607}
Epoch 764/4000

Epoch 00764: LearningRateScheduler reducing learning rate to 0.00020862915545104643.
24/24 - 2s - loss: 0.0670 - val_loss: 0.1580
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06703711>, 'val_loss': 0.15795300900936127}
Epoch 765/4000

Epoch 00765: LearningRateScheduler reducing learning rate to 0.00020773037255725633.
24/24 - 2s - loss: 0.0676 - val_loss: 0.1636
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06755805>, 'val_loss': 0.16357208788394928}
Epoch 766/4000

Epoch 00766: LearningRateScheduler reducing learning rate to 0.000206835461656757.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1576
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06609337>, 'val_loss': 0.15762823820114136}
Epoch 767/4000

Epoch 00767: LearningRateScheduler reducing learning rate to 0.00020594440606884376.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06643865>, 'val_loss': 0.1652834415435791}
Epoch 768/4000

Epoch 00768: LearningRateScheduler reducing learning rate to 0.00020505718918467305.
24/24 - 2s - loss: 0.0671 - val_loss: 0.1564
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06707973>, 'val_loss': 0.1563730239868164}
Epoch 769/4000

Epoch 00769: LearningRateScheduler reducing learning rate to 0.00020417379446695293.
24/24 - 2s - loss: 0.0666 - val_loss: 0.1629
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06659045>, 'val_loss': 0.16286921501159668}
Epoch 770/4000

Epoch 00770: LearningRateScheduler reducing learning rate to 0.0002032942054496347.
24/24 - 2s - loss: 0.0675 - val_loss: 0.1595
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.067544185>, 'val_loss': 0.15948866307735443}
Epoch 771/4000

Epoch 00771: LearningRateScheduler reducing learning rate to 0.00020241840573760614.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1609
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066681825>, 'val_loss': 0.16091786324977875}
Epoch 772/4000

Epoch 00772: LearningRateScheduler reducing learning rate to 0.00020154637900638586.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1566
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06642271>, 'val_loss': 0.15663407742977142}
Epoch 773/4000

Epoch 00773: LearningRateScheduler reducing learning rate to 0.0002006781090018189.
24/24 - 2s - loss: 0.0666 - val_loss: 0.1586
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06663117>, 'val_loss': 0.1585555225610733}
Epoch 774/4000

Epoch 00774: LearningRateScheduler reducing learning rate to 0.0001998135795397739.
24/24 - 2s - loss: 0.0668 - val_loss: 0.1668
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066797584>, 'val_loss': 0.16680939495563507}
Epoch 775/4000

Epoch 00775: LearningRateScheduler reducing learning rate to 0.00019895277450584156.
24/24 - 2s - loss: 0.0668 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0667739>, 'val_loss': 0.16306684911251068}
Epoch 776/4000

Epoch 00776: LearningRateScheduler reducing learning rate to 0.00019809567785503384.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1541
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0660797>, 'val_loss': 0.1541404277086258}
Epoch 777/4000

Epoch 00777: LearningRateScheduler reducing learning rate to 0.00019724227361148536.
24/24 - 2s - loss: 0.0669 - val_loss: 0.1647
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06690714>, 'val_loss': 0.16472484171390533}
Epoch 778/4000

Epoch 00778: LearningRateScheduler reducing learning rate to 0.0001963925458681553.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06665342>, 'val_loss': 0.16505469381809235}
Epoch 779/4000

Epoch 00779: LearningRateScheduler reducing learning rate to 0.0001955464787865311.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1601
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06637417>, 'val_loss': 0.1601102650165558}
Epoch 780/4000

Epoch 00780: LearningRateScheduler reducing learning rate to 0.00019470405659633311.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066141166>, 'val_loss': 0.164827361702919}
Epoch 781/4000

Epoch 00781: LearningRateScheduler reducing learning rate to 0.00019386526359522073.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1626
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06649878>, 'val_loss': 0.16258028149604797}
Epoch 782/4000

Epoch 00782: LearningRateScheduler reducing learning rate to 0.00019303008414849962.
24/24 - 2s - loss: 0.0671 - val_loss: 0.1561
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06707942>, 'val_loss': 0.15610139071941376}
Epoch 783/4000

Epoch 00783: LearningRateScheduler reducing learning rate to 0.0001921985026888304.
24/24 - 2s - loss: 0.0659 - val_loss: 0.1609
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06586779>, 'val_loss': 0.16092079877853394}
Epoch 784/4000

Epoch 00784: LearningRateScheduler reducing learning rate to 0.0001913705037159384.
24/24 - 2s - loss: 0.0672 - val_loss: 0.1596
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06717225>, 'val_loss': 0.15955978631973267}
Epoch 785/4000

Epoch 00785: LearningRateScheduler reducing learning rate to 0.00019054607179632468.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1596
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066446155>, 'val_loss': 0.15964217483997345}
Epoch 786/4000

Epoch 00786: LearningRateScheduler reducing learning rate to 0.00018972519156297866.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1609
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06615506>, 'val_loss': 0.16085369884967804}
Epoch 787/4000

Epoch 00787: LearningRateScheduler reducing learning rate to 0.00018890784771509125.
24/24 - 2s - loss: 0.0669 - val_loss: 0.1590
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066878766>, 'val_loss': 0.15902458131313324}
Epoch 788/4000

Epoch 00788: LearningRateScheduler reducing learning rate to 0.00018809402501776995.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1673
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06667768>, 'val_loss': 0.16730818152427673}
Epoch 789/4000

Epoch 00789: LearningRateScheduler reducing learning rate to 0.00018728370830175484.
24/24 - 2s - loss: 0.0666 - val_loss: 0.1619
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06655491>, 'val_loss': 0.16193704307079315}
Epoch 790/4000

Epoch 00790: LearningRateScheduler reducing learning rate to 0.0001864768824631357.
24/24 - 2s - loss: 0.0666 - val_loss: 0.1575
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0665746>, 'val_loss': 0.1574665755033493}
Epoch 791/4000

Epoch 00791: LearningRateScheduler reducing learning rate to 0.0001856735324630706.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06607241>, 'val_loss': 0.1652364283800125}
Epoch 792/4000

Epoch 00792: LearningRateScheduler reducing learning rate to 0.0001848736433275056.
24/24 - 2s - loss: 0.0668 - val_loss: 0.1633
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06678376>, 'val_loss': 0.16333121061325073}
Epoch 793/4000

Epoch 00793: LearningRateScheduler reducing learning rate to 0.00018407720014689558.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1596
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06674389>, 'val_loss': 0.15955808758735657}
Epoch 794/4000

Epoch 00794: LearningRateScheduler reducing learning rate to 0.00018328418807592628.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065977894>, 'val_loss': 0.1676998734474182}
Epoch 795/4000

Epoch 00795: LearningRateScheduler reducing learning rate to 0.00018249459233323772.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1609
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06617616>, 'val_loss': 0.1608927696943283}
Epoch 796/4000

Epoch 00796: LearningRateScheduler reducing learning rate to 0.00018170839820114864.
24/24 - 2s - loss: 0.0667 - val_loss: 0.1639
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06669016>, 'val_loss': 0.16386045515537262}
Epoch 797/4000

Epoch 00797: LearningRateScheduler reducing learning rate to 0.00018092559102538208.
24/24 - 2s - loss: 0.0670 - val_loss: 0.1527
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06702236>, 'val_loss': 0.15269984304904938}
Epoch 798/4000

Epoch 00798: LearningRateScheduler reducing learning rate to 0.00018014615621479233.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1626
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065446936>, 'val_loss': 0.1625707596540451}
Epoch 799/4000

Epoch 00799: LearningRateScheduler reducing learning rate to 0.000179370079241093.
24/24 - 2s - loss: 0.0668 - val_loss: 0.1614
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06678896>, 'val_loss': 0.1613529771566391}
Epoch 800/4000

Epoch 00800: LearningRateScheduler reducing learning rate to 0.00017859734563858601.
24/24 - 2s - loss: 0.0656 - val_loss: 0.1596
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06556457>, 'val_loss': 0.15955723822116852}
Model saved in ./model/scPDB_2021_pdbid--800--0.1596.
Epoch 801/4000

Epoch 00801: LearningRateScheduler reducing learning rate to 0.00017782794100389227.
24/24 - 2s - loss: 0.0670 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06695563>, 'val_loss': 0.16578532755374908}
Epoch 802/4000

Epoch 00802: LearningRateScheduler reducing learning rate to 0.00017706185099568283.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1552
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06616726>, 'val_loss': 0.1552117019891739}
Epoch 803/4000

Epoch 00803: LearningRateScheduler reducing learning rate to 0.00017629906133441196.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1746
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0664882>, 'val_loss': 0.17459896206855774}
Epoch 804/4000

Epoch 00804: LearningRateScheduler reducing learning rate to 0.00017553955780205067.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1551
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066207565>, 'val_loss': 0.15508531033992767}
Epoch 805/4000

Epoch 00805: LearningRateScheduler reducing learning rate to 0.00017478332624182183.
24/24 - 2s - loss: 0.0663 - val_loss: 0.1682
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06630649>, 'val_loss': 0.16819286346435547}
Epoch 806/4000

Epoch 00806: LearningRateScheduler reducing learning rate to 0.0001740303525579364.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1582
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066509984>, 'val_loss': 0.15822449326515198}
Epoch 807/4000

Epoch 00807: LearningRateScheduler reducing learning rate to 0.00017328062271533039.
24/24 - 2s - loss: 0.0659 - val_loss: 0.1632
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06589232>, 'val_loss': 0.16323427855968475}
Epoch 808/4000

Epoch 00808: LearningRateScheduler reducing learning rate to 0.00017253412273940356.
24/24 - 2s - loss: 0.0656 - val_loss: 0.1544
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0656419>, 'val_loss': 0.15441639721393585}
Epoch 809/4000

Epoch 00809: LearningRateScheduler reducing learning rate to 0.00017179083871575882.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1678
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06620595>, 'val_loss': 0.16784444451332092}
Epoch 810/4000

Epoch 00810: LearningRateScheduler reducing learning rate to 0.00017105075678994276.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1566
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06595357>, 'val_loss': 0.1566389948129654}
Epoch 811/4000

Epoch 00811: LearningRateScheduler reducing learning rate to 0.00017031386316718766.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06600078>, 'val_loss': 0.16480503976345062}
Epoch 812/4000

Epoch 00812: LearningRateScheduler reducing learning rate to 0.00016958014411215416.
24/24 - 2s - loss: 0.0665 - val_loss: 0.1567
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066456236>, 'val_loss': 0.156694695353508}
Epoch 813/4000

Epoch 00813: LearningRateScheduler reducing learning rate to 0.00016884958594867532.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1604
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06534941>, 'val_loss': 0.16044670343399048}
Epoch 814/4000

Epoch 00814: LearningRateScheduler reducing learning rate to 0.00016812217505950155.
24/24 - 2s - loss: 0.0657 - val_loss: 0.1664
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06572718>, 'val_loss': 0.1664329171180725}
Epoch 815/4000

Epoch 00815: LearningRateScheduler reducing learning rate to 0.00016739789788604713.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1599
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06642905>, 'val_loss': 0.15987573564052582}
Epoch 816/4000

Epoch 00816: LearningRateScheduler reducing learning rate to 0.00016667674092813714.
24/24 - 2s - loss: 0.0659 - val_loss: 0.1624
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06588481>, 'val_loss': 0.16235224902629852}
Epoch 817/4000

Epoch 00817: LearningRateScheduler reducing learning rate to 0.00016595869074375604.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06605277>, 'val_loss': 0.16575157642364502}
Epoch 818/4000

Epoch 00818: LearningRateScheduler reducing learning rate to 0.00016524373394879703.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1549
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06614657>, 'val_loss': 0.15490898489952087}
Epoch 819/4000

Epoch 00819: LearningRateScheduler reducing learning rate to 0.00016453185721681247.
24/24 - 2s - loss: 0.0657 - val_loss: 0.1649
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06568057>, 'val_loss': 0.16487814486026764}
Epoch 820/4000

Epoch 00820: LearningRateScheduler reducing learning rate to 0.0001638230472787658.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065970816>, 'val_loss': 0.1730533391237259}
Epoch 821/4000

Epoch 00821: LearningRateScheduler reducing learning rate to 0.00016311729092278383.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1577
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066087395>, 'val_loss': 0.15767298638820648}
Epoch 822/4000

Epoch 00822: LearningRateScheduler reducing learning rate to 0.00016241457499391074.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1585
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06596751>, 'val_loss': 0.158527672290802}
Epoch 823/4000

Epoch 00823: LearningRateScheduler reducing learning rate to 0.00016171488639386283.
24/24 - 2s - loss: 0.0664 - val_loss: 0.1621
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06644135>, 'val_loss': 0.16214245557785034}
Epoch 824/4000

Epoch 00824: LearningRateScheduler reducing learning rate to 0.0001610182120807843.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1586
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06599047>, 'val_loss': 0.1586010754108429}
Epoch 825/4000

Epoch 00825: LearningRateScheduler reducing learning rate to 0.00016032453906900413.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1650
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06547409>, 'val_loss': 0.1649642288684845}
Epoch 826/4000

Epoch 00826: LearningRateScheduler reducing learning rate to 0.0001596338544287942.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1617
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06536188>, 'val_loss': 0.16167260706424713}
Epoch 827/4000

Epoch 00827: LearningRateScheduler reducing learning rate to 0.00015894614528612813.
24/24 - 2s - loss: 0.0659 - val_loss: 0.1585
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065946795>, 'val_loss': 0.15847046673297882}
Epoch 828/4000

Epoch 00828: LearningRateScheduler reducing learning rate to 0.00015826139882244142.
24/24 - 2s - loss: 0.0658 - val_loss: 0.1619
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06579652>, 'val_loss': 0.16187186539173126}
Epoch 829/4000

Epoch 00829: LearningRateScheduler reducing learning rate to 0.00015757960227439242.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1627
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066118>, 'val_loss': 0.16272859275341034}
Epoch 830/4000

Epoch 00830: LearningRateScheduler reducing learning rate to 0.00015690074293362444.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06551049>, 'val_loss': 0.16567197442054749}
Epoch 831/4000

Epoch 00831: LearningRateScheduler reducing learning rate to 0.00015622480814652903.
24/24 - 2s - loss: 0.0658 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06583664>, 'val_loss': 0.16513071954250336}
Epoch 832/4000

Epoch 00832: LearningRateScheduler reducing learning rate to 0.00015555178531400987.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1693
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066139884>, 'val_loss': 0.16926376521587372}
Epoch 833/4000

Epoch 00833: LearningRateScheduler reducing learning rate to 0.00015488166189124813.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1489
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06532198>, 'val_loss': 0.1488870531320572}
Epoch 834/4000

Epoch 00834: LearningRateScheduler reducing learning rate to 0.00015421442538746856.
24/24 - 2s - loss: 0.0658 - val_loss: 0.1638
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06584934>, 'val_loss': 0.1637895107269287}
Epoch 835/4000

Epoch 00835: LearningRateScheduler reducing learning rate to 0.0001535500633657067.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1599
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06543983>, 'val_loss': 0.15987195074558258}
Epoch 836/4000

Epoch 00836: LearningRateScheduler reducing learning rate to 0.00015288856344257697.
24/24 - 2s - loss: 0.0661 - val_loss: 0.1522
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06607061>, 'val_loss': 0.15224000811576843}
Epoch 837/4000

Epoch 00837: LearningRateScheduler reducing learning rate to 0.000152229913288042.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1624
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06600817>, 'val_loss': 0.16238026320934296}
Epoch 838/4000

Epoch 00838: LearningRateScheduler reducing learning rate to 0.00015157410062518266.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1606
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06551218>, 'val_loss': 0.16064487397670746}
Epoch 839/4000

Epoch 00839: LearningRateScheduler reducing learning rate to 0.00015092111322996933.
24/24 - 2s - loss: 0.0657 - val_loss: 0.1617
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06573901>, 'val_loss': 0.1616605669260025}
Epoch 840/4000

Epoch 00840: LearningRateScheduler reducing learning rate to 0.00015027093893103398.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06525205>, 'val_loss': 0.1680527925491333}
Epoch 841/4000

Epoch 00841: LearningRateScheduler reducing learning rate to 0.00014962356560944333.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1642
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06597339>, 'val_loss': 0.16421034932136536}
Epoch 842/4000

Epoch 00842: LearningRateScheduler reducing learning rate to 0.000148978981198473.
24/24 - 2s - loss: 0.0656 - val_loss: 0.1545
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06559883>, 'val_loss': 0.15449270606040955}
Epoch 843/4000

Epoch 00843: LearningRateScheduler reducing learning rate to 0.00014833717368338247.
24/24 - 2s - loss: 0.0649 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06494002>, 'val_loss': 0.1745210438966751}
Epoch 844/4000

Epoch 00844: LearningRateScheduler reducing learning rate to 0.00014769813110119133.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1680
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06537014>, 'val_loss': 0.16798776388168335}
Epoch 845/4000

Epoch 00845: LearningRateScheduler reducing learning rate to 0.00014706184154045603.
24/24 - 2s - loss: 0.0662 - val_loss: 0.1604
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06624488>, 'val_loss': 0.16043205559253693}
Epoch 846/4000

Epoch 00846: LearningRateScheduler reducing learning rate to 0.0001464282931410481.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1605
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06501122>, 'val_loss': 0.16051244735717773}
Epoch 847/4000

Epoch 00847: LearningRateScheduler reducing learning rate to 0.00014579747409393298.
24/24 - 2s - loss: 0.0658 - val_loss: 0.1550
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06584237>, 'val_loss': 0.1549702286720276}
Epoch 848/4000

Epoch 00848: LearningRateScheduler reducing learning rate to 0.00014516937264094992.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06528405>, 'val_loss': 0.1724797934293747}
Epoch 849/4000

Epoch 00849: LearningRateScheduler reducing learning rate to 0.00014454397707459272.
24/24 - 2s - loss: 0.0663 - val_loss: 0.1634
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06625628>, 'val_loss': 0.1634189784526825}
Epoch 850/4000

Epoch 00850: LearningRateScheduler reducing learning rate to 0.0001439212757377917.
24/24 - 2s - loss: 0.0656 - val_loss: 0.1602
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06556036>, 'val_loss': 0.16015389561653137}
Model saved in ./model/scPDB_2021_pdbid--850--0.1602.
Epoch 851/4000

Epoch 00851: LearningRateScheduler reducing learning rate to 0.00014330125702369625.
24/24 - 2s - loss: 0.0657 - val_loss: 0.1678
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065743215>, 'val_loss': 0.16776686906814575}
Epoch 852/4000

Epoch 00852: LearningRateScheduler reducing learning rate to 0.00014268390937545856.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1614
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064986065>, 'val_loss': 0.16138207912445068}
Epoch 853/4000

Epoch 00853: LearningRateScheduler reducing learning rate to 0.00014206922128601822.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06602993>, 'val_loss': 0.16425494849681854}
Epoch 854/4000

Epoch 00854: LearningRateScheduler reducing learning rate to 0.0001414571812978876.
24/24 - 2s - loss: 0.0656 - val_loss: 0.1612
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06556944>, 'val_loss': 0.1612088680267334}
Epoch 855/4000

Epoch 00855: LearningRateScheduler reducing learning rate to 0.0001408477780029385.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065330416>, 'val_loss': 0.16569502651691437}
Epoch 856/4000

Epoch 00856: LearningRateScheduler reducing learning rate to 0.00014024100004218947.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06460244>, 'val_loss': 0.16526193916797638}
Epoch 857/4000

Epoch 00857: LearningRateScheduler reducing learning rate to 0.00013963683610559375.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1694
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06548866>, 'val_loss': 0.16936948895454407}
Epoch 858/4000

Epoch 00858: LearningRateScheduler reducing learning rate to 0.00013903527493182898.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1568
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065341584>, 'val_loss': 0.15677262842655182}
Epoch 859/4000

Epoch 00859: LearningRateScheduler reducing learning rate to 0.00013843630530808692.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1633
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06522836>, 'val_loss': 0.16325542330741882}
Epoch 860/4000

Epoch 00860: LearningRateScheduler reducing learning rate to 0.00013783991606986458.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0650765>, 'val_loss': 0.16711147129535675}
Epoch 861/4000

Epoch 00861: LearningRateScheduler reducing learning rate to 0.00013724609610075617.
24/24 - 2s - loss: 0.0659 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06594547>, 'val_loss': 0.1697060614824295}
Epoch 862/4000

Epoch 00862: LearningRateScheduler reducing learning rate to 0.00013665483433224568.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06530277>, 'val_loss': 0.1715836077928543}
Epoch 863/4000

Epoch 00863: LearningRateScheduler reducing learning rate to 0.00013606611974350085.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1578
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06554574>, 'val_loss': 0.1577916443347931}
Epoch 864/4000

Epoch 00864: LearningRateScheduler reducing learning rate to 0.00013547994136116757.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1662
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065239586>, 'val_loss': 0.16623736917972565}
Epoch 865/4000

Epoch 00865: LearningRateScheduler reducing learning rate to 0.00013489628825916533.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1646
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06502549>, 'val_loss': 0.16459378600120544}
Epoch 866/4000

Epoch 00866: LearningRateScheduler reducing learning rate to 0.00013431514955848377.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1593
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06545403>, 'val_loss': 0.15926936268806458}
Epoch 867/4000

Epoch 00867: LearningRateScheduler reducing learning rate to 0.00013373651442697958.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06471341>, 'val_loss': 0.16774778068065643}
Epoch 868/4000

Epoch 00868: LearningRateScheduler reducing learning rate to 0.00013316037207917482.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06496946>, 'val_loss': 0.1680605560541153}
Epoch 869/4000

Epoch 00869: LearningRateScheduler reducing learning rate to 0.00013258671177605592.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06525326>, 'val_loss': 0.16770116984844208}
Epoch 870/4000

Epoch 00870: LearningRateScheduler reducing learning rate to 0.0001320155228248733.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1635
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06504661>, 'val_loss': 0.16354309022426605}
Epoch 871/4000

Epoch 00871: LearningRateScheduler reducing learning rate to 0.0001314467945789422.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06503483>, 'val_loss': 0.1631138026714325}
Epoch 872/4000

Epoch 00872: LearningRateScheduler reducing learning rate to 0.00013088051643744432.
24/24 - 2s - loss: 0.0663 - val_loss: 0.1567
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.066271536>, 'val_loss': 0.15672409534454346}
Epoch 873/4000

Epoch 00873: LearningRateScheduler reducing learning rate to 0.00013031667784522993.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1695
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06535616>, 'val_loss': 0.16951529681682587}
Epoch 874/4000

Epoch 00874: LearningRateScheduler reducing learning rate to 0.0001297552682926215.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1688
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06514813>, 'val_loss': 0.16878573596477509}
Epoch 875/4000

Epoch 00875: LearningRateScheduler reducing learning rate to 0.0001291962773152175.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1628
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06475093>, 'val_loss': 0.16284692287445068}
Epoch 876/4000

Epoch 00876: LearningRateScheduler reducing learning rate to 0.00012863969449369747.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1638
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06534339>, 'val_loss': 0.16377244889736176}
Epoch 877/4000

Epoch 00877: LearningRateScheduler reducing learning rate to 0.0001280855094536278.
24/24 - 2s - loss: 0.0654 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065364115>, 'val_loss': 0.16373951733112335}
Epoch 878/4000

Epoch 00878: LearningRateScheduler reducing learning rate to 0.00012753371186526857.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064761765>, 'val_loss': 0.17174586653709412}
Epoch 879/4000

Epoch 00879: LearningRateScheduler reducing learning rate to 0.00012698429144338054.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1605
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06514678>, 'val_loss': 0.1605239063501358}
Epoch 880/4000

Epoch 00880: LearningRateScheduler reducing learning rate to 0.00012643723794703376.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065220974>, 'val_loss': 0.1716126650571823}
Epoch 881/4000

Epoch 00881: LearningRateScheduler reducing learning rate to 0.00012589254117941666.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1608
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064776786>, 'val_loss': 0.16082793474197388}
Epoch 882/4000

Epoch 00882: LearningRateScheduler reducing learning rate to 0.000125350190987646.
24/24 - 2s - loss: 0.0658 - val_loss: 0.1669
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06577868>, 'val_loss': 0.16686178743839264}
Epoch 883/4000

Epoch 00883: LearningRateScheduler reducing learning rate to 0.0001248101772625775.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1617
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06502121>, 'val_loss': 0.16170214116573334}
Epoch 884/4000

Epoch 00884: LearningRateScheduler reducing learning rate to 0.00012427248993861746.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1842
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06484584>, 'val_loss': 0.1841992735862732}
Epoch 885/4000

Epoch 00885: LearningRateScheduler reducing learning rate to 0.00012373711899353522.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1620
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06479878>, 'val_loss': 0.16195248067378998}
Epoch 886/4000

Epoch 00886: LearningRateScheduler reducing learning rate to 0.0001232040544482763.
24/24 - 2s - loss: 0.0657 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065694384>, 'val_loss': 0.16828018426895142}
Epoch 887/4000

Epoch 00887: LearningRateScheduler reducing learning rate to 0.0001226732863667764.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1623
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06505614>, 'val_loss': 0.16226361691951752}
Epoch 888/4000

Epoch 00888: LearningRateScheduler reducing learning rate to 0.00012214480485577616.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06465196>, 'val_loss': 0.1652265191078186}
Epoch 889/4000

Epoch 00889: LearningRateScheduler reducing learning rate to 0.00012161860006463679.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06510134>, 'val_loss': 0.17084936797618866}
Epoch 890/4000

Epoch 00890: LearningRateScheduler reducing learning rate to 0.00012109466218515644.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1591
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06499877>, 'val_loss': 0.1591426432132721}
Epoch 891/4000

Epoch 00891: LearningRateScheduler reducing learning rate to 0.00012057298145138743.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1589
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06521375>, 'val_loss': 0.15893733501434326}
Epoch 892/4000

Epoch 00892: LearningRateScheduler reducing learning rate to 0.00012005354813945414.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1662
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06459511>, 'val_loss': 0.16618900001049042}
Epoch 893/4000

Epoch 00893: LearningRateScheduler reducing learning rate to 0.00011953635256737187.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1667
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06481634>, 'val_loss': 0.16665318608283997}
Epoch 894/4000

Epoch 00894: LearningRateScheduler reducing learning rate to 0.00011902138509486618.
24/24 - 2s - loss: 0.0660 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06595374>, 'val_loss': 0.16427959501743317}
Epoch 895/4000

Epoch 00895: LearningRateScheduler reducing learning rate to 0.00011850863612319345.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1603
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06414417>, 'val_loss': 0.16033527255058289}
Epoch 896/4000

Epoch 00896: LearningRateScheduler reducing learning rate to 0.0001179980960949618.
24/24 - 2s - loss: 0.0649 - val_loss: 0.1624
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06493284>, 'val_loss': 0.16239891946315765}
Epoch 897/4000

Epoch 00897: LearningRateScheduler reducing learning rate to 0.00011748975549395295.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1662
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06463302>, 'val_loss': 0.16624684631824493}
Epoch 898/4000

Epoch 00898: LearningRateScheduler reducing learning rate to 0.00011698360484494491.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1605
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065324984>, 'val_loss': 0.16046833992004395}
Epoch 899/4000

Epoch 00899: LearningRateScheduler reducing learning rate to 0.0001164796347135353.
24/24 - 2s - loss: 0.0649 - val_loss: 0.1606
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06485532>, 'val_loss': 0.16056713461875916}
Epoch 900/4000

Epoch 00900: LearningRateScheduler reducing learning rate to 0.00011597783570596556.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1655
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064713776>, 'val_loss': 0.16547195613384247}
Model saved in ./model/scPDB_2021_pdbid--900--0.1655.
Epoch 901/4000

Epoch 00901: LearningRateScheduler reducing learning rate to 0.00011547819846894578.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1623
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064413406>, 'val_loss': 0.1622992604970932}
Epoch 902/4000

Epoch 00902: LearningRateScheduler reducing learning rate to 0.00011498071368948052.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.065089844>, 'val_loss': 0.16811628639698029}
Epoch 903/4000

Epoch 00903: LearningRateScheduler reducing learning rate to 0.00011448537209469497.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1647
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064580955>, 'val_loss': 0.16467861831188202}
Epoch 904/4000

Epoch 00904: LearningRateScheduler reducing learning rate to 0.00011399216445166229.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06521457>, 'val_loss': 0.1636682003736496}
Epoch 905/4000

Epoch 00905: LearningRateScheduler reducing learning rate to 0.00011350108156723148.
24/24 - 2s - loss: 0.0655 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06546838>, 'val_loss': 0.16869868338108063}
Epoch 906/4000

Epoch 00906: LearningRateScheduler reducing learning rate to 0.00011301211428785599.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1630
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06450868>, 'val_loss': 0.16302436590194702}
Epoch 907/4000

Epoch 00907: LearningRateScheduler reducing learning rate to 0.00011252525349942312.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06504901>, 'val_loss': 0.17018090188503265}
Epoch 908/4000

Epoch 00908: LearningRateScheduler reducing learning rate to 0.00011204049012708417.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1656
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06443207>, 'val_loss': 0.16562345623970032}
Epoch 909/4000

Epoch 00909: LearningRateScheduler reducing learning rate to 0.0001115578151350852.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1639
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06512893>, 'val_loss': 0.16386257112026215}
Epoch 910/4000

Epoch 00910: LearningRateScheduler reducing learning rate to 0.00011107721952659873.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064308695>, 'val_loss': 0.16707809269428253}
Epoch 911/4000

Epoch 00911: LearningRateScheduler reducing learning rate to 0.00011059869434355593.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06428578>, 'val_loss': 0.16721421480178833}
Epoch 912/4000

Epoch 00912: LearningRateScheduler reducing learning rate to 0.00011012223066647972.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1633
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06503052>, 'val_loss': 0.16332711279392242}
Epoch 913/4000

Epoch 00913: LearningRateScheduler reducing learning rate to 0.00010964781961431847.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06434604>, 'val_loss': 0.1672458052635193}
Epoch 914/4000

Epoch 00914: LearningRateScheduler reducing learning rate to 0.00010917545234428055.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1670
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06449967>, 'val_loss': 0.16701197624206543}
Epoch 915/4000

Epoch 00915: LearningRateScheduler reducing learning rate to 0.0001087051200516693.
24/24 - 2s - loss: 0.0649 - val_loss: 0.1689
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06492164>, 'val_loss': 0.16893072426319122}
Epoch 916/4000

Epoch 00916: LearningRateScheduler reducing learning rate to 0.00010823681396971918.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1694
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06453884>, 'val_loss': 0.16938257217407227}
Epoch 917/4000

Epoch 00917: LearningRateScheduler reducing learning rate to 0.00010777052536943218.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1694
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06429009>, 'val_loss': 0.1693764626979828}
Epoch 918/4000

Epoch 00918: LearningRateScheduler reducing learning rate to 0.00010730624555941517.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1630
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064348005>, 'val_loss': 0.16296441853046417}
Epoch 919/4000

Epoch 00919: LearningRateScheduler reducing learning rate to 0.00010684396588571793.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06499176>, 'val_loss': 0.16999919712543488}
Epoch 920/4000

Epoch 00920: LearningRateScheduler reducing learning rate to 0.00010638367773167174.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06474701>, 'val_loss': 0.16507865488529205}
Epoch 921/4000

Epoch 00921: LearningRateScheduler reducing learning rate to 0.00010592537251772889.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06425068>, 'val_loss': 0.16576363146305084}
Epoch 922/4000

Epoch 00922: LearningRateScheduler reducing learning rate to 0.0001054690417013027.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064529985>, 'val_loss': 0.16830818355083466}
Epoch 923/4000

Epoch 00923: LearningRateScheduler reducing learning rate to 0.00010501467677660833.
24/24 - 2s - loss: 0.0653 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06525669>, 'val_loss': 0.1672409325838089}
Epoch 924/4000

Epoch 00924: LearningRateScheduler reducing learning rate to 0.00010456226927450415.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1678
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064418025>, 'val_loss': 0.16776247322559357}
Epoch 925/4000

Epoch 00925: LearningRateScheduler reducing learning rate to 0.00010411181076233396.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06458686>, 'val_loss': 0.16571903228759766}
Epoch 926/4000

Epoch 00926: LearningRateScheduler reducing learning rate to 0.00010366329284376977.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06472043>, 'val_loss': 0.1784992814064026}
Epoch 927/4000

Epoch 00927: LearningRateScheduler reducing learning rate to 0.0001032167071586554.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1635
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06429608>, 'val_loss': 0.16345904767513275}
Epoch 928/4000

Epoch 00928: LearningRateScheduler reducing learning rate to 0.00010277204538285048.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06508164>, 'val_loss': 0.163053497672081}
Epoch 929/4000

Epoch 00929: LearningRateScheduler reducing learning rate to 0.00010232929922807538.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1630
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06411537>, 'val_loss': 0.1630283147096634}
Epoch 930/4000

Epoch 00930: LearningRateScheduler reducing learning rate to 0.00010188846044175673.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1765
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06442172>, 'val_loss': 0.17651985585689545}
Epoch 931/4000

Epoch 00931: LearningRateScheduler reducing learning rate to 0.00010144952080687359.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1607
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06471205>, 'val_loss': 0.16067539155483246}
Epoch 932/4000

Epoch 00932: LearningRateScheduler reducing learning rate to 0.00010101247214180425.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06400236>, 'val_loss': 0.169952854514122}
Epoch 933/4000

Epoch 00933: LearningRateScheduler reducing learning rate to 0.00010057730630017379.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1632
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06473038>, 'val_loss': 0.16317707300186157}
Epoch 934/4000

Epoch 00934: LearningRateScheduler reducing learning rate to 0.00010014401517070223.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06405804>, 'val_loss': 0.16998939216136932}
Epoch 935/4000

Epoch 00935: LearningRateScheduler reducing learning rate to 9.971259067705322e-05.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1618
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064457566>, 'val_loss': 0.16183555126190186}
Epoch 936/4000

Epoch 00936: LearningRateScheduler reducing learning rate to 9.928302477768371e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1679
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06469403>, 'val_loss': 0.1679278016090393}
Epoch 937/4000

Epoch 00937: LearningRateScheduler reducing learning rate to 9.885530946569386e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1609
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064131565>, 'val_loss': 0.16091208159923553}
Epoch 938/4000

Epoch 00938: LearningRateScheduler reducing learning rate to 9.842943676867794e-05.
24/24 - 2s - loss: 0.0651 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06508092>, 'val_loss': 0.1753035932779312}
Epoch 939/4000

Epoch 00939: LearningRateScheduler reducing learning rate to 9.80053987485756e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06411326>, 'val_loss': 0.17094971239566803}
Epoch 940/4000

Epoch 00940: LearningRateScheduler reducing learning rate to 9.758318750152405e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06401725>, 'val_loss': 0.16523121297359467}
Epoch 941/4000

Epoch 00941: LearningRateScheduler reducing learning rate to 9.71627951577106e-05.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1670
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06460691>, 'val_loss': 0.16700172424316406}
Epoch 942/4000

Epoch 00942: LearningRateScheduler reducing learning rate to 9.67442138812261e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06356651>, 'val_loss': 0.1686617136001587}
Epoch 943/4000

Epoch 00943: LearningRateScheduler reducing learning rate to 9.632743586991876e-05.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06496108>, 'val_loss': 0.16580677032470703}
Epoch 944/4000

Epoch 00944: LearningRateScheduler reducing learning rate to 9.591245335524878e-05.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1701
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06446157>, 'val_loss': 0.17014308273792267}
Epoch 945/4000

Epoch 00945: LearningRateScheduler reducing learning rate to 9.54992586021436e-05.
24/24 - 2s - loss: 0.0642 - val_loss: 0.1680
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06423038>, 'val_loss': 0.16797195374965668}
Epoch 946/4000

Epoch 00946: LearningRateScheduler reducing learning rate to 9.508784390885358e-05.
24/24 - 2s - loss: 0.0652 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06518319>, 'val_loss': 0.16661719977855682}
Epoch 947/4000

Epoch 00947: LearningRateScheduler reducing learning rate to 9.467820160680862e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1600
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06319833>, 'val_loss': 0.1599940061569214}
Epoch 948/4000

Epoch 00948: LearningRateScheduler reducing learning rate to 9.427032406047509e-05.
24/24 - 2s - loss: 0.0649 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06491115>, 'val_loss': 0.16845102608203888}
Epoch 949/4000

Epoch 00949: LearningRateScheduler reducing learning rate to 9.386420366721353e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1747
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06328445>, 'val_loss': 0.17470358312129974}
Epoch 950/4000

Epoch 00950: LearningRateScheduler reducing learning rate to 9.345983285713695e-05.
24/24 - 2s - loss: 0.0642 - val_loss: 0.1641
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064223796>, 'val_loss': 0.1641421765089035}
Model saved in ./model/scPDB_2021_pdbid--950--0.1641.
Epoch 951/4000

Epoch 00951: LearningRateScheduler reducing learning rate to 9.305720409296986e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1639
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06444615>, 'val_loss': 0.1638900637626648}
Epoch 952/4000

Epoch 00952: LearningRateScheduler reducing learning rate to 9.265630986990754e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1680
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0642613>, 'val_loss': 0.1679821014404297}
Epoch 953/4000

Epoch 00953: LearningRateScheduler reducing learning rate to 9.225714271547629e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064262845>, 'val_loss': 0.16308918595314026}
Epoch 954/4000

Epoch 00954: LearningRateScheduler reducing learning rate to 9.185969518939414e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06466212>, 'val_loss': 0.17125184834003448}
Epoch 955/4000

Epoch 00955: LearningRateScheduler reducing learning rate to 9.146395988343222e-05.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06499402>, 'val_loss': 0.16591957211494446}
Epoch 956/4000

Epoch 00956: LearningRateScheduler reducing learning rate to 9.106992942127648e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06383521>, 'val_loss': 0.1709291934967041}
Epoch 957/4000

Epoch 00957: LearningRateScheduler reducing learning rate to 9.067759645839046e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1623
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06429254>, 'val_loss': 0.16229189932346344}
Epoch 958/4000

Epoch 00958: LearningRateScheduler reducing learning rate to 9.028695368187822e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064416364>, 'val_loss': 0.17122404277324677}
Epoch 959/4000

Epoch 00959: LearningRateScheduler reducing learning rate to 8.9897993810348e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1670
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06344026>, 'val_loss': 0.16699710488319397}
Epoch 960/4000

Epoch 00960: LearningRateScheduler reducing learning rate to 8.95107095937767e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06465333>, 'val_loss': 0.17103564739227295}
Epoch 961/4000

Epoch 00961: LearningRateScheduler reducing learning rate to 8.912509381337453e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064300664>, 'val_loss': 0.16751162707805634}
Epoch 962/4000

Epoch 00962: LearningRateScheduler reducing learning rate to 8.874113928145057e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06395179>, 'val_loss': 0.1741180419921875}
Epoch 963/4000

Epoch 00963: LearningRateScheduler reducing learning rate to 8.835883884127873e-05.
24/24 - 2s - loss: 0.0650 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06495368>, 'val_loss': 0.16987474262714386}
Epoch 964/4000

Epoch 00964: LearningRateScheduler reducing learning rate to 8.797818536696443e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06427113>, 'val_loss': 0.16967253386974335}
Epoch 965/4000

Epoch 00965: LearningRateScheduler reducing learning rate to 8.759917176331172e-05.
24/24 - 3s - loss: 0.0641 - val_loss: 0.1642
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06411189>, 'val_loss': 0.1641654670238495}
Epoch 966/4000

Epoch 00966: LearningRateScheduler reducing learning rate to 8.722179096569103e-05.
24/24 - 2s - loss: 0.0648 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064811625>, 'val_loss': 0.16855847835540771}
Epoch 967/4000

Epoch 00967: LearningRateScheduler reducing learning rate to 8.684603593990752e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064385764>, 'val_loss': 0.169850155711174}
Epoch 968/4000

Epoch 00968: LearningRateScheduler reducing learning rate to 8.647189968206993e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0639466>, 'val_loss': 0.16657046973705292}
Epoch 969/4000

Epoch 00969: LearningRateScheduler reducing learning rate to 8.609937521846007e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1606
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064380445>, 'val_loss': 0.1605832576751709}
Epoch 970/4000

Epoch 00970: LearningRateScheduler reducing learning rate to 8.572845560540279e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1641
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06434783>, 'val_loss': 0.16414642333984375}
Epoch 971/4000

Epoch 00971: LearningRateScheduler reducing learning rate to 8.535913392913659e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1654
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063889734>, 'val_loss': 0.16544078290462494}
Epoch 972/4000

Epoch 00972: LearningRateScheduler reducing learning rate to 8.499140330568473e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06432765>, 'val_loss': 0.16577818989753723}
Epoch 973/4000

Epoch 00973: LearningRateScheduler reducing learning rate to 8.462525688072693e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06371593>, 'val_loss': 0.16425029933452606}
Epoch 974/4000

Epoch 00974: LearningRateScheduler reducing learning rate to 8.426068782947154e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1688
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06470341>, 'val_loss': 0.16884616017341614}
Epoch 975/4000

Epoch 00975: LearningRateScheduler reducing learning rate to 8.389768935652854e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06404719>, 'val_loss': 0.16656120121479034}
Epoch 976/4000

Epoch 00976: LearningRateScheduler reducing learning rate to 8.353625469578259e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064094536>, 'val_loss': 0.16478705406188965}
Epoch 977/4000

Epoch 00977: LearningRateScheduler reducing learning rate to 8.317637711026708e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06466028>, 'val_loss': 0.17103224992752075}
Epoch 978/4000

Epoch 00978: LearningRateScheduler reducing learning rate to 8.281804989203853e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06359918>, 'val_loss': 0.17241163551807404}
Epoch 979/4000

Epoch 00979: LearningRateScheduler reducing learning rate to 8.246126636205158e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06427087>, 'val_loss': 0.1698695421218872}
Epoch 980/4000

Epoch 00980: LearningRateScheduler reducing learning rate to 8.210601987003444e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06402994>, 'val_loss': 0.17165642976760864}
Epoch 981/4000

Epoch 00981: LearningRateScheduler reducing learning rate to 8.175230379436498e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064141914>, 'val_loss': 0.16721923649311066}
Epoch 982/4000

Epoch 00982: LearningRateScheduler reducing learning rate to 8.140011154194728e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1610
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06444688>, 'val_loss': 0.1610129475593567}
Epoch 983/4000

Epoch 00983: LearningRateScheduler reducing learning rate to 8.104943654808874e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06389554>, 'val_loss': 0.17432096600532532}
Epoch 984/4000

Epoch 00984: LearningRateScheduler reducing learning rate to 8.070027227637771e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1668
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06410052>, 'val_loss': 0.16676340997219086}
Epoch 985/4000

Epoch 00985: LearningRateScheduler reducing learning rate to 8.035261221856171e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1654
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06343594>, 'val_loss': 0.1653667688369751}
Epoch 986/4000

Epoch 00986: LearningRateScheduler reducing learning rate to 8.000644989442605e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06440625>, 'val_loss': 0.17639805376529694}
Epoch 987/4000

Epoch 00987: LearningRateScheduler reducing learning rate to 7.966177885167306e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063954994>, 'val_loss': 0.16371600329875946}
Epoch 988/4000

Epoch 00988: LearningRateScheduler reducing learning rate to 7.931859266580187e-05.
24/24 - 2s - loss: 0.0642 - val_loss: 0.1703
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06415328>, 'val_loss': 0.1703462153673172}
Epoch 989/4000

Epoch 00989: LearningRateScheduler reducing learning rate to 7.897688493998855e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063915946>, 'val_loss': 0.16850198805332184}
Epoch 990/4000

Epoch 00990: LearningRateScheduler reducing learning rate to 7.863664930496702e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06426356>, 'val_loss': 0.16719160974025726}
Epoch 991/4000

Epoch 00991: LearningRateScheduler reducing learning rate to 7.829787941891022e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1641
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06391597>, 'val_loss': 0.16414189338684082}
Epoch 992/4000

Epoch 00992: LearningRateScheduler reducing learning rate to 7.796056896731196e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06394568>, 'val_loss': 0.1697252243757248}
Epoch 993/4000

Epoch 00993: LearningRateScheduler reducing learning rate to 7.762471166286918e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063512966>, 'val_loss': 0.17135781049728394}
Epoch 994/4000

Epoch 00994: LearningRateScheduler reducing learning rate to 7.729030124536477e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1673
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06427748>, 'val_loss': 0.167262002825737}
Epoch 995/4000

Epoch 00995: LearningRateScheduler reducing learning rate to 7.69573314815509e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1632
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063606>, 'val_loss': 0.1632000058889389}
Epoch 996/4000

Epoch 00996: LearningRateScheduler reducing learning rate to 7.662579616503287e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064692594>, 'val_loss': 0.17164720594882965}
Epoch 997/4000

Epoch 00997: LearningRateScheduler reducing learning rate to 7.629568911615331e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1670
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06395132>, 'val_loss': 0.16704316437244415}
Epoch 998/4000

Epoch 00998: LearningRateScheduler reducing learning rate to 7.596700418187711e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06401117>, 'val_loss': 0.17131225764751434}
Epoch 999/4000

Epoch 00999: LearningRateScheduler reducing learning rate to 7.563973523567662e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06372743>, 'val_loss': 0.17065250873565674}
Epoch 1000/4000

Epoch 01000: LearningRateScheduler reducing learning rate to 7.531387617741766e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1711
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06381136>, 'val_loss': 0.17107175290584564}
Model saved in ./model/scPDB_2021_pdbid--1000--0.1711.
Epoch 1001/4000

Epoch 01001: LearningRateScheduler reducing learning rate to 7.498942093324556e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063831136>, 'val_loss': 0.1656867265701294}
Epoch 1002/4000

Epoch 01002: LearningRateScheduler reducing learning rate to 7.466636345547208e-05.
24/24 - 2s - loss: 0.0642 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064157665>, 'val_loss': 0.16524547338485718}
Epoch 1003/4000

Epoch 01003: LearningRateScheduler reducing learning rate to 7.434469772246266e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063504346>, 'val_loss': 0.16989104449748993}
Epoch 1004/4000

Epoch 01004: LearningRateScheduler reducing learning rate to 7.402441773852425e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1602
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0640061>, 'val_loss': 0.1601550132036209}
Epoch 1005/4000

Epoch 01005: LearningRateScheduler reducing learning rate to 7.370551753379342e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063099824>, 'val_loss': 0.1729329228401184}
Epoch 1006/4000

Epoch 01006: LearningRateScheduler reducing learning rate to 7.338799116412519e-05.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1669
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064461686>, 'val_loss': 0.16690488159656525}
Epoch 1007/4000

Epoch 01007: LearningRateScheduler reducing learning rate to 7.307183271098216e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06425004>, 'val_loss': 0.17174440622329712}
Epoch 1008/4000

Epoch 01008: LearningRateScheduler reducing learning rate to 7.275703628132431e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06326545>, 'val_loss': 0.1684790402650833}
Epoch 1009/4000

Epoch 01009: LearningRateScheduler reducing learning rate to 7.2443596007499e-05.
24/24 - 2s - loss: 0.0643 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06432296>, 'val_loss': 0.17098546028137207}
Epoch 1010/4000

Epoch 01010: LearningRateScheduler reducing learning rate to 7.21315060471317e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1661
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06435106>, 'val_loss': 0.16614185273647308}
Epoch 1011/4000

Epoch 01011: LearningRateScheduler reducing learning rate to 7.182076058301705e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06348192>, 'val_loss': 0.1676803082227707}
Epoch 1012/4000

Epoch 01012: LearningRateScheduler reducing learning rate to 7.15113538230105e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1670
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06409653>, 'val_loss': 0.16703814268112183}
Epoch 1013/4000

Epoch 01013: LearningRateScheduler reducing learning rate to 7.120327999992024e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1701
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06367045>, 'val_loss': 0.17012721300125122}
Epoch 1014/4000

Epoch 01014: LearningRateScheduler reducing learning rate to 7.08965333713998e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063970394>, 'val_loss': 0.16588164865970612}
Epoch 1015/4000

Epoch 01015: LearningRateScheduler reducing learning rate to 7.059110821984094e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1740
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063511334>, 'val_loss': 0.17397741973400116}
Epoch 1016/4000

Epoch 01016: LearningRateScheduler reducing learning rate to 7.02869988522671e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063880555>, 'val_loss': 0.17425520718097687}
Epoch 1017/4000

Epoch 01017: LearningRateScheduler reducing learning rate to 6.998419960022735e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1619
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06400572>, 'val_loss': 0.16189734637737274}
Epoch 1018/4000

Epoch 01018: LearningRateScheduler reducing learning rate to 6.968270481969061e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06390139>, 'val_loss': 0.1682610660791397}
Epoch 1019/4000

Epoch 01019: LearningRateScheduler reducing learning rate to 6.938250889094057e-05.
24/24 - 2s - loss: 0.0647 - val_loss: 0.1715
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064710796>, 'val_loss': 0.17150801420211792}
Epoch 1020/4000

Epoch 01020: LearningRateScheduler reducing learning rate to 6.908360621847085e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06362779>, 'val_loss': 0.1705082207918167}
Epoch 1021/4000

Epoch 01021: LearningRateScheduler reducing learning rate to 6.878599123088077e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1727
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0637769>, 'val_loss': 0.17265264689922333}
Epoch 1022/4000

Epoch 01022: LearningRateScheduler reducing learning rate to 6.848965838077142e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1649
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06377379>, 'val_loss': 0.1649431586265564}
Epoch 1023/4000

Epoch 01023: LearningRateScheduler reducing learning rate to 6.819460214464235e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1692
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063704655>, 'val_loss': 0.16922612488269806}
Epoch 1024/4000

Epoch 01024: LearningRateScheduler reducing learning rate to 6.790081702278863e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06413065>, 'val_loss': 0.16427265107631683}
Epoch 1025/4000

Epoch 01025: LearningRateScheduler reducing learning rate to 6.760829753919816e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06338226>, 'val_loss': 0.1685718297958374}
Epoch 1026/4000

Epoch 01026: LearningRateScheduler reducing learning rate to 6.731703824144981e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06358375>, 'val_loss': 0.17359614372253418}
Epoch 1027/4000

Epoch 01027: LearningRateScheduler reducing learning rate to 6.702703370061166e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1695
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06383146>, 'val_loss': 0.16952966153621674}
Epoch 1028/4000

Epoch 01028: LearningRateScheduler reducing learning rate to 6.673827851113987e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06389402>, 'val_loss': 0.16856062412261963}
Epoch 1029/4000

Epoch 01029: LearningRateScheduler reducing learning rate to 6.645076729077794e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1611
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06356123>, 'val_loss': 0.1611192524433136}
Epoch 1030/4000

Epoch 01030: LearningRateScheduler reducing learning rate to 6.616449468045625e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06306306>, 'val_loss': 0.17134134471416473}
Epoch 1031/4000

Epoch 01031: LearningRateScheduler reducing learning rate to 6.587945534419238e-05.
24/24 - 2s - loss: 0.0644 - val_loss: 0.1593
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06444862>, 'val_loss': 0.15926261246204376}
Epoch 1032/4000

Epoch 01032: LearningRateScheduler reducing learning rate to 6.559564396899144e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06374682>, 'val_loss': 0.1689848154783249}
Epoch 1033/4000

Epoch 01033: LearningRateScheduler reducing learning rate to 6.531305526474722e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1704
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06382582>, 'val_loss': 0.17037217319011688}
Epoch 1034/4000

Epoch 01034: LearningRateScheduler reducing learning rate to 6.503168396414347e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1595
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06352614>, 'val_loss': 0.1594715118408203}
Epoch 1035/4000

Epoch 01035: LearningRateScheduler reducing learning rate to 6.475152482255575e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063724615>, 'val_loss': 0.16745884716510773}
Epoch 1036/4000

Epoch 01036: LearningRateScheduler reducing learning rate to 6.447257261795367e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06318845>, 'val_loss': 0.16830851137638092}
Epoch 1037/4000

Epoch 01037: LearningRateScheduler reducing learning rate to 6.419482215080358e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06400689>, 'val_loss': 0.16529802978038788}
Epoch 1038/4000

Epoch 01038: LearningRateScheduler reducing learning rate to 6.391826824397161e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06384279>, 'val_loss': 0.17241840064525604}
Epoch 1039/4000

Epoch 01039: LearningRateScheduler reducing learning rate to 6.36429057426272e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06342894>, 'val_loss': 0.1709192842245102}
Epoch 1040/4000

Epoch 01040: LearningRateScheduler reducing learning rate to 6.336872951414704e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06365507>, 'val_loss': 0.1712336242198944}
Epoch 1041/4000

Epoch 01041: LearningRateScheduler reducing learning rate to 6.309573444801932e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06362138>, 'val_loss': 0.17156845331192017}
Epoch 1042/4000

Epoch 01042: LearningRateScheduler reducing learning rate to 6.282391545574857e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0639702>, 'val_loss': 0.1713123470544815}
Epoch 1043/4000

Epoch 01043: LearningRateScheduler reducing learning rate to 6.25532674707607e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1591
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06299475>, 'val_loss': 0.1590515822172165}
Epoch 1044/4000

Epoch 01044: LearningRateScheduler reducing learning rate to 6.228378544830872e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06410746>, 'val_loss': 0.16524797677993774}
Epoch 1045/4000

Epoch 01045: LearningRateScheduler reducing learning rate to 6.201546436537854e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1617
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06330467>, 'val_loss': 0.16169267892837524}
Epoch 1046/4000

Epoch 01046: LearningRateScheduler reducing learning rate to 6.174829922059545e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06379812>, 'val_loss': 0.1696680337190628}
Epoch 1047/4000

Epoch 01047: LearningRateScheduler reducing learning rate to 6.148228503413087e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06413474>, 'val_loss': 0.17286443710327148}
Epoch 1048/4000

Epoch 01048: LearningRateScheduler reducing learning rate to 6.121741684760946e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064064234>, 'val_loss': 0.17295968532562256}
Epoch 1049/4000

Epoch 01049: LearningRateScheduler reducing learning rate to 6.09536897240169e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06311251>, 'val_loss': 0.16709916293621063}
Epoch 1050/4000

Epoch 01050: LearningRateScheduler reducing learning rate to 6.0691098747607604e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1750
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06380895>, 'val_loss': 0.17501960694789886}
Model saved in ./model/scPDB_2021_pdbid--1050--0.1750.
Epoch 1051/4000

Epoch 01051: LearningRateScheduler reducing learning rate to 6.042963902381326e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06368097>, 'val_loss': 0.16658306121826172}
Epoch 1052/4000

Epoch 01052: LearningRateScheduler reducing learning rate to 6.0169305679151566e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1735
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06332537>, 'val_loss': 0.1735004186630249}
Epoch 1053/4000

Epoch 01053: LearningRateScheduler reducing learning rate to 5.991009386113537e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06391881>, 'val_loss': 0.17609606683254242}
Epoch 1054/4000

Epoch 01054: LearningRateScheduler reducing learning rate to 5.9651998738182226e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06330155>, 'val_loss': 0.16650138795375824}
Epoch 1055/4000

Epoch 01055: LearningRateScheduler reducing learning rate to 5.939501549952435e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06391548>, 'val_loss': 0.17323295772075653}
Epoch 1056/4000

Epoch 01056: LearningRateScheduler reducing learning rate to 5.9139139355118933e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1628
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062800996>, 'val_loss': 0.1628446877002716}
Epoch 1057/4000

Epoch 01057: LearningRateScheduler reducing learning rate to 5.888436553555889e-05.
24/24 - 2s - loss: 0.0646 - val_loss: 0.1598
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064603426>, 'val_loss': 0.15978482365608215}
Epoch 1058/4000

Epoch 01058: LearningRateScheduler reducing learning rate to 5.863068929198389e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06358097>, 'val_loss': 0.16810151934623718}
Epoch 1059/4000

Epoch 01059: LearningRateScheduler reducing learning rate to 5.837810589599194e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06377245>, 'val_loss': 0.16870887577533722}
Epoch 1060/4000

Epoch 01060: LearningRateScheduler reducing learning rate to 5.812661063955115e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1754
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06319135>, 'val_loss': 0.17540673911571503}
Epoch 1061/4000

Epoch 01061: LearningRateScheduler reducing learning rate to 5.7876198834912056e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063463114>, 'val_loss': 0.16709044575691223}
Epoch 1062/4000

Epoch 01062: LearningRateScheduler reducing learning rate to 5.762686581452019e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06354141>, 'val_loss': 0.16841785609722137}
Epoch 1063/4000

Epoch 01063: LearningRateScheduler reducing learning rate to 5.737860693092909e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1673
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06359398>, 'val_loss': 0.16728337109088898}
Epoch 1064/4000

Epoch 01064: LearningRateScheduler reducing learning rate to 5.713141755671372e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1893
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06355129>, 'val_loss': 0.1893123835325241}
Epoch 1065/4000

Epoch 01065: LearningRateScheduler reducing learning rate to 5.688529308438414e-05.
24/24 - 2s - loss: 0.0645 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06445004>, 'val_loss': 0.1651972383260727}
Epoch 1066/4000

Epoch 01066: LearningRateScheduler reducing learning rate to 5.664022892629968e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1645
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289239>, 'val_loss': 0.16449613869190216}
Epoch 1067/4000

Epoch 01067: LearningRateScheduler reducing learning rate to 5.639622051458343e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06392608>, 'val_loss': 0.17320527136325836}
Epoch 1068/4000

Epoch 01068: LearningRateScheduler reducing learning rate to 5.6153263301037036e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063980594>, 'val_loss': 0.17138130962848663}
Epoch 1069/4000

Epoch 01069: LearningRateScheduler reducing learning rate to 5.5911352757056015e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06377513>, 'val_loss': 0.1671409159898758}
Epoch 1070/4000

Epoch 01070: LearningRateScheduler reducing learning rate to 5.5670484373545255e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1624
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063719355>, 'val_loss': 0.1624184548854828}
Epoch 1071/4000

Epoch 01071: LearningRateScheduler reducing learning rate to 5.543065366083506e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1783
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063848905>, 'val_loss': 0.1783113330602646}
Epoch 1072/4000

Epoch 01072: LearningRateScheduler reducing learning rate to 5.519185614859733e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1668
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06347269>, 'val_loss': 0.166750967502594}
Epoch 1073/4000

Epoch 01073: LearningRateScheduler reducing learning rate to 5.4954087385762434e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06304379>, 'val_loss': 0.16370776295661926}
Epoch 1074/4000

Epoch 01074: LearningRateScheduler reducing learning rate to 5.471734294043604e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1805
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063990384>, 'val_loss': 0.18049825727939606}
Epoch 1075/4000

Epoch 01075: LearningRateScheduler reducing learning rate to 5.448161839981665e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1660
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06346298>, 'val_loss': 0.1660405695438385}
Epoch 1076/4000

Epoch 01076: LearningRateScheduler reducing learning rate to 5.4246909370113244e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06357946>, 'val_loss': 0.17310625314712524}
Epoch 1077/4000

Epoch 01077: LearningRateScheduler reducing learning rate to 5.401321147646347e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06292283>, 'val_loss': 0.1643398404121399}
Epoch 1078/4000

Epoch 01078: LearningRateScheduler reducing learning rate to 5.3780520362852054e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064077236>, 'val_loss': 0.17374582588672638}
Epoch 1079/4000

Epoch 01079: LearningRateScheduler reducing learning rate to 5.354883169202961e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1585
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06390726>, 'val_loss': 0.15847821533679962}
Epoch 1080/4000

Epoch 01080: LearningRateScheduler reducing learning rate to 5.3318141145431795e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06324922>, 'val_loss': 0.1725289672613144}
Epoch 1081/4000

Epoch 01081: LearningRateScheduler reducing learning rate to 5.308844442309882e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1674
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06341544>, 'val_loss': 0.16738413274288177}
Epoch 1082/4000

Epoch 01082: LearningRateScheduler reducing learning rate to 5.285973724359531e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06338466>, 'val_loss': 0.17361940443515778}
Epoch 1083/4000

Epoch 01083: LearningRateScheduler reducing learning rate to 5.263201534393047e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062904865>, 'val_loss': 0.16767500340938568}
Epoch 1084/4000

Epoch 01084: LearningRateScheduler reducing learning rate to 5.2405274479478646e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06365542>, 'val_loss': 0.17451095581054688}
Epoch 1085/4000

Epoch 01085: LearningRateScheduler reducing learning rate to 5.217951042390022e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1646
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06337367>, 'val_loss': 0.1646161824464798}
Epoch 1086/4000

Epoch 01086: LearningRateScheduler reducing learning rate to 5.195471896906279e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1769
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06358777>, 'val_loss': 0.17685389518737793}
Epoch 1087/4000

Epoch 01087: LearningRateScheduler reducing learning rate to 5.1730895924962786e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1680
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0633717>, 'val_loss': 0.16795961558818817}
Epoch 1088/4000

Epoch 01088: LearningRateScheduler reducing learning rate to 5.150803711964733e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06324346>, 'val_loss': 0.16589829325675964}
Epoch 1089/4000

Epoch 01089: LearningRateScheduler reducing learning rate to 5.128613839913648e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06314073>, 'val_loss': 0.171153262257576}
Epoch 1090/4000

Epoch 01090: LearningRateScheduler reducing learning rate to 5.106519562734583e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063251086>, 'val_loss': 0.1721373200416565}
Epoch 1091/4000

Epoch 01091: LearningRateScheduler reducing learning rate to 5.084520468600938e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1619
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06394497>, 'val_loss': 0.16187559068202972}
Epoch 1092/4000

Epoch 01092: LearningRateScheduler reducing learning rate to 5.062616147460279e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06291946>, 'val_loss': 0.17518168687820435}
Epoch 1093/4000

Epoch 01093: LearningRateScheduler reducing learning rate to 5.040806191026694e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1804
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06313227>, 'val_loss': 0.18036378920078278}
Epoch 1094/4000

Epoch 01094: LearningRateScheduler reducing learning rate to 5.0190901927731847e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1649
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06347678>, 'val_loss': 0.16487297415733337}
Epoch 1095/4000

Epoch 01095: LearningRateScheduler reducing learning rate to 4.997467747924086e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1728
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063288234>, 'val_loss': 0.17277860641479492}
Epoch 1096/4000

Epoch 01096: LearningRateScheduler reducing learning rate to 4.975938453447522e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0638449>, 'val_loss': 0.17071568965911865}
Epoch 1097/4000

Epoch 01097: LearningRateScheduler reducing learning rate to 4.9545019080479005e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1607
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06308781>, 'val_loss': 0.16071106493473053}
Epoch 1098/4000

Epoch 01098: LearningRateScheduler reducing learning rate to 4.9331577121584205e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06326277>, 'val_loss': 0.16854380071163177}
Epoch 1099/4000

Epoch 01099: LearningRateScheduler reducing learning rate to 4.9119054679336324e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1704
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063585594>, 'val_loss': 0.17036955058574677}
Epoch 1100/4000

Epoch 01100: LearningRateScheduler reducing learning rate to 4.8907447792420234e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1790
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064097>, 'val_loss': 0.178970068693161}
Model saved in ./model/scPDB_2021_pdbid--1100--0.1790.
Epoch 1101/4000

Epoch 01101: LearningRateScheduler reducing learning rate to 4.86967525165863e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06223413>, 'val_loss': 0.17187261581420898}
Epoch 1102/4000

Epoch 01102: LearningRateScheduler reducing learning rate to 4.8486964924576855e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06391251>, 'val_loss': 0.1675504446029663}
Epoch 1103/4000

Epoch 01103: LearningRateScheduler reducing learning rate to 4.827808110605305e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06311361>, 'val_loss': 0.17389622330665588}
Epoch 1104/4000

Epoch 01104: LearningRateScheduler reducing learning rate to 4.807009716752192e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1692
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06324642>, 'val_loss': 0.16920070350170135}
Epoch 1105/4000

Epoch 01105: LearningRateScheduler reducing learning rate to 4.7863009232263824e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1776
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063370734>, 'val_loss': 0.1775994747877121}
Epoch 1106/4000

Epoch 01106: LearningRateScheduler reducing learning rate to 4.765681344026019e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1673
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06377366>, 'val_loss': 0.16728025674819946}
Epoch 1107/4000

Epoch 01107: LearningRateScheduler reducing learning rate to 4.745150594812157e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06298464>, 'val_loss': 0.1675703376531601}
Epoch 1108/4000

Epoch 01108: LearningRateScheduler reducing learning rate to 4.724708292901599e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1701
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06353201>, 'val_loss': 0.17005901038646698}
Epoch 1109/4000

Epoch 01109: LearningRateScheduler reducing learning rate to 4.704354057259761e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1660
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06290102>, 'val_loss': 0.16596025228500366}
Epoch 1110/4000

Epoch 01110: LearningRateScheduler reducing learning rate to 4.684087508493573e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06352611>, 'val_loss': 0.1757245510816574}
Epoch 1111/4000

Epoch 01111: LearningRateScheduler reducing learning rate to 4.6639082688444056e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063024715>, 'val_loss': 0.17002715170383453}
Epoch 1112/4000

Epoch 01112: LearningRateScheduler reducing learning rate to 4.643815962181029e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1650
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06342409>, 'val_loss': 0.16499638557434082}
Epoch 1113/4000

Epoch 01113: LearningRateScheduler reducing learning rate to 4.623810213992603e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06345871>, 'val_loss': 0.17075574398040771}
Epoch 1114/4000

Epoch 01114: LearningRateScheduler reducing learning rate to 4.6038906513816915e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1662
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063363105>, 'val_loss': 0.16621629893779755}
Epoch 1115/4000

Epoch 01115: LearningRateScheduler reducing learning rate to 4.584056903057321e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295123>, 'val_loss': 0.17852598428726196}
Epoch 1116/4000

Epoch 01116: LearningRateScheduler reducing learning rate to 4.5643085993280506e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1650
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06386877>, 'val_loss': 0.16501210629940033}
Epoch 1117/4000

Epoch 01117: LearningRateScheduler reducing learning rate to 4.5446453720950864e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063140415>, 'val_loss': 0.1714409589767456}
Epoch 1118/4000

Epoch 01118: LearningRateScheduler reducing learning rate to 4.5250668548454216e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06287054>, 'val_loss': 0.17633603513240814}
Epoch 1119/4000

Epoch 01119: LearningRateScheduler reducing learning rate to 4.505572682644997e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06369176>, 'val_loss': 0.16646598279476166}
Epoch 1120/4000

Epoch 01120: LearningRateScheduler reducing learning rate to 4.48616249213191e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06345885>, 'val_loss': 0.16913384199142456}
Epoch 1121/4000

Epoch 01121: LearningRateScheduler reducing learning rate to 4.4668359215096294e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1696
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06285827>, 'val_loss': 0.1695888340473175}
Epoch 1122/4000

Epoch 01122: LearningRateScheduler reducing learning rate to 4.447592610540266e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063793845>, 'val_loss': 0.16830652952194214}
Epoch 1123/4000

Epoch 01123: LearningRateScheduler reducing learning rate to 4.428432200537845e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06296665>, 'val_loss': 0.1672053188085556}
Epoch 1124/4000

Epoch 01124: LearningRateScheduler reducing learning rate to 4.409354334361626e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063396834>, 'val_loss': 0.16971707344055176}
Epoch 1125/4000

Epoch 01125: LearningRateScheduler reducing learning rate to 4.3903586564094445e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06312993>, 'val_loss': 0.17406123876571655}
Epoch 1126/4000

Epoch 01126: LearningRateScheduler reducing learning rate to 4.371444812611088e-05.
24/24 - 2s - loss: 0.0641 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06411468>, 'val_loss': 0.17330004274845123}
Epoch 1127/4000

Epoch 01127: LearningRateScheduler reducing learning rate to 4.3526124504216896e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063439704>, 'val_loss': 0.17163054645061493}
Epoch 1128/4000

Epoch 01128: LearningRateScheduler reducing learning rate to 4.3338612188151617e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06324118>, 'val_loss': 0.16366957128047943}
Epoch 1129/4000

Epoch 01129: LearningRateScheduler reducing learning rate to 4.3151907682776516e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06338195>, 'val_loss': 0.1718645542860031}
Epoch 1130/4000

Epoch 01130: LearningRateScheduler reducing learning rate to 4.296600750801024e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1647
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06273981>, 'val_loss': 0.1647152453660965}
Epoch 1131/4000

Epoch 01131: LearningRateScheduler reducing learning rate to 4.27809081987638e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063706316>, 'val_loss': 0.17939992249011993}
Epoch 1132/4000

Epoch 01132: LearningRateScheduler reducing learning rate to 4.2596606304875924e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06287352>, 'val_loss': 0.16811178624629974}
Epoch 1133/4000

Epoch 01133: LearningRateScheduler reducing learning rate to 4.241309839104881e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1812
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06386016>, 'val_loss': 0.18123005330562592}
Epoch 1134/4000

Epoch 01134: LearningRateScheduler reducing learning rate to 4.223038103678403e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1631
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06376386>, 'val_loss': 0.163075253367424}
Epoch 1135/4000

Epoch 01135: LearningRateScheduler reducing learning rate to 4.204845083631879e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627912>, 'val_loss': 0.1709633618593216}
Epoch 1136/4000

Epoch 01136: LearningRateScheduler reducing learning rate to 4.186730439856252e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1750
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06235625>, 'val_loss': 0.17501762509346008}
Epoch 1137/4000

Epoch 01137: LearningRateScheduler reducing learning rate to 4.168693834703353e-05.
24/24 - 2s - loss: 0.0642 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06423492>, 'val_loss': 0.17054402828216553}
Epoch 1138/4000

Epoch 01138: LearningRateScheduler reducing learning rate to 4.1507349319796214e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1828
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063239224>, 'val_loss': 0.1828499585390091}
Epoch 1139/4000

Epoch 01139: LearningRateScheduler reducing learning rate to 4.132853396939829e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1604
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06333823>, 'val_loss': 0.1603539139032364}
Epoch 1140/4000

Epoch 01140: LearningRateScheduler reducing learning rate to 4.1150488962808425e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06278421>, 'val_loss': 0.17138390243053436}
Epoch 1141/4000

Epoch 01141: LearningRateScheduler reducing learning rate to 4.097321098135415e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06350427>, 'val_loss': 0.17095869779586792}
Epoch 1142/4000

Epoch 01142: LearningRateScheduler reducing learning rate to 4.079669672065996e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1804
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062896095>, 'val_loss': 0.18041548132896423}
Epoch 1143/4000

Epoch 01143: LearningRateScheduler reducing learning rate to 4.062094289058573e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06307306>, 'val_loss': 0.16593877971172333}
Epoch 1144/4000

Epoch 01144: LearningRateScheduler reducing learning rate to 4.04459462151654e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1769
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06326049>, 'val_loss': 0.17691965401172638}
Epoch 1145/4000

Epoch 01145: LearningRateScheduler reducing learning rate to 4.0271703432545897e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1770
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063225694>, 'val_loss': 0.17698676884174347}
Epoch 1146/4000

Epoch 01146: LearningRateScheduler reducing learning rate to 4.0098211294926354e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063887484>, 'val_loss': 0.1689501255750656}
Epoch 1147/4000

Epoch 01147: LearningRateScheduler reducing learning rate to 3.992546656849756e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06309429>, 'val_loss': 0.16572438180446625}
Epoch 1148/4000

Epoch 01148: LearningRateScheduler reducing learning rate to 3.9753466033381675e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06291999>, 'val_loss': 0.1704978346824646}
Epoch 1149/4000

Epoch 01149: LearningRateScheduler reducing learning rate to 3.958220648357223e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063598245>, 'val_loss': 0.16651146113872528}
Epoch 1150/4000

Epoch 01150: LearningRateScheduler reducing learning rate to 3.9411684726874375e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062826626>, 'val_loss': 0.16868318617343903}
Model saved in ./model/scPDB_2021_pdbid--1150--0.1687.
Epoch 1151/4000

Epoch 01151: LearningRateScheduler reducing learning rate to 3.924189758484534e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06287097>, 'val_loss': 0.17103803157806396}
Epoch 1152/4000

Epoch 01152: LearningRateScheduler reducing learning rate to 3.907284189273524e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1768
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062856615>, 'val_loss': 0.17676274478435516}
Epoch 1153/4000

Epoch 01153: LearningRateScheduler reducing learning rate to 3.890451449942805e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1624
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06368131>, 'val_loss': 0.16237114369869232}
Epoch 1154/4000

Epoch 01154: LearningRateScheduler reducing learning rate to 3.8736912267382875e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06310594>, 'val_loss': 0.17992274463176727}
Epoch 1155/4000

Epoch 01155: LearningRateScheduler reducing learning rate to 3.8570032072575476e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1649
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063749425>, 'val_loss': 0.16492091119289398}
Epoch 1156/4000

Epoch 01156: LearningRateScheduler reducing learning rate to 3.840387080444006e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062951654>, 'val_loss': 0.17169909179210663}
Epoch 1157/4000

Epoch 01157: LearningRateScheduler reducing learning rate to 3.8238425365811254e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1777
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06266275>, 'val_loss': 0.17769402265548706}
Epoch 1158/4000

Epoch 01158: LearningRateScheduler reducing learning rate to 3.8073692672866404e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06366297>, 'val_loss': 0.17124901711940765}
Epoch 1159/4000

Epoch 01159: LearningRateScheduler reducing learning rate to 3.7909669655068084e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1696
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06335875>, 'val_loss': 0.169564351439476}
Epoch 1160/4000

Epoch 01160: LearningRateScheduler reducing learning rate to 3.774635325510689e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1746
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295091>, 'val_loss': 0.1745598465204239}
Epoch 1161/4000

Epoch 01161: LearningRateScheduler reducing learning rate to 3.758374042884441e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1662
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06308974>, 'val_loss': 0.16624456644058228}
Epoch 1162/4000

Epoch 01162: LearningRateScheduler reducing learning rate to 3.742182814525651e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1633
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289181>, 'val_loss': 0.16329258680343628}
Epoch 1163/4000

Epoch 01163: LearningRateScheduler reducing learning rate to 3.726061338637684e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268797>, 'val_loss': 0.16983464360237122}
Epoch 1164/4000

Epoch 01164: LearningRateScheduler reducing learning rate to 3.710009314724056e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0631098>, 'val_loss': 0.1730118989944458}
Epoch 1165/4000

Epoch 01165: LearningRateScheduler reducing learning rate to 3.6940264435828346e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06365688>, 'val_loss': 0.1763441115617752}
Epoch 1166/4000

Epoch 01166: LearningRateScheduler reducing learning rate to 3.678112427301061e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627884>, 'val_loss': 0.16584663093090057}
Epoch 1167/4000

Epoch 01167: LearningRateScheduler reducing learning rate to 3.662266969249198e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1664
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06291533>, 'val_loss': 0.1663786619901657}
Epoch 1168/4000

Epoch 01168: LearningRateScheduler reducing learning rate to 3.6464897740756024e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250049>, 'val_loss': 0.16902215778827667}
Epoch 1169/4000

Epoch 01169: LearningRateScheduler reducing learning rate to 3.630780547701012e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062310413>, 'val_loss': 0.17084074020385742}
Epoch 1170/4000

Epoch 01170: LearningRateScheduler reducing learning rate to 3.615138997313079e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063504875>, 'val_loss': 0.17478860914707184}
Epoch 1171/4000

Epoch 01171: LearningRateScheduler reducing learning rate to 3.5995648313608944e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06380922>, 'val_loss': 0.16587278246879578}
Epoch 1172/4000

Epoch 01172: LearningRateScheduler reducing learning rate to 3.5840577595495686e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1813
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062035486>, 'val_loss': 0.18126091361045837}
Epoch 1173/4000

Epoch 01173: LearningRateScheduler reducing learning rate to 3.56861749283481e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1679
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0635254>, 'val_loss': 0.16786082088947296}
Epoch 1174/4000

Epoch 01174: LearningRateScheduler reducing learning rate to 3.553243743417545e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06267918>, 'val_loss': 0.17049694061279297}
Epoch 1175/4000

Epoch 01175: LearningRateScheduler reducing learning rate to 3.537936224738547e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062922835>, 'val_loss': 0.1705089509487152}
Epoch 1176/4000

Epoch 01176: LearningRateScheduler reducing learning rate to 3.5226946514731004e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1775
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06310007>, 'val_loss': 0.17749536037445068}
Epoch 1177/4000

Epoch 01177: LearningRateScheduler reducing learning rate to 3.507518739525679e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1770
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06327778>, 'val_loss': 0.17700020968914032}
Epoch 1178/4000

Epoch 01178: LearningRateScheduler reducing learning rate to 3.4924082060246523e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063001275>, 'val_loss': 0.16480907797813416}
Epoch 1179/4000

Epoch 01179: LearningRateScheduler reducing learning rate to 3.477362769317012e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1659
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0626803>, 'val_loss': 0.16594763100147247}
Epoch 1180/4000

Epoch 01180: LearningRateScheduler reducing learning rate to 3.462382148963123e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1735
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06348897>, 'val_loss': 0.17354117333889008}
Epoch 1181/4000

Epoch 01181: LearningRateScheduler reducing learning rate to 3.447466065731493e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06292728>, 'val_loss': 0.17116676270961761}
Epoch 1182/4000

Epoch 01182: LearningRateScheduler reducing learning rate to 3.432614241593575e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06304012>, 'val_loss': 0.16648177802562714}
Epoch 1183/4000

Epoch 01183: LearningRateScheduler reducing learning rate to 3.4178263997185756e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063413896>, 'val_loss': 0.1699894219636917}
Epoch 1184/4000

Epoch 01184: LearningRateScheduler reducing learning rate to 3.403102264468303e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1677
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063121915>, 'val_loss': 0.16773472726345062}
Epoch 1185/4000

Epoch 01185: LearningRateScheduler reducing learning rate to 3.388441561392025e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1722
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06276953>, 'val_loss': 0.17215444147586823}
Epoch 1186/4000

Epoch 01186: LearningRateScheduler reducing learning rate to 3.373844017221353e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06331906>, 'val_loss': 0.17638246715068817}
Epoch 1187/4000

Epoch 01187: LearningRateScheduler reducing learning rate to 3.3593093598651516e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06349417>, 'val_loss': 0.1671258509159088}
Epoch 1188/4000

Epoch 01188: LearningRateScheduler reducing learning rate to 3.3448373184044636e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06256736>, 'val_loss': 0.1735835075378418}
Epoch 1189/4000

Epoch 01189: LearningRateScheduler reducing learning rate to 3.330427623087463e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1694
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06304421>, 'val_loss': 0.16936779022216797}
Epoch 1190/4000

Epoch 01190: LearningRateScheduler reducing learning rate to 3.316080005324425e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06257292>, 'val_loss': 0.1738741248846054}
Epoch 1191/4000

Epoch 01191: LearningRateScheduler reducing learning rate to 3.30179419768272e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1722
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0631942>, 'val_loss': 0.17215049266815186}
Epoch 1192/4000

Epoch 01192: LearningRateScheduler reducing learning rate to 3.287569933881829e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06283239>, 'val_loss': 0.17132245004177094}
Epoch 1193/4000

Epoch 01193: LearningRateScheduler reducing learning rate to 3.273406948788382e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1703
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063088045>, 'val_loss': 0.1702711135149002}
Epoch 1194/4000

Epoch 01194: LearningRateScheduler reducing learning rate to 3.25930497841121e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1696
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06345212>, 'val_loss': 0.1695660501718521}
Epoch 1195/4000

Epoch 01195: LearningRateScheduler reducing learning rate to 3.2452637598964356e-05.
24/24 - 2s - loss: 0.0638 - val_loss: 0.1701
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06381878>, 'val_loss': 0.17007660865783691}
Epoch 1196/4000

Epoch 01196: LearningRateScheduler reducing learning rate to 3.231283031522562e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1792
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062495608>, 'val_loss': 0.17915597558021545}
Epoch 1197/4000

Epoch 01197: LearningRateScheduler reducing learning rate to 3.217362532695597e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06277327>, 'val_loss': 0.1676148623228073}
Epoch 1198/4000

Epoch 01198: LearningRateScheduler reducing learning rate to 3.2035020039442044e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063585944>, 'val_loss': 0.1701505184173584}
Epoch 1199/4000

Epoch 01199: LearningRateScheduler reducing learning rate to 3.1897011869148564e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0628252>, 'val_loss': 0.1760939061641693}
Epoch 1200/4000

Epoch 01200: LearningRateScheduler reducing learning rate to 3.175959824367023e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06297477>, 'val_loss': 0.17307277023792267}
Model saved in ./model/scPDB_2021_pdbid--1200--0.1731.
Epoch 1201/4000

Epoch 01201: LearningRateScheduler reducing learning rate to 3.162277660168378e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1660
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261222>, 'val_loss': 0.1660485416650772}
Epoch 1202/4000

Epoch 01202: LearningRateScheduler reducing learning rate to 3.148654439290025e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1755
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063540764>, 'val_loss': 0.17550601065158844}
Epoch 1203/4000

Epoch 01203: LearningRateScheduler reducing learning rate to 3.1350899078017395e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062366612>, 'val_loss': 0.16863012313842773}
Epoch 1204/4000

Epoch 01204: LearningRateScheduler reducing learning rate to 3.12158381286724e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1680
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06341138>, 'val_loss': 0.16804175078868866}
Epoch 1205/4000

Epoch 01205: LearningRateScheduler reducing learning rate to 3.1081359027394744e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1811
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06284946>, 'val_loss': 0.18107542395591736}
Epoch 1206/4000

Epoch 01206: LearningRateScheduler reducing learning rate to 3.094745926755928e-05.
24/24 - 2s - loss: 0.0639 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06388835>, 'val_loss': 0.17251794040203094}
Epoch 1207/4000

Epoch 01207: LearningRateScheduler reducing learning rate to 3.081413635333948e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1646
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06308023>, 'val_loss': 0.1645841747522354}
Epoch 1208/4000

Epoch 01208: LearningRateScheduler reducing learning rate to 3.068138779966096e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06253182>, 'val_loss': 0.16970740258693695}
Epoch 1209/4000

Epoch 01209: LearningRateScheduler reducing learning rate to 3.054921113215513e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06333309>, 'val_loss': 0.16646404564380646}
Epoch 1210/4000

Epoch 01210: LearningRateScheduler reducing learning rate to 3.041760388711307e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06288167>, 'val_loss': 0.17192675173282623}
Epoch 1211/4000

Epoch 01211: LearningRateScheduler reducing learning rate to 3.0286563611439635e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1791
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06233113>, 'val_loss': 0.17910148203372955}
Epoch 1212/4000

Epoch 01212: LearningRateScheduler reducing learning rate to 3.0156087862607707e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06290202>, 'val_loss': 0.17167897522449493}
Epoch 1213/4000

Epoch 01213: LearningRateScheduler reducing learning rate to 3.002617420861267e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06327028>, 'val_loss': 0.17336136102676392}
Epoch 1214/4000

Epoch 01214: LearningRateScheduler reducing learning rate to 2.9896820227927092e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063089624>, 'val_loss': 0.16860869526863098}
Epoch 1215/4000

Epoch 01215: LearningRateScheduler reducing learning rate to 2.9768023509455572e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1762
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06296852>, 'val_loss': 0.17623257637023926}
Epoch 1216/4000

Epoch 01216: LearningRateScheduler reducing learning rate to 2.9639781652489813e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063053615>, 'val_loss': 0.1741533875465393}
Epoch 1217/4000

Epoch 01217: LearningRateScheduler reducing learning rate to 2.9512092266663854e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1689
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06259771>, 'val_loss': 0.168942391872406}
Epoch 1218/4000

Epoch 01218: LearningRateScheduler reducing learning rate to 2.9384952971909533e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1692
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06343403>, 'val_loss': 0.16917537152767181}
Epoch 1219/4000

Epoch 01219: LearningRateScheduler reducing learning rate to 2.925836139841215e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261999>, 'val_loss': 0.17190837860107422}
Epoch 1220/4000

Epoch 01220: LearningRateScheduler reducing learning rate to 2.9132315186566206e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0626542>, 'val_loss': 0.1748034507036209}
Epoch 1221/4000

Epoch 01221: LearningRateScheduler reducing learning rate to 2.9006811986931526e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1651
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06315082>, 'val_loss': 0.1651463508605957}
Epoch 1222/4000

Epoch 01222: LearningRateScheduler reducing learning rate to 2.888184946018939e-05.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0634835>, 'val_loss': 0.1682518869638443}
Epoch 1223/4000

Epoch 01223: LearningRateScheduler reducing learning rate to 2.8757425277098977e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1722
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06227891>, 'val_loss': 0.17216260731220245}
Epoch 1224/4000

Epoch 01224: LearningRateScheduler reducing learning rate to 2.863353711845392e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1786
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06303054>, 'val_loss': 0.17856954038143158}
Epoch 1225/4000

Epoch 01225: LearningRateScheduler reducing learning rate to 2.8510182675039083e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06298231>, 'val_loss': 0.17235875129699707}
Epoch 1226/4000

Epoch 01226: LearningRateScheduler reducing learning rate to 2.838735964758754e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1636
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063598834>, 'val_loss': 0.16357679665088654}
Epoch 1227/4000

Epoch 01227: LearningRateScheduler reducing learning rate to 2.8265065746737683e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06214444>, 'val_loss': 0.17174339294433594}
Epoch 1228/4000

Epoch 01228: LearningRateScheduler reducing learning rate to 2.8143298692990577e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06369569>, 'val_loss': 0.17049367725849152}
Epoch 1229/4000

Epoch 01229: LearningRateScheduler reducing learning rate to 2.802205621666746e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1704
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06218655>, 'val_loss': 0.17036426067352295}
Epoch 1230/4000

Epoch 01230: LearningRateScheduler reducing learning rate to 2.7901336057867433e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06293648>, 'val_loss': 0.16805680096149445}
Epoch 1231/4000

Epoch 01231: LearningRateScheduler reducing learning rate to 2.7781135966425348e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1767
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06249756>, 'val_loss': 0.1767226904630661}
Epoch 1232/4000

Epoch 01232: LearningRateScheduler reducing learning rate to 2.766145370186986e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06305957>, 'val_loss': 0.1724700629711151}
Epoch 1233/4000

Epoch 01233: LearningRateScheduler reducing learning rate to 2.754228703338166e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06313758>, 'val_loss': 0.16838385164737701}
Epoch 1234/4000

Epoch 01234: LearningRateScheduler reducing learning rate to 2.7423633739751904e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062616035>, 'val_loss': 0.1736495941877365}
Epoch 1235/4000

Epoch 01235: LearningRateScheduler reducing learning rate to 2.7305491609340808e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1775
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063223325>, 'val_loss': 0.17748908698558807}
Epoch 1236/4000

Epoch 01236: LearningRateScheduler reducing learning rate to 2.7187858440036418e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272984>, 'val_loss': 0.17432600259780884}
Epoch 1237/4000

Epoch 01237: LearningRateScheduler reducing learning rate to 2.7070732039213566e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1750
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06282402>, 'val_loss': 0.1750386506319046}
Epoch 1238/4000

Epoch 01238: LearningRateScheduler reducing learning rate to 2.6954110223693013e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1776
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06269675>, 'val_loss': 0.1776123344898224}
Epoch 1239/4000

Epoch 01239: LearningRateScheduler reducing learning rate to 2.683799081970073e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1689
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06328606>, 'val_loss': 0.16887259483337402}
Epoch 1240/4000

Epoch 01240: LearningRateScheduler reducing learning rate to 2.672237166282741e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063221835>, 'val_loss': 0.1651538610458374}
Epoch 1241/4000

Epoch 01241: LearningRateScheduler reducing learning rate to 2.6607250597988095e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06282752>, 'val_loss': 0.17451991140842438}
Epoch 1242/4000

Epoch 01242: LearningRateScheduler reducing learning rate to 2.6492625479382033e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06302095>, 'val_loss': 0.17156250774860382}
Epoch 1243/4000

Epoch 01243: LearningRateScheduler reducing learning rate to 2.6378494170452653e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06259682>, 'val_loss': 0.17089761793613434}
Epoch 1244/4000

Epoch 01244: LearningRateScheduler reducing learning rate to 2.6264854543847787e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1612
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062243693>, 'val_loss': 0.16119152307510376}
Epoch 1245/4000

Epoch 01245: LearningRateScheduler reducing learning rate to 2.615170448137996e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1723
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06357473>, 'val_loss': 0.17228631675243378}
Epoch 1246/4000

Epoch 01246: LearningRateScheduler reducing learning rate to 2.603904187398694e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06286846>, 'val_loss': 0.17308683693408966}
Epoch 1247/4000

Epoch 01247: LearningRateScheduler reducing learning rate to 2.5926864621692424e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06284555>, 'val_loss': 0.16982479393482208}
Epoch 1248/4000

Epoch 01248: LearningRateScheduler reducing learning rate to 2.5815170633566893e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1808
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06284481>, 'val_loss': 0.1807919591665268}
Epoch 1249/4000

Epoch 01249: LearningRateScheduler reducing learning rate to 2.5703957827688628e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06256431>, 'val_loss': 0.1798543930053711}
Epoch 1250/4000

Epoch 01250: LearningRateScheduler reducing learning rate to 2.5593224131104935e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06293881>, 'val_loss': 0.17520572245121002}
Model saved in ./model/scPDB_2021_pdbid--1250--0.1752.
Epoch 1251/4000

Epoch 01251: LearningRateScheduler reducing learning rate to 2.5482967479793457e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062295947>, 'val_loss': 0.17453855276107788}
Epoch 1252/4000

Epoch 01252: LearningRateScheduler reducing learning rate to 2.5373185818623756e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063407965>, 'val_loss': 0.17565704882144928}
Epoch 1253/4000

Epoch 01253: LearningRateScheduler reducing learning rate to 2.5263877101318958e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1762
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06270114>, 'val_loss': 0.17616577446460724}
Epoch 1254/4000

Epoch 01254: LearningRateScheduler reducing learning rate to 2.5155039290417645e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06307603>, 'val_loss': 0.17047691345214844}
Epoch 1255/4000

Epoch 01255: LearningRateScheduler reducing learning rate to 2.5046670357235868e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06307978>, 'val_loss': 0.17246897518634796}
Epoch 1256/4000

Epoch 01256: LearningRateScheduler reducing learning rate to 2.4938768281829317e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1781
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06332481>, 'val_loss': 0.1780921071767807}
Epoch 1257/4000

Epoch 01257: LearningRateScheduler reducing learning rate to 2.48313310529557e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261113>, 'val_loss': 0.16838155686855316}
Epoch 1258/4000

Epoch 01258: LearningRateScheduler reducing learning rate to 2.4724356668037226e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06263183>, 'val_loss': 0.17210249602794647}
Epoch 1259/4000

Epoch 01259: LearningRateScheduler reducing learning rate to 2.46178431331233e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1634
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06301444>, 'val_loss': 0.16337256133556366}
Epoch 1260/4000

Epoch 01260: LearningRateScheduler reducing learning rate to 2.451178846285335e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1703
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062752776>, 'val_loss': 0.17028872668743134}
Epoch 1261/4000

Epoch 01261: LearningRateScheduler reducing learning rate to 2.44061906804198e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0631745>, 'val_loss': 0.17292283475399017}
Epoch 1262/4000

Epoch 01262: LearningRateScheduler reducing learning rate to 2.4301047817531263e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1756
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627873>, 'val_loss': 0.17563973367214203}
Epoch 1263/4000

Epoch 01263: LearningRateScheduler reducing learning rate to 2.4196357914375814e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06257775>, 'val_loss': 0.17386382818222046}
Epoch 1264/4000

Epoch 01264: LearningRateScheduler reducing learning rate to 2.4092119019584494e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06329136>, 'val_loss': 0.16575123369693756}
Epoch 1265/4000

Epoch 01265: LearningRateScheduler reducing learning rate to 2.3988329190194904e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1780
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06291286>, 'val_loss': 0.177976593375206}
Epoch 1266/4000

Epoch 01266: LearningRateScheduler reducing learning rate to 2.388498649161502e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06308397>, 'val_loss': 0.17319810390472412}
Epoch 1267/4000

Epoch 01267: LearningRateScheduler reducing learning rate to 2.3782088997587102e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1762
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06296743>, 'val_loss': 0.1762477159500122}
Epoch 1268/4000

Epoch 01268: LearningRateScheduler reducing learning rate to 2.3679634790151838e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063275695>, 'val_loss': 0.1690884679555893}
Epoch 1269/4000

Epoch 01269: LearningRateScheduler reducing learning rate to 2.3577621959612534e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1766
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06232011>, 'val_loss': 0.1766146868467331}
Epoch 1270/4000

Epoch 01270: LearningRateScheduler reducing learning rate to 2.3476048604499555e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063089624>, 'val_loss': 0.17192576825618744}
Epoch 1271/4000

Epoch 01271: LearningRateScheduler reducing learning rate to 2.337491283153488e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06281581>, 'val_loss': 0.17067918181419373}
Epoch 1272/4000

Epoch 01272: LearningRateScheduler reducing learning rate to 2.3274212755596792e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06258298>, 'val_loss': 0.171408012509346}
Epoch 1273/4000

Epoch 01273: LearningRateScheduler reducing learning rate to 2.3173946499684777e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1720
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062821314>, 'val_loss': 0.17199312150478363}
Epoch 1274/4000

Epoch 01274: LearningRateScheduler reducing learning rate to 2.3074112194884503e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062379416>, 'val_loss': 0.17336410284042358}
Epoch 1275/4000

Epoch 01275: LearningRateScheduler reducing learning rate to 2.2974707980332993e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062903374>, 'val_loss': 0.17854994535446167}
Epoch 1276/4000

Epoch 01276: LearningRateScheduler reducing learning rate to 2.287573200318395e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1767
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0629552>, 'val_loss': 0.17667876183986664}
Epoch 1277/4000

Epoch 01277: LearningRateScheduler reducing learning rate to 2.2777182418573213e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289061>, 'val_loss': 0.17411284148693085}
Epoch 1278/4000

Epoch 01278: LearningRateScheduler reducing learning rate to 2.2679057389584378e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06292006>, 'val_loss': 0.16901636123657227}
Epoch 1279/4000

Epoch 01279: LearningRateScheduler reducing learning rate to 2.2581355087214538e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1645
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06258522>, 'val_loss': 0.16448882222175598}
Epoch 1280/4000

Epoch 01280: LearningRateScheduler reducing learning rate to 2.248407369034021e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1782
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063315384>, 'val_loss': 0.1781642585992813}
Epoch 1281/4000

Epoch 01281: LearningRateScheduler reducing learning rate to 2.2387211385683393e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1693
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295415>, 'val_loss': 0.16929513216018677}
Epoch 1282/4000

Epoch 01282: LearningRateScheduler reducing learning rate to 2.2290766367777745e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06277665>, 'val_loss': 0.1720682829618454}
Epoch 1283/4000

Epoch 01283: LearningRateScheduler reducing learning rate to 2.219473683893497e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062338546>, 'val_loss': 0.16999363899230957}
Epoch 1284/4000

Epoch 01284: LearningRateScheduler reducing learning rate to 2.2099121009211264e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1715
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06265064>, 'val_loss': 0.17152859270572662}
Epoch 1285/4000

Epoch 01285: LearningRateScheduler reducing learning rate to 2.2003917096373983e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1639
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06293159>, 'val_loss': 0.16390255093574524}
Epoch 1286/4000

Epoch 01286: LearningRateScheduler reducing learning rate to 2.1909123325868414e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1779
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062498722>, 'val_loss': 0.17791521549224854}
Epoch 1287/4000

Epoch 01287: LearningRateScheduler reducing learning rate to 2.18147379307847e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06314608>, 'val_loss': 0.17321926355361938}
Epoch 1288/4000

Epoch 01288: LearningRateScheduler reducing learning rate to 2.17207591518249e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06277717>, 'val_loss': 0.1684291809797287}
Epoch 1289/4000

Epoch 01289: LearningRateScheduler reducing learning rate to 2.16271852372702e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1863
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06255217>, 'val_loss': 0.186323881149292}
Epoch 1290/4000

Epoch 01290: LearningRateScheduler reducing learning rate to 2.1534014442948266e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1787
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06262225>, 'val_loss': 0.1787150502204895}
Epoch 1291/4000

Epoch 01291: LearningRateScheduler reducing learning rate to 2.1441245032200713e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1804
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06299767>, 'val_loss': 0.18035368621349335}
Epoch 1292/4000

Epoch 01292: LearningRateScheduler reducing learning rate to 2.1348875275850787e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1604
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062280416>, 'val_loss': 0.16038477420806885}
Epoch 1293/4000

Epoch 01293: LearningRateScheduler reducing learning rate to 2.125690345217106e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1805
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0632516>, 'val_loss': 0.18046636879444122}
Epoch 1294/4000

Epoch 01294: LearningRateScheduler reducing learning rate to 2.11653278468514e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1805
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062531054>, 'val_loss': 0.1804962009191513}
Epoch 1295/4000

Epoch 01295: LearningRateScheduler reducing learning rate to 2.1074146752966975e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06337191>, 'val_loss': 0.17567561566829681}
Epoch 1296/4000

Epoch 01296: LearningRateScheduler reducing learning rate to 2.0983358470946475e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06281578>, 'val_loss': 0.167562797665596}
Epoch 1297/4000

Epoch 01297: LearningRateScheduler reducing learning rate to 2.0892961308540385e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062378183>, 'val_loss': 0.17570002377033234}
Epoch 1298/4000

Epoch 01298: LearningRateScheduler reducing learning rate to 2.08029535807895e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1728
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06239101>, 'val_loss': 0.17284704744815826}
Epoch 1299/4000

Epoch 01299: LearningRateScheduler reducing learning rate to 2.071333360999347e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1747
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063004985>, 'val_loss': 0.1746523231267929}
Epoch 1300/4000

Epoch 01300: LearningRateScheduler reducing learning rate to 2.062409972567955e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063027866>, 'val_loss': 0.1733003854751587}
Model saved in ./model/scPDB_2021_pdbid--1300--0.1733.
Epoch 1301/4000

Epoch 01301: LearningRateScheduler reducing learning rate to 2.0535250264571452e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06214506>, 'val_loss': 0.17480678856372833}
Epoch 1302/4000

Epoch 01302: LearningRateScheduler reducing learning rate to 2.044678357055837e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06290736>, 'val_loss': 0.17169798910617828}
Epoch 1303/4000

Epoch 01303: LearningRateScheduler reducing learning rate to 2.0358697994664072e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06266881>, 'val_loss': 0.17416416108608246}
Epoch 1304/4000

Epoch 01304: LearningRateScheduler reducing learning rate to 2.027099189501619e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268649>, 'val_loss': 0.16427811980247498}
Epoch 1305/4000

Epoch 01305: LearningRateScheduler reducing learning rate to 2.0183663636815606e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063080736>, 'val_loss': 0.1763317734003067}
Epoch 1306/4000

Epoch 01306: LearningRateScheduler reducing learning rate to 2.0096711592305986e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06314527>, 'val_loss': 0.17004753649234772}
Epoch 1307/4000

Epoch 01307: LearningRateScheduler reducing learning rate to 2.001013414074344e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06236304>, 'val_loss': 0.17525070905685425}
Epoch 1308/4000

Epoch 01308: LearningRateScheduler reducing learning rate to 1.99239296683663e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06258901>, 'val_loss': 0.174290731549263}
Epoch 1309/4000

Epoch 01309: LearningRateScheduler reducing learning rate to 1.9838096568365052e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1740
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06283963>, 'val_loss': 0.17396779358386993}
Epoch 1310/4000

Epoch 01310: LearningRateScheduler reducing learning rate to 1.9752633240852394e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0625113>, 'val_loss': 0.17447130382061005}
Epoch 1311/4000

Epoch 01311: LearningRateScheduler reducing learning rate to 1.9667538092833383e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1749
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06267297>, 'val_loss': 0.174937903881073}
Epoch 1312/4000

Epoch 01312: LearningRateScheduler reducing learning rate to 1.9582809538175776e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06254128>, 'val_loss': 0.16965119540691376}
Epoch 1313/4000

Epoch 01313: LearningRateScheduler reducing learning rate to 1.9498445997580452e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1814
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06321287>, 'val_loss': 0.18137295544147491}
Epoch 1314/4000

Epoch 01314: LearningRateScheduler reducing learning rate to 1.9414445898551976e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062899224>, 'val_loss': 0.16760964691638947}
Epoch 1315/4000

Epoch 01315: LearningRateScheduler reducing learning rate to 1.9330807675369276e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268447>, 'val_loss': 0.17447113990783691}
Epoch 1316/4000

Epoch 01316: LearningRateScheduler reducing learning rate to 1.9247529769056477e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06201445>, 'val_loss': 0.17432302236557007}
Epoch 1317/4000

Epoch 01317: LearningRateScheduler reducing learning rate to 1.9164610627353855e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295483>, 'val_loss': 0.17015917599201202}
Epoch 1318/4000

Epoch 01318: LearningRateScheduler reducing learning rate to 1.9082048704688853e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1664
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06306356>, 'val_loss': 0.16635261476039886}
Epoch 1319/4000

Epoch 01319: LearningRateScheduler reducing learning rate to 1.899984246214732e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1790
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062106386>, 'val_loss': 0.17898288369178772}
Epoch 1320/4000

Epoch 01320: LearningRateScheduler reducing learning rate to 1.8917990367444804e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1777
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062584676>, 'val_loss': 0.17772573232650757}
Epoch 1321/4000

Epoch 01321: LearningRateScheduler reducing learning rate to 1.8836490894897997e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062811725>, 'val_loss': 0.17023791372776031}
Epoch 1322/4000

Epoch 01322: LearningRateScheduler reducing learning rate to 1.8755342525396304e-05.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061736222>, 'val_loss': 0.17073498666286469}
Epoch 1323/4000

Epoch 01323: LearningRateScheduler reducing learning rate to 1.8674543746373513e-05.
24/24 - 2s - loss: 0.0640 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.064011864>, 'val_loss': 0.17301855981349945}
Epoch 1324/4000

Epoch 01324: LearningRateScheduler reducing learning rate to 1.8594093051779615e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06273119>, 'val_loss': 0.16527388989925385}
Epoch 1325/4000

Epoch 01325: LearningRateScheduler reducing learning rate to 1.8513988942052713e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1811
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062859274>, 'val_loss': 0.18110209703445435}
Epoch 1326/4000

Epoch 01326: LearningRateScheduler reducing learning rate to 1.84342299240911e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0624696>, 'val_loss': 0.17000043392181396}
Epoch 1327/4000

Epoch 01327: LearningRateScheduler reducing learning rate to 1.83548145112254e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06264653>, 'val_loss': 0.17483167350292206}
Epoch 1328/4000

Epoch 01328: LearningRateScheduler reducing learning rate to 1.827574122319088e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06311452>, 'val_loss': 0.17297981679439545}
Epoch 1329/4000

Epoch 01329: LearningRateScheduler reducing learning rate to 1.819700858609983e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1689
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06218088>, 'val_loss': 0.16894318163394928}
Epoch 1330/4000

Epoch 01330: LearningRateScheduler reducing learning rate to 1.811861513241413e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062510304>, 'val_loss': 0.17309145629405975}
Epoch 1331/4000

Epoch 01331: LearningRateScheduler reducing learning rate to 1.804055940091786e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1784
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06257783>, 'val_loss': 0.17838521301746368}
Epoch 1332/4000

Epoch 01332: LearningRateScheduler reducing learning rate to 1.796283993669008e-05.
24/24 - 2s - loss: 0.0637 - val_loss: 0.1770
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06368577>, 'val_loss': 0.1770114153623581}
Epoch 1333/4000

Epoch 01333: LearningRateScheduler reducing learning rate to 1.7885455291077713e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1706
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061988547>, 'val_loss': 0.17060233652591705}
Epoch 1334/4000

Epoch 01334: LearningRateScheduler reducing learning rate to 1.7808404021668527e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062824294>, 'val_loss': 0.1794409155845642}
Epoch 1335/4000

Epoch 01335: LearningRateScheduler reducing learning rate to 1.773168469226428e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1773
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06288887>, 'val_loss': 0.17727547883987427}
Epoch 1336/4000

Epoch 01336: LearningRateScheduler reducing learning rate to 1.7655295872853916e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1667
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062738694>, 'val_loss': 0.16672195494174957}
Epoch 1337/4000

Epoch 01337: LearningRateScheduler reducing learning rate to 1.7579236139586924e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063181184>, 'val_loss': 0.1720878630876541}
Epoch 1338/4000

Epoch 01338: LearningRateScheduler reducing learning rate to 1.7503504074746806e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062493224>, 'val_loss': 0.1753462553024292}
Epoch 1339/4000

Epoch 01339: LearningRateScheduler reducing learning rate to 1.7428098266724642e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1755
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062492806>, 'val_loss': 0.1755068302154541}
Epoch 1340/4000

Epoch 01340: LearningRateScheduler reducing learning rate to 1.7353017309992776e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1621
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268603>, 'val_loss': 0.16208043694496155}
Epoch 1341/4000

Epoch 01341: LearningRateScheduler reducing learning rate to 1.7278259805078634e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1786
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06302356>, 'val_loss': 0.17856134474277496}
Epoch 1342/4000

Epoch 01342: LearningRateScheduler reducing learning rate to 1.7203824358538613e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062488373>, 'val_loss': 0.16869187355041504}
Epoch 1343/4000

Epoch 01343: LearningRateScheduler reducing learning rate to 1.712970958293213e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0625641>, 'val_loss': 0.174371138215065}
Epoch 1344/4000

Epoch 01344: LearningRateScheduler reducing learning rate to 1.7055914096795753e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062956624>, 'val_loss': 0.17161011695861816}
Epoch 1345/4000

Epoch 01345: LearningRateScheduler reducing learning rate to 1.6982436524617442e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062941976>, 'val_loss': 0.17186994850635529}
Epoch 1346/4000

Epoch 01346: LearningRateScheduler reducing learning rate to 1.6909275496810935e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1759
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062337883>, 'val_loss': 0.17587290704250336}
Epoch 1347/4000

Epoch 01347: LearningRateScheduler reducing learning rate to 1.6836429649690184e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06314201>, 'val_loss': 0.17066706717014313}
Epoch 1348/4000

Epoch 01348: LearningRateScheduler reducing learning rate to 1.676389762544397e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1740
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261647>, 'val_loss': 0.17397625744342804}
Epoch 1349/4000

Epoch 01349: LearningRateScheduler reducing learning rate to 1.669167807211058e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063359916>, 'val_loss': 0.17252208292484283}
Epoch 1350/4000

Epoch 01350: LearningRateScheduler reducing learning rate to 1.6619769643552592e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289481>, 'val_loss': 0.16987161338329315}
Model saved in ./model/scPDB_2021_pdbid--1350--0.1699.
Epoch 1351/4000

Epoch 01351: LearningRateScheduler reducing learning rate to 1.6548170999431816e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06220908>, 'val_loss': 0.17426054179668427}
Epoch 1352/4000

Epoch 01352: LearningRateScheduler reducing learning rate to 1.647688080518427e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06286926>, 'val_loss': 0.17942191660404205}
Epoch 1353/4000

Epoch 01353: LearningRateScheduler reducing learning rate to 1.640589773199538e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1692
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06274886>, 'val_loss': 0.16918252408504486}
Epoch 1354/4000

Epoch 01354: LearningRateScheduler reducing learning rate to 1.6335220456775104e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1793
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06314382>, 'val_loss': 0.17932277917861938}
Epoch 1355/4000

Epoch 01355: LearningRateScheduler reducing learning rate to 1.626484766213335e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06253953>, 'val_loss': 0.17534898221492767}
Epoch 1356/4000

Epoch 01356: LearningRateScheduler reducing learning rate to 1.6194778036355382e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250694>, 'val_loss': 0.17015761137008667}
Epoch 1357/4000

Epoch 01357: LearningRateScheduler reducing learning rate to 1.6125010273377407e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1727
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062630646>, 'val_loss': 0.17268867790699005}
Epoch 1358/4000

Epoch 01358: LearningRateScheduler reducing learning rate to 1.6055543072762187e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06257716>, 'val_loss': 0.17434975504875183}
Epoch 1359/4000

Epoch 01359: LearningRateScheduler reducing learning rate to 1.598637513967483e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06229869>, 'val_loss': 0.17327089607715607}
Epoch 1360/4000

Epoch 01360: LearningRateScheduler reducing learning rate to 1.5917505184858654e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1667
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06287341>, 'val_loss': 0.16667313873767853}
Epoch 1361/4000

Epoch 01361: LearningRateScheduler reducing learning rate to 1.5848931924611128e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1854
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06243947>, 'val_loss': 0.18541736900806427}
Epoch 1362/4000

Epoch 01362: LearningRateScheduler reducing learning rate to 1.5780654080759974e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0626081>, 'val_loss': 0.16849909722805023}
Epoch 1363/4000

Epoch 01363: LearningRateScheduler reducing learning rate to 1.5712670380639335e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1717
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06249873>, 'val_loss': 0.17170028388500214}
Epoch 1364/4000

Epoch 01364: LearningRateScheduler reducing learning rate to 1.5644979557066044e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1723
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06254015>, 'val_loss': 0.17226845026016235}
Epoch 1365/4000

Epoch 01365: LearningRateScheduler reducing learning rate to 1.5577580348316014e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062906824>, 'val_loss': 0.17848140001296997}
Epoch 1366/4000

Epoch 01366: LearningRateScheduler reducing learning rate to 1.551047149810072e-05.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06170833>, 'val_loss': 0.17714200913906097}
Epoch 1367/4000

Epoch 01367: LearningRateScheduler reducing learning rate to 1.5443651755543775e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063195966>, 'val_loss': 0.16854560375213623}
Epoch 1368/4000

Epoch 01368: LearningRateScheduler reducing learning rate to 1.5377119875157617e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06240501>, 'val_loss': 0.16967792809009552}
Epoch 1369/4000

Epoch 01369: LearningRateScheduler reducing learning rate to 1.5310874616820297e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062547915>, 'val_loss': 0.1712229996919632}
Epoch 1370/4000

Epoch 01370: LearningRateScheduler reducing learning rate to 1.524491474575236e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06240521>, 'val_loss': 0.1697504222393036}
Epoch 1371/4000

Epoch 01371: LearningRateScheduler reducing learning rate to 1.5179239032493834e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1787
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06287016>, 'val_loss': 0.17873843014240265}
Epoch 1372/4000

Epoch 01372: LearningRateScheduler reducing learning rate to 1.5113846252881314e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1772
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062283527>, 'val_loss': 0.17717717587947845}
Epoch 1373/4000

Epoch 01373: LearningRateScheduler reducing learning rate to 1.5048735188025132e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1696
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06232767>, 'val_loss': 0.1695893555879593}
Epoch 1374/4000

Epoch 01374: LearningRateScheduler reducing learning rate to 1.4983904624286652e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06260017>, 'val_loss': 0.17126576602458954}
Epoch 1375/4000

Epoch 01375: LearningRateScheduler reducing learning rate to 1.491935335325564e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1718
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268359>, 'val_loss': 0.17176848649978638}
Epoch 1376/4000

Epoch 01376: LearningRateScheduler reducing learning rate to 1.4855080171727746e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06231603>, 'val_loss': 0.16476023197174072}
Epoch 1377/4000

Epoch 01377: LearningRateScheduler reducing learning rate to 1.479108388168207e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062335547>, 'val_loss': 0.1686202436685562}
Epoch 1378/4000

Epoch 01378: LearningRateScheduler reducing learning rate to 1.4727363290258837e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1735
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0626291>, 'val_loss': 0.17346282303333282}
Epoch 1379/4000

Epoch 01379: LearningRateScheduler reducing learning rate to 1.4663917209737157e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06284566>, 'val_loss': 0.17081217467784882}
Epoch 1380/4000

Epoch 01380: LearningRateScheduler reducing learning rate to 1.4600744457512892e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06257529>, 'val_loss': 0.1732170432806015}
Epoch 1381/4000

Epoch 01381: LearningRateScheduler reducing learning rate to 1.4537843856076616e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062718205>, 'val_loss': 0.17942287027835846}
Epoch 1382/4000

Epoch 01382: LearningRateScheduler reducing learning rate to 1.447521423299165e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250664>, 'val_loss': 0.17095717787742615}
Epoch 1383/4000

Epoch 01383: LearningRateScheduler reducing learning rate to 1.4412854420872235e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06298228>, 'val_loss': 0.1685202270746231}
Epoch 1384/4000

Epoch 01384: LearningRateScheduler reducing learning rate to 1.4350763257361739e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063126534>, 'val_loss': 0.16525490581989288}
Epoch 1385/4000

Epoch 01385: LearningRateScheduler reducing learning rate to 1.4288939585111027e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1895
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06256824>, 'val_loss': 0.18947194516658783}
Epoch 1386/4000

Epoch 01386: LearningRateScheduler reducing learning rate to 1.422738225175686e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1701
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062090073>, 'val_loss': 0.17008553445339203}
Epoch 1387/4000

Epoch 01387: LearningRateScheduler reducing learning rate to 1.4166090109900434e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062565565>, 'val_loss': 0.17479097843170166}
Epoch 1388/4000

Epoch 01388: LearningRateScheduler reducing learning rate to 1.4105062017085979e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1778
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06263376>, 'val_loss': 0.17783160507678986}
Epoch 1389/4000

Epoch 01389: LearningRateScheduler reducing learning rate to 1.4044296835779475e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062159114>, 'val_loss': 0.17391474545001984}
Epoch 1390/4000

Epoch 01390: LearningRateScheduler reducing learning rate to 1.3983793433347445e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1673
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06255801>, 'val_loss': 0.16730500757694244}
Epoch 1391/4000

Epoch 01391: LearningRateScheduler reducing learning rate to 1.3923550682035842e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062823534>, 'val_loss': 0.17428860068321228}
Epoch 1392/4000

Epoch 01392: LearningRateScheduler reducing learning rate to 1.3863567458949028e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06307409>, 'val_loss': 0.17631857097148895}
Epoch 1393/4000

Epoch 01393: LearningRateScheduler reducing learning rate to 1.3803842646028849e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06309143>, 'val_loss': 0.1675180196762085}
Epoch 1394/4000

Epoch 01394: LearningRateScheduler reducing learning rate to 1.3744375130033788e-05.
24/24 - 2s - loss: 0.0616 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06160068>, 'val_loss': 0.17415691912174225}
Epoch 1395/4000

Epoch 01395: LearningRateScheduler reducing learning rate to 1.3685163802518218e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06329602>, 'val_loss': 0.17607301473617554}
Epoch 1396/4000

Epoch 01396: LearningRateScheduler reducing learning rate to 1.3626207559811741e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06201789>, 'val_loss': 0.17987482249736786}
Epoch 1397/4000

Epoch 01397: LearningRateScheduler reducing learning rate to 1.3567505302998619e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062407244>, 'val_loss': 0.16834978759288788}
Epoch 1398/4000

Epoch 01398: LearningRateScheduler reducing learning rate to 1.350905593789728e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06339276>, 'val_loss': 0.1736205816268921}
Epoch 1399/4000

Epoch 01399: LearningRateScheduler reducing learning rate to 1.3450858375039942e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1760
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06224859>, 'val_loss': 0.17595787346363068}
Epoch 1400/4000

Epoch 01400: LearningRateScheduler reducing learning rate to 1.3392911529652282e-05.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1791
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06321364>, 'val_loss': 0.17914436757564545}
Model saved in ./model/scPDB_2021_pdbid--1400--0.1791.
Epoch 1401/4000

Epoch 01401: LearningRateScheduler reducing learning rate to 1.333521432163323e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062028807>, 'val_loss': 0.1740807294845581}
Epoch 1402/4000

Epoch 01402: LearningRateScheduler reducing learning rate to 1.3277765675534862e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06262294>, 'val_loss': 0.17075850069522858}
Epoch 1403/4000

Epoch 01403: LearningRateScheduler reducing learning rate to 1.322056452054229e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1822
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062498536>, 'val_loss': 0.18220646679401398}
Epoch 1404/4000

Epoch 01404: LearningRateScheduler reducing learning rate to 1.3163609790453764e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062142354>, 'val_loss': 0.17451822757720947}
Epoch 1405/4000

Epoch 01405: LearningRateScheduler reducing learning rate to 1.3106900423660759e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06358617>, 'val_loss': 0.17635197937488556}
Epoch 1406/4000

Epoch 01406: LearningRateScheduler reducing learning rate to 1.3050435363128215e-05.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1580
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061900917>, 'val_loss': 0.15799281001091003}
Epoch 1407/4000

Epoch 01407: LearningRateScheduler reducing learning rate to 1.2994213556374819e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1784
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06326175>, 'val_loss': 0.17839236557483673}
Epoch 1408/4000

Epoch 01408: LearningRateScheduler reducing learning rate to 1.2938233955453386e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062325243>, 'val_loss': 0.17433692514896393}
Epoch 1409/4000

Epoch 01409: LearningRateScheduler reducing learning rate to 1.2882495516931332e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1813
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06280665>, 'val_loss': 0.1813335418701172}
Epoch 1410/4000

Epoch 01410: LearningRateScheduler reducing learning rate to 1.2826997201871227e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062071417>, 'val_loss': 0.17160116136074066}
Epoch 1411/4000

Epoch 01411: LearningRateScheduler reducing learning rate to 1.2771737975811423e-05.
24/24 - 2s - loss: 0.0636 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06355107>, 'val_loss': 0.1701759546995163}
Epoch 1412/4000

Epoch 01412: LearningRateScheduler reducing learning rate to 1.2716716808746772e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1754
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062228326>, 'val_loss': 0.1753578782081604}
Epoch 1413/4000

Epoch 01413: LearningRateScheduler reducing learning rate to 1.2661932675109436e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1845
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06237047>, 'val_loss': 0.18450528383255005}
Epoch 1414/4000

Epoch 01414: LearningRateScheduler reducing learning rate to 1.260738455374976e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062566645>, 'val_loss': 0.1761428862810135}
Epoch 1415/4000

Epoch 01415: LearningRateScheduler reducing learning rate to 1.2553071427917244e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062610954>, 'val_loss': 0.1683223843574524}
Epoch 1416/4000

Epoch 01416: LearningRateScheduler reducing learning rate to 1.2498992285241594e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1727
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06280718>, 'val_loss': 0.17267926037311554}
Epoch 1417/4000

Epoch 01417: LearningRateScheduler reducing learning rate to 1.2445146117713845e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06240571>, 'val_loss': 0.1793600171804428}
Epoch 1418/4000

Epoch 01418: LearningRateScheduler reducing learning rate to 1.2391531921667578e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0626828>, 'val_loss': 0.16986195743083954}
Epoch 1419/4000

Epoch 01419: LearningRateScheduler reducing learning rate to 1.2338148697760207e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272867>, 'val_loss': 0.17850041389465332}
Epoch 1420/4000

Epoch 01420: LearningRateScheduler reducing learning rate to 1.2284995450954356e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062106136>, 'val_loss': 0.1736028641462326}
Epoch 1421/4000

Epoch 01421: LearningRateScheduler reducing learning rate to 1.2232071190499312e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1762
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062731035>, 'val_loss': 0.17618797719478607}
Epoch 1422/4000

Epoch 01422: LearningRateScheduler reducing learning rate to 1.2179374929912552e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1720
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062887534>, 'val_loss': 0.17204593122005463}
Epoch 1423/4000

Epoch 01423: LearningRateScheduler reducing learning rate to 1.2126905686961367e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1774
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0621127>, 'val_loss': 0.17741042375564575}
Epoch 1424/4000

Epoch 01424: LearningRateScheduler reducing learning rate to 1.207466248364454e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1746
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295263>, 'val_loss': 0.17457552254199982}
Epoch 1425/4000

Epoch 01425: LearningRateScheduler reducing learning rate to 1.2022644346174125e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062017065>, 'val_loss': 0.17211854457855225}
Epoch 1426/4000

Epoch 01426: LearningRateScheduler reducing learning rate to 1.1970850304957296e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1823
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06295099>, 'val_loss': 0.18233425915241241}
Epoch 1427/4000

Epoch 01427: LearningRateScheduler reducing learning rate to 1.1919279394578271e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1629
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0623735>, 'val_loss': 0.16291287541389465}
Epoch 1428/4000

Epoch 01428: LearningRateScheduler reducing learning rate to 1.1867930653780316e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06251073>, 'val_loss': 0.1770995408296585}
Epoch 1429/4000

Epoch 01429: LearningRateScheduler reducing learning rate to 1.1816803125447834e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062493805>, 'val_loss': 0.17092685401439667}
Epoch 1430/4000

Epoch 01430: LearningRateScheduler reducing learning rate to 1.1765895856588519e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1751
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062372852>, 'val_loss': 0.175106942653656}
Epoch 1431/4000

Epoch 01431: LearningRateScheduler reducing learning rate to 1.1715207898315598e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062247183>, 'val_loss': 0.17313528060913086}
Epoch 1432/4000

Epoch 01432: LearningRateScheduler reducing learning rate to 1.1664738305830134e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06292607>, 'val_loss': 0.1731836050748825}
Epoch 1433/4000

Epoch 01433: LearningRateScheduler reducing learning rate to 1.1614486138403426e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1693
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062234372>, 'val_loss': 0.16926367580890656}
Epoch 1434/4000

Epoch 01434: LearningRateScheduler reducing learning rate to 1.1564450459359473e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06265577>, 'val_loss': 0.17049789428710938}
Epoch 1435/4000

Epoch 01435: LearningRateScheduler reducing learning rate to 1.151463033605751e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1769
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06260363>, 'val_loss': 0.17692583799362183}
Epoch 1436/4000

Epoch 01436: LearningRateScheduler reducing learning rate to 1.1465024839874626e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1759
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06266793>, 'val_loss': 0.17594486474990845}
Epoch 1437/4000

Epoch 01437: LearningRateScheduler reducing learning rate to 1.1415633046188456e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1723
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062885776>, 'val_loss': 0.17226572334766388}
Epoch 1438/4000

Epoch 01438: LearningRateScheduler reducing learning rate to 1.1366454034359944e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1795
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06212838>, 'val_loss': 0.17945073544979095}
Epoch 1439/4000

Epoch 01439: LearningRateScheduler reducing learning rate to 1.1317486887716188e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06263467>, 'val_loss': 0.17406709492206573}
Epoch 1440/4000

Epoch 01440: LearningRateScheduler reducing learning rate to 1.1268730693533348e-05.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272309>, 'val_loss': 0.1686038374900818}
Epoch 1441/4000

Epoch 01441: LearningRateScheduler reducing learning rate to 1.1220184543019633e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06281912>, 'val_loss': 0.1706531047821045}
Epoch 1442/4000

Epoch 01442: LearningRateScheduler reducing learning rate to 1.1171847531298373e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1891
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062090795>, 'val_loss': 0.18905746936798096}
Epoch 1443/4000

Epoch 01443: LearningRateScheduler reducing learning rate to 1.1123718757391131e-05.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063378744>, 'val_loss': 0.1736595630645752}
Epoch 1444/4000

Epoch 01444: LearningRateScheduler reducing learning rate to 1.1075797324200929e-05.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06169147>, 'val_loss': 0.17437125742435455}
Epoch 1445/4000

Epoch 01445: LearningRateScheduler reducing learning rate to 1.102808233849552e-05.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1800
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06288293>, 'val_loss': 0.17997044324874878}
Epoch 1446/4000

Epoch 01446: LearningRateScheduler reducing learning rate to 1.0980572910890735e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1775
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06263526>, 'val_loss': 0.17745955288410187}
Epoch 1447/4000

Epoch 01447: LearningRateScheduler reducing learning rate to 1.0933268155833913e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1760
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06279414>, 'val_loss': 0.17602963745594025}
Epoch 1448/4000

Epoch 01448: LearningRateScheduler reducing learning rate to 1.0886167191587383e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062083058>, 'val_loss': 0.17706407606601715}
Epoch 1449/4000

Epoch 01449: LearningRateScheduler reducing learning rate to 1.0839269140212037e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06236958>, 'val_loss': 0.17073112726211548}
Epoch 1450/4000

Epoch 01450: LearningRateScheduler reducing learning rate to 1.0792573127550961e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1797
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06313532>, 'val_loss': 0.17974519729614258}
Model saved in ./model/scPDB_2021_pdbid--1450--0.1797.
Epoch 1451/4000

Epoch 01451: LearningRateScheduler reducing learning rate to 1.0746078283213167e-05.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061690737>, 'val_loss': 0.16858012974262238}
Epoch 1452/4000

Epoch 01452: LearningRateScheduler reducing learning rate to 1.0699783740557322e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06259292>, 'val_loss': 0.17361204326152802}
Epoch 1453/4000

Epoch 01453: LearningRateScheduler reducing learning rate to 1.0653688636675625e-05.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06300426>, 'val_loss': 0.17482584714889526}
Epoch 1454/4000

Epoch 01454: LearningRateScheduler reducing learning rate to 1.0607792112377721e-05.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1817
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0623334>, 'val_loss': 0.18168124556541443}
Epoch 1455/4000

Epoch 01455: LearningRateScheduler reducing learning rate to 1.0562093312174678e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1688
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062759906>, 'val_loss': 0.16876693069934845}
Epoch 1456/4000

Epoch 01456: LearningRateScheduler reducing learning rate to 1.0516591384263051e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1789
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06251928>, 'val_loss': 0.17892687022686005}
Epoch 1457/4000

Epoch 01457: LearningRateScheduler reducing learning rate to 1.0471285480508989e-05.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062526345>, 'val_loss': 0.1665937602519989}
Epoch 1458/4000

Epoch 01458: LearningRateScheduler reducing learning rate to 1.0426174756432446e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06255372>, 'val_loss': 0.1751672476530075}
Epoch 1459/4000

Epoch 01459: LearningRateScheduler reducing learning rate to 1.0381258371191425e-05.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1685
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063301526>, 'val_loss': 0.1684718132019043}
Epoch 1460/4000

Epoch 01460: LearningRateScheduler reducing learning rate to 1.0336535487566314e-05.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1622
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06202938>, 'val_loss': 0.16223077476024628}
Epoch 1461/4000

Epoch 01461: LearningRateScheduler reducing learning rate to 1.0292005271944276e-05.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06242609>, 'val_loss': 0.17609846591949463}
Epoch 1462/4000

Epoch 01462: LearningRateScheduler reducing learning rate to 1.0247666894303708e-05.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06260031>, 'val_loss': 0.16843675076961517}
Epoch 1463/4000

Epoch 01463: LearningRateScheduler reducing learning rate to 1.020351952819878e-05.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1825
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061781805>, 'val_loss': 0.18250633776187897}
Epoch 1464/4000

Epoch 01464: LearningRateScheduler reducing learning rate to 1.015956235074402e-05.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06311587>, 'val_loss': 0.17327482998371124}
Epoch 1465/4000

Epoch 01465: LearningRateScheduler reducing learning rate to 1.0115794542598982e-05.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1747
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06217289>, 'val_loss': 0.17472101747989655}
Epoch 1466/4000

Epoch 01466: LearningRateScheduler reducing learning rate to 1.007221528795297e-05.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1781
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06284844>, 'val_loss': 0.17811669409275055}
Epoch 1467/4000

Epoch 01467: LearningRateScheduler reducing learning rate to 1.0028823774509838e-05.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062137634>, 'val_loss': 0.1711902618408203}
Epoch 1468/4000

Epoch 01468: LearningRateScheduler reducing learning rate to 9.98561919347284e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06301663>, 'val_loss': 0.1719462275505066}
Epoch 1469/4000

Epoch 01469: LearningRateScheduler reducing learning rate to 9.942600739529562e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1797
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250777>, 'val_loss': 0.17974434792995453}
Epoch 1470/4000

Epoch 01470: LearningRateScheduler reducing learning rate to 9.89976761083691e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06217293>, 'val_loss': 0.17023980617523193}
Epoch 1471/4000

Epoch 01471: LearningRateScheduler reducing learning rate to 9.857119009006159e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062682286>, 'val_loss': 0.16909344494342804}
Epoch 1472/4000

Epoch 01472: LearningRateScheduler reducing learning rate to 9.814654139088075e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06269368>, 'val_loss': 0.1711587905883789}
Epoch 1473/4000

Epoch 01473: LearningRateScheduler reducing learning rate to 9.772372209558104e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1805
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062290248>, 'val_loss': 0.18050415813922882}
Epoch 1474/4000

Epoch 01474: LearningRateScheduler reducing learning rate to 9.730272432301604e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1772
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06301033>, 'val_loss': 0.17717917263507843}
Epoch 1475/4000

Epoch 01475: LearningRateScheduler reducing learning rate to 9.688354022599167e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06233849>, 'val_loss': 0.16752368211746216}
Epoch 1476/4000

Epoch 01476: LearningRateScheduler reducing learning rate to 9.64661619911199e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06253404>, 'val_loss': 0.175174281001091}
Epoch 1477/4000

Epoch 01477: LearningRateScheduler reducing learning rate to 9.605058183867303e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1773
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06198427>, 'val_loss': 0.1772710531949997}
Epoch 1478/4000

Epoch 01478: LearningRateScheduler reducing learning rate to 9.563679202243884e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062558666>, 'val_loss': 0.17944566905498505}
Epoch 1479/4000

Epoch 01479: LearningRateScheduler reducing learning rate to 9.522478482957599e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06270974>, 'val_loss': 0.17242856323719025}
Epoch 1480/4000

Epoch 01480: LearningRateScheduler reducing learning rate to 9.481455258047047e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06241096>, 'val_loss': 0.17370641231536865}
Epoch 1481/4000

Epoch 01481: LearningRateScheduler reducing learning rate to 9.440608762859232e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06206842>, 'val_loss': 0.1753155142068863}
Epoch 1482/4000

Epoch 01482: LearningRateScheduler reducing learning rate to 9.399938236035314e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062016156>, 'val_loss': 0.1709788590669632}
Epoch 1483/4000

Epoch 01483: LearningRateScheduler reducing learning rate to 9.359442919496422e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06311751>, 'val_loss': 0.17524652183055878}
Epoch 1484/4000

Epoch 01484: LearningRateScheduler reducing learning rate to 9.319122058429512e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06242157>, 'val_loss': 0.1702171415090561}
Epoch 1485/4000

Epoch 01485: LearningRateScheduler reducing learning rate to 9.27897490127331e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062397305>, 'val_loss': 0.1723758578300476}
Epoch 1486/4000

Epoch 01486: LearningRateScheduler reducing learning rate to 9.239000699704303e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1711
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062421784>, 'val_loss': 0.1711171269416809}
Epoch 1487/4000

Epoch 01487: LearningRateScheduler reducing learning rate to 9.199198708622774e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1821
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06266477>, 'val_loss': 0.18209554255008698}
Epoch 1488/4000

Epoch 01488: LearningRateScheduler reducing learning rate to 9.15956818613894e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0624342>, 'val_loss': 0.1741732358932495}
Epoch 1489/4000

Epoch 01489: LearningRateScheduler reducing learning rate to 9.120108393559096e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06239927>, 'val_loss': 0.17337912321090698}
Epoch 1490/4000

Epoch 01490: LearningRateScheduler reducing learning rate to 9.080818595371873e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06230242>, 'val_loss': 0.1689811497926712}
Epoch 1491/4000

Epoch 01491: LearningRateScheduler reducing learning rate to 9.041698059234504e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1789
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06235944>, 'val_loss': 0.17886964976787567}
Epoch 1492/4000

Epoch 01492: LearningRateScheduler reducing learning rate to 9.00274605595919e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062554754>, 'val_loss': 0.17375726997852325}
Epoch 1493/4000

Epoch 01493: LearningRateScheduler reducing learning rate to 8.963961859499501e-06.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1773
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06332446>, 'val_loss': 0.17728811502456665}
Epoch 1494/4000

Epoch 01494: LearningRateScheduler reducing learning rate to 8.925344746936842e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062135387>, 'val_loss': 0.17246967554092407}
Epoch 1495/4000

Epoch 01495: LearningRateScheduler reducing learning rate to 8.886893998466989e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1741
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062269412>, 'val_loss': 0.17411063611507416}
Epoch 1496/4000

Epoch 01496: LearningRateScheduler reducing learning rate to 8.848608897386654e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06264342>, 'val_loss': 0.1763034611940384}
Epoch 1497/4000

Epoch 01497: LearningRateScheduler reducing learning rate to 8.810488730080142e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06254289>, 'val_loss': 0.1743255853652954}
Epoch 1498/4000

Epoch 01498: LearningRateScheduler reducing learning rate to 8.772532786006041e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1831
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061815117>, 'val_loss': 0.18306352198123932}
Epoch 1499/4000

Epoch 01499: LearningRateScheduler reducing learning rate to 8.734740357683976e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1618
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062838905>, 'val_loss': 0.16178706288337708}
Epoch 1500/4000

Epoch 01500: LearningRateScheduler reducing learning rate to 8.697110740681444e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06281064>, 'val_loss': 0.1798776537179947}
Model saved in ./model/scPDB_2021_pdbid--1500--0.1799.
Epoch 1501/4000

Epoch 01501: LearningRateScheduler reducing learning rate to 8.659643233600647e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1727
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062190507>, 'val_loss': 0.17274148762226105}
Epoch 1502/4000

Epoch 01502: LearningRateScheduler reducing learning rate to 8.622337138065444e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06271935>, 'val_loss': 0.1690501719713211}
Epoch 1503/4000

Epoch 01503: LearningRateScheduler reducing learning rate to 8.585191758708325e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06273466>, 'val_loss': 0.17375870048999786}
Epoch 1504/4000

Epoch 01504: LearningRateScheduler reducing learning rate to 8.548206403157453e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1649
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062211107>, 'val_loss': 0.16487626731395721}
Epoch 1505/4000

Epoch 01505: LearningRateScheduler reducing learning rate to 8.511380382023758e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1866
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062499855>, 'val_loss': 0.18658801913261414}
Epoch 1506/4000

Epoch 01506: LearningRateScheduler reducing learning rate to 8.474713008888087e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1726
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062149193>, 'val_loss': 0.1726447343826294}
Epoch 1507/4000

Epoch 01507: LearningRateScheduler reducing learning rate to 8.438203600288402e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1762
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06297145>, 'val_loss': 0.17616605758666992}
Epoch 1508/4000

Epoch 01508: LearningRateScheduler reducing learning rate to 8.401851475707057e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1688
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061973732>, 'val_loss': 0.1687839925289154}
Epoch 1509/4000

Epoch 01509: LearningRateScheduler reducing learning rate to 8.365655957558096e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0628617>, 'val_loss': 0.17516537010669708}
Epoch 1510/4000

Epoch 01510: LearningRateScheduler reducing learning rate to 8.329616371174635e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062495682>, 'val_loss': 0.17289955914020538}
Epoch 1511/4000

Epoch 01511: LearningRateScheduler reducing learning rate to 8.29373204479628e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1641
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06294314>, 'val_loss': 0.16409866511821747}
Epoch 1512/4000

Epoch 01512: LearningRateScheduler reducing learning rate to 8.25800230955661e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1791
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261075>, 'val_loss': 0.17908255755901337}
Epoch 1513/4000

Epoch 01513: LearningRateScheduler reducing learning rate to 8.222426499470708e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1758
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062213387>, 'val_loss': 0.1757526844739914}
Epoch 1514/4000

Epoch 01514: LearningRateScheduler reducing learning rate to 8.187003951422742e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1665
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062658556>, 'val_loss': 0.16651050746440887}
Epoch 1515/4000

Epoch 01515: LearningRateScheduler reducing learning rate to 8.151734005153621e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06212685>, 'val_loss': 0.17071853578090668}
Epoch 1516/4000

Epoch 01516: LearningRateScheduler reducing learning rate to 8.116616003248664e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06309009>, 'val_loss': 0.17448067665100098}
Epoch 1517/4000

Epoch 01517: LearningRateScheduler reducing learning rate to 8.08164929112537e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1679
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06167533>, 'val_loss': 0.16792407631874084}
Epoch 1518/4000

Epoch 01518: LearningRateScheduler reducing learning rate to 8.046833217021196e-06.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06331701>, 'val_loss': 0.17643283307552338}
Epoch 1519/4000

Epoch 01519: LearningRateScheduler reducing learning rate to 8.01216713198143e-06.
24/24 - 2s - loss: 0.0614 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061360553>, 'val_loss': 0.17714685201644897}
Epoch 1520/4000

Epoch 01520: LearningRateScheduler reducing learning rate to 7.977650389847075e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1630
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06279997>, 'val_loss': 0.16303731501102448}
Epoch 1521/4000

Epoch 01521: LearningRateScheduler reducing learning rate to 7.943282347242812e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1778
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06232838>, 'val_loss': 0.1777917593717575}
Epoch 1522/4000

Epoch 01522: LearningRateScheduler reducing learning rate to 7.909062363565018e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627771>, 'val_loss': 0.1737423688173294}
Epoch 1523/4000

Epoch 01523: LearningRateScheduler reducing learning rate to 7.874989800969808e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062670715>, 'val_loss': 0.1734037846326828}
Epoch 1524/4000

Epoch 01524: LearningRateScheduler reducing learning rate to 7.841064024361159e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06251295>, 'val_loss': 0.1799411028623581}
Epoch 1525/4000

Epoch 01525: LearningRateScheduler reducing learning rate to 7.807284401379066e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1756
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06278804>, 'val_loss': 0.17556707561016083}
Epoch 1526/4000

Epoch 01526: LearningRateScheduler reducing learning rate to 7.773650302387755e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1645
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061946295>, 'val_loss': 0.16449780762195587}
Epoch 1527/4000

Epoch 01527: LearningRateScheduler reducing learning rate to 7.740161100463955e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272123>, 'val_loss': 0.17155826091766357}
Epoch 1528/4000

Epoch 01528: LearningRateScheduler reducing learning rate to 7.706816171385193e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062326603>, 'val_loss': 0.1708175390958786}
Epoch 1529/4000

Epoch 01529: LearningRateScheduler reducing learning rate to 7.673614893618188e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062690936>, 'val_loss': 0.1737576276063919}
Epoch 1530/4000

Epoch 01530: LearningRateScheduler reducing learning rate to 7.640556648307238e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06209645>, 'val_loss': 0.174386665225029}
Epoch 1531/4000

Epoch 01531: LearningRateScheduler reducing learning rate to 7.6076408192627e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1669
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062612474>, 'val_loss': 0.16688084602355957}
Epoch 1532/4000

Epoch 01532: LearningRateScheduler reducing learning rate to 7.574866792949503e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1758
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061869107>, 'val_loss': 0.17578963935375214}
Epoch 1533/4000

Epoch 01533: LearningRateScheduler reducing learning rate to 7.5422339584757065e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062618144>, 'val_loss': 0.17638646066188812}
Epoch 1534/4000

Epoch 01534: LearningRateScheduler reducing learning rate to 7.5097417075811206e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1821
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061902862>, 'val_loss': 0.1820744127035141}
Epoch 1535/4000

Epoch 01535: LearningRateScheduler reducing learning rate to 7.477389434625965e-06.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1688
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06330338>, 'val_loss': 0.16881461441516876}
Epoch 1536/4000

Epoch 01536: LearningRateScheduler reducing learning rate to 7.445176536579575e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06283764>, 'val_loss': 0.17050759494304657}
Epoch 1537/4000

Epoch 01537: LearningRateScheduler reducing learning rate to 7.413102413009175e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250759>, 'val_loss': 0.17078417539596558}
Epoch 1538/4000

Epoch 01538: LearningRateScheduler reducing learning rate to 7.3811664660686705e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1755
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06301502>, 'val_loss': 0.17548155784606934}
Epoch 1539/4000

Epoch 01539: LearningRateScheduler reducing learning rate to 7.349368100487516e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1784
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062096257>, 'val_loss': 0.1784038096666336}
Epoch 1540/4000

Epoch 01540: LearningRateScheduler reducing learning rate to 7.317706723559617e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06292834>, 'val_loss': 0.17386867105960846}
Epoch 1541/4000

Epoch 01541: LearningRateScheduler reducing learning rate to 7.286181745132278e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06216757>, 'val_loss': 0.17213696241378784}
Epoch 1542/4000

Epoch 01542: LearningRateScheduler reducing learning rate to 7.254792577595206e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1796
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06173396>, 'val_loss': 0.1795828938484192}
Epoch 1543/4000

Epoch 01543: LearningRateScheduler reducing learning rate to 7.223538635869557e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06254703>, 'val_loss': 0.1736798733472824}
Epoch 1544/4000

Epoch 01544: LearningRateScheduler reducing learning rate to 7.192419337397034e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06275072>, 'val_loss': 0.17089492082595825}
Epoch 1545/4000

Epoch 01545: LearningRateScheduler reducing learning rate to 7.161434102129021e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1700
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06251814>, 'val_loss': 0.1700359582901001}
Epoch 1546/4000

Epoch 01546: LearningRateScheduler reducing learning rate to 7.130582352515775e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06237952>, 'val_loss': 0.17438654601573944}
Epoch 1547/4000

Epoch 01547: LearningRateScheduler reducing learning rate to 7.0998635134956545e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06276556>, 'val_loss': 0.1716311275959015}
Epoch 1548/4000

Epoch 01548: LearningRateScheduler reducing learning rate to 7.06927701248443e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1765
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06192855>, 'val_loss': 0.17646966874599457}
Epoch 1549/4000

Epoch 01549: LearningRateScheduler reducing learning rate to 7.038822279364564e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06210262>, 'val_loss': 0.17516584694385529}
Epoch 1550/4000

Epoch 01550: LearningRateScheduler reducing learning rate to 7.0084987464746165e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1705
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06297191>, 'val_loss': 0.17046187818050385}
Model saved in ./model/scPDB_2021_pdbid--1550--0.1705.
Epoch 1551/4000

Epoch 01551: LearningRateScheduler reducing learning rate to 6.978305848598658e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1711
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06256784>, 'val_loss': 0.17111806571483612}
Epoch 1552/4000

Epoch 01552: LearningRateScheduler reducing learning rate to 6.948243022955731e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06252593>, 'val_loss': 0.17163872718811035}
Epoch 1553/4000

Epoch 01553: LearningRateScheduler reducing learning rate to 6.91830970918936e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1722
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06200935>, 'val_loss': 0.17220470309257507}
Epoch 1554/4000

Epoch 01554: LearningRateScheduler reducing learning rate to 6.88850534935711e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1731
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062164295>, 'val_loss': 0.1731298416852951}
Epoch 1555/4000

Epoch 01555: LearningRateScheduler reducing learning rate to 6.858829387920183e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1661
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062389385>, 'val_loss': 0.16614824533462524}
Epoch 1556/4000

Epoch 01556: LearningRateScheduler reducing learning rate to 6.829281271733067e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1900
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062359326>, 'val_loss': 0.1899615377187729}
Epoch 1557/4000

Epoch 01557: LearningRateScheduler reducing learning rate to 6.79986045003322e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06211503>, 'val_loss': 0.170840322971344}
Epoch 1558/4000

Epoch 01558: LearningRateScheduler reducing learning rate to 6.77056637443081e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1775
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06225985>, 'val_loss': 0.1774592399597168}
Epoch 1559/4000

Epoch 01559: LearningRateScheduler reducing learning rate to 6.74139849889849e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1841
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06237563>, 'val_loss': 0.18409299850463867}
Epoch 1560/4000

Epoch 01560: LearningRateScheduler reducing learning rate to 6.712356279761223e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627609>, 'val_loss': 0.16981200873851776}
Epoch 1561/4000

Epoch 01561: LearningRateScheduler reducing learning rate to 6.683439175686142e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1758
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06260791>, 'val_loss': 0.1758248656988144}
Epoch 1562/4000

Epoch 01562: LearningRateScheduler reducing learning rate to 6.654646647672469e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1703
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062338743>, 'val_loss': 0.17033007740974426}
Epoch 1563/4000

Epoch 01563: LearningRateScheduler reducing learning rate to 6.625978159041458e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1792
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061719254>, 'val_loss': 0.17924420535564423}
Epoch 1564/4000

Epoch 01564: LearningRateScheduler reducing learning rate to 6.5974331754264e-06.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1749
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06320781>, 'val_loss': 0.17493557929992676}
Epoch 1565/4000

Epoch 01565: LearningRateScheduler reducing learning rate to 6.56901116476266e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1704
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0625459>, 'val_loss': 0.17042595148086548}
Epoch 1566/4000

Epoch 01566: LearningRateScheduler reducing learning rate to 6.5407115972777586e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0622964>, 'val_loss': 0.17240695655345917}
Epoch 1567/4000

Epoch 01567: LearningRateScheduler reducing learning rate to 6.512533945481496e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06225275>, 'val_loss': 0.1762651950120926}
Epoch 1568/4000

Epoch 01568: LearningRateScheduler reducing learning rate to 6.484477684156124e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06267072>, 'val_loss': 0.1724775731563568}
Epoch 1569/4000

Epoch 01569: LearningRateScheduler reducing learning rate to 6.456542290346552e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06198914>, 'val_loss': 0.17387379705905914}
Epoch 1570/4000

Epoch 01570: LearningRateScheduler reducing learning rate to 6.4287272433506045e-06.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063237295>, 'val_loss': 0.1721419095993042}
Epoch 1571/4000

Epoch 01571: LearningRateScheduler reducing learning rate to 6.401032024709306e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1760
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061983794>, 'val_loss': 0.1760321408510208}
Epoch 1572/4000

Epoch 01572: LearningRateScheduler reducing learning rate to 6.37345611819723e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06267882>, 'val_loss': 0.1743287295103073}
Epoch 1573/4000

Epoch 01573: LearningRateScheduler reducing learning rate to 6.345999009812866e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1786
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063117854>, 'val_loss': 0.1786014437675476}
Epoch 1574/4000

Epoch 01574: LearningRateScheduler reducing learning rate to 6.318660187769046e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1637
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06189765>, 'val_loss': 0.16367371380329132}
Epoch 1575/4000

Epoch 01575: LearningRateScheduler reducing learning rate to 6.291439142483398e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06190135>, 'val_loss': 0.1744426041841507}
Epoch 1576/4000

Epoch 01576: LearningRateScheduler reducing learning rate to 6.264335366568854e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1669
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06277693>, 'val_loss': 0.1669219583272934}
Epoch 1577/4000

Epoch 01577: LearningRateScheduler reducing learning rate to 6.237348354824191e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06274723>, 'val_loss': 0.17639271914958954}
Epoch 1578/4000

Epoch 01578: LearningRateScheduler reducing learning rate to 6.2104776042246125e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1706
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06239915>, 'val_loss': 0.1705956906080246}
Epoch 1579/4000

Epoch 01579: LearningRateScheduler reducing learning rate to 6.183722613912371e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1772
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289584>, 'val_loss': 0.17722107470035553}
Epoch 1580/4000

Epoch 01580: LearningRateScheduler reducing learning rate to 6.1570828851874394e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062460963>, 'val_loss': 0.17163048684597015}
Epoch 1581/4000

Epoch 01581: LearningRateScheduler reducing learning rate to 6.130557921498206e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1767
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06256578>, 'val_loss': 0.1767459362745285}
Epoch 1582/4000

Epoch 01582: LearningRateScheduler reducing learning rate to 6.104147228432227e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289565>, 'val_loss': 0.17072445154190063}
Epoch 1583/4000

Epoch 01583: LearningRateScheduler reducing learning rate to 6.077850313707005e-06.
24/24 - 2s - loss: 0.0615 - val_loss: 0.1780
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061508853>, 'val_loss': 0.1780097931623459}
Epoch 1584/4000

Epoch 01584: LearningRateScheduler reducing learning rate to 6.051666687160817e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062349897>, 'val_loss': 0.17119698226451874}
Epoch 1585/4000

Epoch 01585: LearningRateScheduler reducing learning rate to 6.025595860743577e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063134946>, 'val_loss': 0.17104683816432953}
Epoch 1586/4000

Epoch 01586: LearningRateScheduler reducing learning rate to 5.9996373485077375e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1820
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06213081>, 'val_loss': 0.1820395439863205}
Epoch 1587/4000

Epoch 01587: LearningRateScheduler reducing learning rate to 5.973790666599233e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06276401>, 'val_loss': 0.1721237450838089}
Epoch 1588/4000

Epoch 01588: LearningRateScheduler reducing learning rate to 5.948055333248462e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061984286>, 'val_loss': 0.17316953837871552}
Epoch 1589/4000

Epoch 01589: LearningRateScheduler reducing learning rate to 5.9224308687613064e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06262319>, 'val_loss': 0.17341038584709167}
Epoch 1590/4000

Epoch 01590: LearningRateScheduler reducing learning rate to 5.896916795510187e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1754
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062399637>, 'val_loss': 0.17540661990642548}
Epoch 1591/4000

Epoch 01591: LearningRateScheduler reducing learning rate to 5.871512637925165e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1652
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062738836>, 'val_loss': 0.1651519536972046}
Epoch 1592/4000

Epoch 01592: LearningRateScheduler reducing learning rate to 5.84621792248508e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1846
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061835214>, 'val_loss': 0.1846371293067932}
Epoch 1593/4000

Epoch 01593: LearningRateScheduler reducing learning rate to 5.821032177708714e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06280001>, 'val_loss': 0.17534101009368896}
Epoch 1594/4000

Epoch 01594: LearningRateScheduler reducing learning rate to 5.795954934146014e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06273054>, 'val_loss': 0.1712859869003296}
Epoch 1595/4000

Epoch 01595: LearningRateScheduler reducing learning rate to 5.770985724369333e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1804
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06173901>, 'val_loss': 0.1804458349943161}
Epoch 1596/4000

Epoch 01596: LearningRateScheduler reducing learning rate to 5.74612408296472e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06241324>, 'val_loss': 0.16991472244262695}
Epoch 1597/4000

Epoch 01597: LearningRateScheduler reducing learning rate to 5.72136954652326e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261386>, 'val_loss': 0.17625509202480316}
Epoch 1598/4000

Epoch 01598: LearningRateScheduler reducing learning rate to 5.6967216536324055e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062366188>, 'val_loss': 0.17389197647571564}
Epoch 1599/4000

Epoch 01599: LearningRateScheduler reducing learning rate to 5.6721799448674e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062523566>, 'val_loss': 0.16909249126911163}
Epoch 1600/4000

Epoch 01600: LearningRateScheduler reducing learning rate to 5.647743962782708e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062211826>, 'val_loss': 0.16967971622943878}
Model saved in ./model/scPDB_2021_pdbid--1600--0.1697.
Epoch 1601/4000

Epoch 01601: LearningRateScheduler reducing learning rate to 5.623413251903487e-06.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06335942>, 'val_loss': 0.17939122021198273}
Epoch 1602/4000

Epoch 01602: LearningRateScheduler reducing learning rate to 5.599187358717098e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06258895>, 'val_loss': 0.16903327405452728}
Epoch 1603/4000

Epoch 01603: LearningRateScheduler reducing learning rate to 5.575065831664655e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062222283>, 'val_loss': 0.17383038997650146}
Epoch 1604/4000

Epoch 01604: LearningRateScheduler reducing learning rate to 5.551048221132604e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062417876>, 'val_loss': 0.17573586106300354}
Epoch 1605/4000

Epoch 01605: LearningRateScheduler reducing learning rate to 5.5271340794443455e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1766
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061860953>, 'val_loss': 0.1766086369752884}
Epoch 1606/4000

Epoch 01606: LearningRateScheduler reducing learning rate to 5.50332296085189e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1768
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062677674>, 'val_loss': 0.17677241563796997}
Epoch 1607/4000

Epoch 01607: LearningRateScheduler reducing learning rate to 5.479614421527544e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1684
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062449783>, 'val_loss': 0.1684318631887436}
Epoch 1608/4000

Epoch 01608: LearningRateScheduler reducing learning rate to 5.456008019555648e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062249828>, 'val_loss': 0.174831822514534}
Epoch 1609/4000

Epoch 01609: LearningRateScheduler reducing learning rate to 5.432503314924329e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1770
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06220765>, 'val_loss': 0.17697082459926605}
Epoch 1610/4000

Epoch 01610: LearningRateScheduler reducing learning rate to 5.409099869517305e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06285432>, 'val_loss': 0.1743355542421341}
Epoch 1611/4000

Epoch 01611: LearningRateScheduler reducing learning rate to 5.385797247105716e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1796
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06274792>, 'val_loss': 0.1795501559972763}
Epoch 1612/4000

Epoch 01612: LearningRateScheduler reducing learning rate to 5.362595013339993e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06249691>, 'val_loss': 0.17210125923156738}
Epoch 1613/4000

Epoch 01613: LearningRateScheduler reducing learning rate to 5.339492735741764e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1657
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062163815>, 'val_loss': 0.16570457816123962}
Epoch 1614/4000

Epoch 01614: LearningRateScheduler reducing learning rate to 5.316489983695791e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062445965>, 'val_loss': 0.17644917964935303}
Epoch 1615/4000

Epoch 01615: LearningRateScheduler reducing learning rate to 5.293586328441943e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1769
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06241112>, 'val_loss': 0.17689122259616852}
Epoch 1616/4000

Epoch 01616: LearningRateScheduler reducing learning rate to 5.2707813430672055e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1778
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062201235>, 'val_loss': 0.1777702122926712}
Epoch 1617/4000

Epoch 01617: LearningRateScheduler reducing learning rate to 5.248074602497724e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1653
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627535>, 'val_loss': 0.1652994155883789}
Epoch 1618/4000

Epoch 01618: LearningRateScheduler reducing learning rate to 5.225465683490878e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1681
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062111516>, 'val_loss': 0.1680869311094284}
Epoch 1619/4000

Epoch 01619: LearningRateScheduler reducing learning rate to 5.202954164627394e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06264176>, 'val_loss': 0.16826415061950684}
Epoch 1620/4000

Epoch 01620: LearningRateScheduler reducing learning rate to 5.18053962630349e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06180228>, 'val_loss': 0.17322884500026703}
Epoch 1621/4000

Epoch 01621: LearningRateScheduler reducing learning rate to 5.158221650723055e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1759
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06307808>, 'val_loss': 0.17592144012451172}
Epoch 1622/4000

Epoch 01622: LearningRateScheduler reducing learning rate to 5.135999821889858e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1627
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062328484>, 'val_loss': 0.1627136766910553}
Epoch 1623/4000

Epoch 01623: LearningRateScheduler reducing learning rate to 5.113873725599798e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1800
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06248497>, 'val_loss': 0.17998595535755157}
Epoch 1624/4000

Epoch 01624: LearningRateScheduler reducing learning rate to 5.091842949433184e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1736
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06215217>, 'val_loss': 0.17358702421188354}
Epoch 1625/4000

Epoch 01625: LearningRateScheduler reducing learning rate to 5.069907082747042e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06235898>, 'val_loss': 0.17625896632671356}
Epoch 1626/4000

Epoch 01626: LearningRateScheduler reducing learning rate to 5.048065716667469e-06.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06334183>, 'val_loss': 0.17633266746997833}
Epoch 1627/4000

Epoch 01627: LearningRateScheduler reducing learning rate to 5.0263184440820055e-06.
24/24 - 2s - loss: 0.0614 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06144162>, 'val_loss': 0.17516906559467316}
Epoch 1628/4000

Epoch 01628: LearningRateScheduler reducing learning rate to 5.004664859632048e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1689
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272907>, 'val_loss': 0.16894957423210144}
Epoch 1629/4000

Epoch 01629: LearningRateScheduler reducing learning rate to 4.983104559705294e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062105324>, 'val_loss': 0.1696641892194748}
Epoch 1630/4000

Epoch 01630: LearningRateScheduler reducing learning rate to 4.961637142428223e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1720
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06251755>, 'val_loss': 0.17203430831432343}
Epoch 1631/4000

Epoch 01631: LearningRateScheduler reducing learning rate to 4.940262207658597e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1690
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062875114>, 'val_loss': 0.16902121901512146}
Epoch 1632/4000

Epoch 01632: LearningRateScheduler reducing learning rate to 4.918979356978011e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1654
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06170361>, 'val_loss': 0.1653638780117035}
Epoch 1633/4000

Epoch 01633: LearningRateScheduler reducing learning rate to 4.897788193684461e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1781
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062356513>, 'val_loss': 0.17806603014469147}
Epoch 1634/4000

Epoch 01634: LearningRateScheduler reducing learning rate to 4.876688322784952e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1682
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062945314>, 'val_loss': 0.16816869378089905}
Epoch 1635/4000

Epoch 01635: LearningRateScheduler reducing learning rate to 4.855679350988133e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062117353>, 'val_loss': 0.17134010791778564}
Epoch 1636/4000

Epoch 01636: LearningRateScheduler reducing learning rate to 4.8347608866969705e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061910443>, 'val_loss': 0.16827110946178436}
Epoch 1637/4000

Epoch 01637: LearningRateScheduler reducing learning rate to 4.813932540001447e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1779
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061777238>, 'val_loss': 0.17788586020469666}
Epoch 1638/4000

Epoch 01638: LearningRateScheduler reducing learning rate to 4.793193922671291e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06253904>, 'val_loss': 0.1729194074869156}
Epoch 1639/4000

Epoch 01639: LearningRateScheduler reducing learning rate to 4.772544648148744e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1697
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06249>, 'val_loss': 0.16970930993556976}
Epoch 1640/4000

Epoch 01640: LearningRateScheduler reducing learning rate to 4.751984331541355e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1784
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062486697>, 'val_loss': 0.17835155129432678}
Epoch 1641/4000

Epoch 01641: LearningRateScheduler reducing learning rate to 4.7315125896148055e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1786
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062734544>, 'val_loss': 0.17859335243701935}
Epoch 1642/4000

Epoch 01642: LearningRateScheduler reducing learning rate to 4.711129040785763e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1645
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06200126>, 'val_loss': 0.1644638478755951}
Epoch 1643/4000

Epoch 01643: LearningRateScheduler reducing learning rate to 4.690833305114773e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1860
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062262863>, 'val_loss': 0.1859695315361023}
Epoch 1644/4000

Epoch 01644: LearningRateScheduler reducing learning rate to 4.670625004299179e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06283213>, 'val_loss': 0.175203338265419}
Epoch 1645/4000

Epoch 01645: LearningRateScheduler reducing learning rate to 4.6505037616660595e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1760
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06220886>, 'val_loss': 0.17597784101963043}
Epoch 1646/4000

Epoch 01646: LearningRateScheduler reducing learning rate to 4.630469202165229e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1808
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061747275>, 'val_loss': 0.18080194294452667}
Epoch 1647/4000

Epoch 01647: LearningRateScheduler reducing learning rate to 4.61052095236222e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1787
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06223169>, 'val_loss': 0.1787252426147461}
Epoch 1648/4000

Epoch 01648: LearningRateScheduler reducing learning rate to 4.590658640431344e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1790
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06259961>, 'val_loss': 0.17897658050060272}
Epoch 1649/4000

Epoch 01649: LearningRateScheduler reducing learning rate to 4.570881896148747e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1796
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250608>, 'val_loss': 0.17957115173339844}
Epoch 1650/4000

Epoch 01650: LearningRateScheduler reducing learning rate to 4.551190350885518e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1811
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061965663>, 'val_loss': 0.18109148740768433}
Model saved in ./model/scPDB_2021_pdbid--1650--0.1811.
Epoch 1651/4000

Epoch 01651: LearningRateScheduler reducing learning rate to 4.531583637600815e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1725
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06258105>, 'val_loss': 0.17251427471637726}
Epoch 1652/4000

Epoch 01652: LearningRateScheduler reducing learning rate to 4.512061390835019e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06288579>, 'val_loss': 0.1706855446100235}
Epoch 1653/4000

Epoch 01653: LearningRateScheduler reducing learning rate to 4.492623246702931e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1686
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062046345>, 'val_loss': 0.16857647895812988}
Epoch 1654/4000

Epoch 01654: LearningRateScheduler reducing learning rate to 4.47326884288698e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1728
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06194467>, 'val_loss': 0.17283372581005096}
Epoch 1655/4000

Epoch 01655: LearningRateScheduler reducing learning rate to 4.453997818630476e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1799
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062271874>, 'val_loss': 0.17988762259483337}
Epoch 1656/4000

Epoch 01656: LearningRateScheduler reducing learning rate to 4.434809814730882e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1777
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062532924>, 'val_loss': 0.17771558463573456}
Epoch 1657/4000

Epoch 01657: LearningRateScheduler reducing learning rate to 4.415704473533123e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1757
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062068965>, 'val_loss': 0.17568714916706085}
Epoch 1658/4000

Epoch 01658: LearningRateScheduler reducing learning rate to 4.396681438922913e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061805315>, 'val_loss': 0.17939414083957672}
Epoch 1659/4000

Epoch 01659: LearningRateScheduler reducing learning rate to 4.377740356320123e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1683
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062477183>, 'val_loss': 0.16830813884735107}
Epoch 1660/4000

Epoch 01660: LearningRateScheduler reducing learning rate to 4.3588808726721714e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1712
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062270585>, 'val_loss': 0.17122836410999298}
Epoch 1661/4000

Epoch 01661: LearningRateScheduler reducing learning rate to 4.340102636447436e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1764
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062620424>, 'val_loss': 0.17643247544765472}
Epoch 1662/4000

Epoch 01662: LearningRateScheduler reducing learning rate to 4.321405297628713e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1758
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06252905>, 'val_loss': 0.17579370737075806}
Epoch 1663/4000

Epoch 01663: LearningRateScheduler reducing learning rate to 4.302788507706683e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06229954>, 'val_loss': 0.17326487600803375}
Epoch 1664/4000

Epoch 01664: LearningRateScheduler reducing learning rate to 4.28425191967342e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1759
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06250955>, 'val_loss': 0.17590922117233276}
Epoch 1665/4000

Epoch 01665: LearningRateScheduler reducing learning rate to 4.265795188015925e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1784
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627161>, 'val_loss': 0.17844335734844208}
Epoch 1666/4000

Epoch 01666: LearningRateScheduler reducing learning rate to 4.247417968709678e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06165321>, 'val_loss': 0.1738419383764267}
Epoch 1667/4000

Epoch 01667: LearningRateScheduler reducing learning rate to 4.229119919212235e-06.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1747
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06316284>, 'val_loss': 0.17465677857398987}
Epoch 1668/4000

Epoch 01668: LearningRateScheduler reducing learning rate to 4.210900698456836e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061975967>, 'val_loss': 0.17069196701049805}
Epoch 1669/4000

Epoch 01669: LearningRateScheduler reducing learning rate to 4.192759966846053e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1709
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06245512>, 'val_loss': 0.17088381946086884}
Epoch 1670/4000

Epoch 01670: LearningRateScheduler reducing learning rate to 4.1746973862454546e-06.
24/24 - 2s - loss: 0.0614 - val_loss: 0.1766
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061394136>, 'val_loss': 0.17659002542495728}
Epoch 1671/4000

Epoch 01671: LearningRateScheduler reducing learning rate to 4.156712619977309e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1682
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06239869>, 'val_loss': 0.16818952560424805}
Epoch 1672/4000

Epoch 01672: LearningRateScheduler reducing learning rate to 4.138805332814304e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1729
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06272549>, 'val_loss': 0.17294646799564362}
Epoch 1673/4000

Epoch 01673: LearningRateScheduler reducing learning rate to 4.120975190973301e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1715
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061832126>, 'val_loss': 0.17153231799602509}
Epoch 1674/4000

Epoch 01674: LearningRateScheduler reducing learning rate to 4.103221862109113e-06.
24/24 - 2s - loss: 0.0633 - val_loss: 0.1716
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063311785>, 'val_loss': 0.1716003566980362}
Epoch 1675/4000

Epoch 01675: LearningRateScheduler reducing learning rate to 4.085545015308309e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1750
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062313043>, 'val_loss': 0.17497754096984863}
Epoch 1676/4000

Epoch 01676: LearningRateScheduler reducing learning rate to 4.067944321083046e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1732
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062173903>, 'val_loss': 0.17318421602249146}
Epoch 1677/4000

Epoch 01677: LearningRateScheduler reducing learning rate to 4.05041945136493e-06.
24/24 - 2s - loss: 0.0631 - val_loss: 0.1727
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06312844>, 'val_loss': 0.1726592779159546}
Epoch 1678/4000

Epoch 01678: LearningRateScheduler reducing learning rate to 4.032970079498898e-06.
24/24 - 2s - loss: 0.0616 - val_loss: 0.1682
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06162131>, 'val_loss': 0.16823603212833405}
Epoch 1679/4000

Epoch 01679: LearningRateScheduler reducing learning rate to 4.01559588023713e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1793
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062011525>, 'val_loss': 0.17930269241333008}
Epoch 1680/4000

Epoch 01680: LearningRateScheduler reducing learning rate to 3.998296529732986e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1671
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06289021>, 'val_loss': 0.1671154499053955}
Epoch 1681/4000

Epoch 01681: LearningRateScheduler reducing learning rate to 3.981071705534972e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1708
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062114384>, 'val_loss': 0.17079932987689972}
Epoch 1682/4000

Epoch 01682: LearningRateScheduler reducing learning rate to 3.963921086580727e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1834
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062900744>, 'val_loss': 0.18342192471027374}
Epoch 1683/4000

Epoch 01683: LearningRateScheduler reducing learning rate to 3.946844353191043e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1721
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06192767>, 'val_loss': 0.17207138240337372}
Epoch 1684/4000

Epoch 01684: LearningRateScheduler reducing learning rate to 3.929841187063897e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062403724>, 'val_loss': 0.1741621494293213}
Epoch 1685/4000

Epoch 01685: LearningRateScheduler reducing learning rate to 3.912911271268529e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06220123>, 'val_loss': 0.17422249913215637}
Epoch 1686/4000

Epoch 01686: LearningRateScheduler reducing learning rate to 3.896054290239529e-06.
24/24 - 2s - loss: 0.0614 - val_loss: 0.1832
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061356116>, 'val_loss': 0.18324410915374756}
Epoch 1687/4000

Epoch 01687: LearningRateScheduler reducing learning rate to 3.879269929770953e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1790
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06281772>, 'val_loss': 0.17904603481292725}
Epoch 1688/4000

Epoch 01688: LearningRateScheduler reducing learning rate to 3.862557877010472e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1756
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062232193>, 'val_loss': 0.17564572393894196}
Epoch 1689/4000

Epoch 01689: LearningRateScheduler reducing learning rate to 3.845917820453536e-06.
24/24 - 2s - loss: 0.0618 - val_loss: 0.1746
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061810974>, 'val_loss': 0.1746482253074646}
Epoch 1690/4000

Epoch 01690: LearningRateScheduler reducing learning rate to 3.829349449937569e-06.
24/24 - 2s - loss: 0.0635 - val_loss: 0.1754
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06347304>, 'val_loss': 0.17543160915374756}
Epoch 1691/4000

Epoch 01691: LearningRateScheduler reducing learning rate to 3.812852456636189e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1710
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061975263>, 'val_loss': 0.1710318922996521}
Epoch 1692/4000

Epoch 01692: LearningRateScheduler reducing learning rate to 3.7964265330534497e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062575646>, 'val_loss': 0.173902228474617}
Epoch 1693/4000

Epoch 01693: LearningRateScheduler reducing learning rate to 3.7800713730181115e-06.
24/24 - 2s - loss: 0.0612 - val_loss: 0.1735
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061245367>, 'val_loss': 0.1734849065542221}
Epoch 1694/4000

Epoch 01694: LearningRateScheduler reducing learning rate to 3.763786671677928e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062657304>, 'val_loss': 0.17241337895393372}
Epoch 1695/4000

Epoch 01695: LearningRateScheduler reducing learning rate to 3.747572125493978e-06.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063398436>, 'val_loss': 0.17377080023288727}
Epoch 1696/4000

Epoch 01696: LearningRateScheduler reducing learning rate to 3.731427432234991e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1666
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06270739>, 'val_loss': 0.16656091809272766}
Epoch 1697/4000

Epoch 01697: LearningRateScheduler reducing learning rate to 3.715352290971723e-06.
24/24 - 2s - loss: 0.0615 - val_loss: 0.1752
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061479025>, 'val_loss': 0.17523913085460663}
Epoch 1698/4000

Epoch 01698: LearningRateScheduler reducing learning rate to 3.6993464020713438e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1760
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0623644>, 'val_loss': 0.17600078880786896}
Epoch 1699/4000

Epoch 01699: LearningRateScheduler reducing learning rate to 3.6834094671918567e-06.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1792
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.063170776>, 'val_loss': 0.17915111780166626}
Epoch 1700/4000

Epoch 01700: LearningRateScheduler reducing learning rate to 3.6675411892765324e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1619
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06198616>, 'val_loss': 0.16194307804107666}
Model saved in ./model/scPDB_2021_pdbid--1700--0.1619.
Epoch 1701/4000

Epoch 01701: LearningRateScheduler reducing learning rate to 3.6517412725483745e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1794
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268809>, 'val_loss': 0.1793941706418991}
Epoch 1702/4000

Epoch 01702: LearningRateScheduler reducing learning rate to 3.6360094225046064e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1756
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06214844>, 'val_loss': 0.17556744813919067}
Epoch 1703/4000

Epoch 01703: LearningRateScheduler reducing learning rate to 3.6203453459111812e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1820
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062466975>, 'val_loss': 0.18200668692588806}
Epoch 1704/4000

Epoch 01704: LearningRateScheduler reducing learning rate to 3.604748750797316e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1713
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06244409>, 'val_loss': 0.17125697433948517}
Epoch 1705/4000

Epoch 01705: LearningRateScheduler reducing learning rate to 3.58921934645005e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1753
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062597>, 'val_loss': 0.17532360553741455}
Epoch 1706/4000

Epoch 01706: LearningRateScheduler reducing learning rate to 3.5737568434088258e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1726
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06205052>, 'val_loss': 0.17259205877780914}
Epoch 1707/4000

Epoch 01707: LearningRateScheduler reducing learning rate to 3.558360953460094e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1704
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062677026>, 'val_loss': 0.1704210489988327}
Epoch 1708/4000

Epoch 01708: LearningRateScheduler reducing learning rate to 3.54303138963194e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1845
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062374163>, 'val_loss': 0.18451671302318573}
Epoch 1709/4000

Epoch 01709: LearningRateScheduler reducing learning rate to 3.527767866188737e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1584
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06264486>, 'val_loss': 0.15841341018676758}
Epoch 1710/4000

Epoch 01710: LearningRateScheduler reducing learning rate to 3.5125700986258195e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1756
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062917024>, 'val_loss': 0.17564640939235687}
Epoch 1711/4000

Epoch 01711: LearningRateScheduler reducing learning rate to 3.4974378036641774e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1733
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062014278>, 'val_loss': 0.17325669527053833}
Epoch 1712/4000

Epoch 01712: LearningRateScheduler reducing learning rate to 3.4823706992451796e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1828
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062278584>, 'val_loss': 0.18284735083580017}
Epoch 1713/4000

Epoch 01713: LearningRateScheduler reducing learning rate to 3.467368504525315e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1739
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062270347>, 'val_loss': 0.17390334606170654}
Epoch 1714/4000

Epoch 01714: LearningRateScheduler reducing learning rate to 3.4524309398709573e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1789
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06271863>, 'val_loss': 0.1789073795080185}
Epoch 1715/4000

Epoch 01715: LearningRateScheduler reducing learning rate to 3.4375577268531545e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1750
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062335286>, 'val_loss': 0.17504198849201202}
Epoch 1716/4000

Epoch 01716: LearningRateScheduler reducing learning rate to 3.422748588242436e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261602>, 'val_loss': 0.17298440635204315}
Epoch 1717/4000

Epoch 01717: LearningRateScheduler reducing learning rate to 3.4080032480036488e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1722
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06204593>, 'val_loss': 0.17222170531749725}
Epoch 1718/4000

Epoch 01718: LearningRateScheduler reducing learning rate to 3.3933214312908085e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1699
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06193284>, 'val_loss': 0.169910728931427}
Epoch 1719/4000

Epoch 01719: LearningRateScheduler reducing learning rate to 3.378702864441981e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1783
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06291557>, 'val_loss': 0.1782742291688919}
Epoch 1720/4000

Epoch 01720: LearningRateScheduler reducing learning rate to 3.364147274974177e-06.
24/24 - 2s - loss: 0.0632 - val_loss: 0.1747
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06319672>, 'val_loss': 0.17471079528331757}
Epoch 1721/4000

Epoch 01721: LearningRateScheduler reducing learning rate to 3.3496543915782755e-06.
24/24 - 2s - loss: 0.0617 - val_loss: 0.1783
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0617125>, 'val_loss': 0.178266242146492}
Epoch 1722/4000

Epoch 01722: LearningRateScheduler reducing learning rate to 3.3352239441139665e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1735
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06207003>, 'val_loss': 0.17354734241962433}
Epoch 1723/4000

Epoch 01723: LearningRateScheduler reducing learning rate to 3.320855663604715e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1714
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062401306>, 'val_loss': 0.17143511772155762}
Epoch 1724/4000

Epoch 01724: LearningRateScheduler reducing learning rate to 3.306549282232749e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1744
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06225853>, 'val_loss': 0.17444291710853577}
Epoch 1725/4000

Epoch 01725: LearningRateScheduler reducing learning rate to 3.2923045333340643e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1749
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06260195>, 'val_loss': 0.17490410804748535}
Epoch 1726/4000

Epoch 01726: LearningRateScheduler reducing learning rate to 3.278121151393458e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1770
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062130462>, 'val_loss': 0.17699579894542694}
Epoch 1727/4000

Epoch 01727: LearningRateScheduler reducing learning rate to 3.2639988720395765e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1643
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062098686>, 'val_loss': 0.16426129639148712}
Epoch 1728/4000

Epoch 01728: LearningRateScheduler reducing learning rate to 3.2499374320399895e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1749
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062890835>, 'val_loss': 0.17485420405864716}
Epoch 1729/4000

Epoch 01729: LearningRateScheduler reducing learning rate to 3.235936569296282e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1761
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06220046>, 'val_loss': 0.17608754336833954}
Epoch 1730/4000

Epoch 01730: LearningRateScheduler reducing learning rate to 3.22199602283917e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1740
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062271666>, 'val_loss': 0.17400304973125458}
Epoch 1731/4000

Epoch 01731: LearningRateScheduler reducing learning rate to 3.2081155328236356e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1771
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06229655>, 'val_loss': 0.17711643874645233}
Epoch 1732/4000

Epoch 01732: LearningRateScheduler reducing learning rate to 3.194294840524084e-06.
24/24 - 2s - loss: 0.0615 - val_loss: 0.1738
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06145329>, 'val_loss': 0.17376047372817993}
Epoch 1733/4000

Epoch 01733: LearningRateScheduler reducing learning rate to 3.1805336883295205e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1695
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06271594>, 'val_loss': 0.16948388516902924}
Epoch 1734/4000

Epoch 01734: LearningRateScheduler reducing learning rate to 3.1668318197387493e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1786
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06276777>, 'val_loss': 0.17855213582515717}
Epoch 1735/4000

Epoch 01735: LearningRateScheduler reducing learning rate to 3.1531889793555926e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1773
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062737234>, 'val_loss': 0.17728841304779053}
Epoch 1736/4000

Epoch 01736: LearningRateScheduler reducing learning rate to 3.139604912884129e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1839
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062448677>, 'val_loss': 0.18391864001750946}
Epoch 1737/4000

Epoch 01737: LearningRateScheduler reducing learning rate to 3.126079367123955e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0622292>, 'val_loss': 0.1697801947593689}
Epoch 1738/4000

Epoch 01738: LearningRateScheduler reducing learning rate to 3.112612089965463e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1777
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062260315>, 'val_loss': 0.17772631347179413}
Epoch 1739/4000

Epoch 01739: LearningRateScheduler reducing learning rate to 3.099202830385147e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1675
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062008973>, 'val_loss': 0.16750235855579376}
Epoch 1740/4000

Epoch 01740: LearningRateScheduler reducing learning rate to 3.0858513384409173e-06.
24/24 - 2s - loss: 0.0629 - val_loss: 0.1737
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062896>, 'val_loss': 0.17365020513534546}
Epoch 1741/4000

Epoch 01741: LearningRateScheduler reducing learning rate to 3.0725573652674467e-06.
24/24 - 2s - loss: 0.0625 - val_loss: 0.1682
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06246041>, 'val_loss': 0.1682136505842209}
Epoch 1742/4000

Epoch 01742: LearningRateScheduler reducing learning rate to 3.059320663071527e-06.
24/24 - 2s - loss: 0.0630 - val_loss: 0.1742
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06298589>, 'val_loss': 0.17417195439338684}
Epoch 1743/4000

Epoch 01743: LearningRateScheduler reducing learning rate to 3.0461409851274605e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1702
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062073734>, 'val_loss': 0.17020542919635773}
Epoch 1744/4000

Epoch 01744: LearningRateScheduler reducing learning rate to 3.033018085772447e-06.
24/24 - 2s - loss: 0.0619 - val_loss: 0.1676
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061936907>, 'val_loss': 0.1675899773836136}
Epoch 1745/4000

Epoch 01745: LearningRateScheduler reducing learning rate to 3.019951720402014e-06.
24/24 - 2s - loss: 0.0623 - val_loss: 0.1687
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062289327>, 'val_loss': 0.16868028044700623}
Epoch 1746/4000

Epoch 01746: LearningRateScheduler reducing learning rate to 3.0069416454654536e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1707
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06261901>, 'val_loss': 0.1707388013601303}
Epoch 1747/4000

Epoch 01747: LearningRateScheduler reducing learning rate to 2.9939876184612868e-06.
24/24 - 2s - loss: 0.0622 - val_loss: 0.1785
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062214408>, 'val_loss': 0.17852415144443512}
Epoch 1748/4000

Epoch 01748: LearningRateScheduler reducing learning rate to 2.981089397932738e-06.
24/24 - 2s - loss: 0.0616 - val_loss: 0.1730
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061578903>, 'val_loss': 0.17302285134792328}
Epoch 1749/4000

Epoch 01749: LearningRateScheduler reducing learning rate to 2.96824674346324e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1698
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062391534>, 'val_loss': 0.1698351502418518}
Epoch 1750/4000

Epoch 01750: LearningRateScheduler reducing learning rate to 2.9554594156719476e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1748
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062067974>, 'val_loss': 0.17480270564556122}
Model saved in ./model/scPDB_2021_pdbid--1750--0.1748.
Epoch 1751/4000

Epoch 01751: LearningRateScheduler reducing learning rate to 2.94272717620928e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1691
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06270737>, 'val_loss': 0.16910326480865479}
Epoch 1752/4000

Epoch 01752: LearningRateScheduler reducing learning rate to 2.930049787752474e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1724
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06243344>, 'val_loss': 0.17240841686725616}
Epoch 1753/4000

Epoch 01753: LearningRateScheduler reducing learning rate to 2.9174270140011653e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1734
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627976>, 'val_loss': 0.17337174713611603}
Epoch 1754/4000

Epoch 01754: LearningRateScheduler reducing learning rate to 2.9048586196729777e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1743
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06201397>, 'val_loss': 0.17434966564178467}
Epoch 1755/4000

Epoch 01755: LearningRateScheduler reducing learning rate to 2.8923443704991443e-06.
24/24 - 2s - loss: 0.0628 - val_loss: 0.1763
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06278605>, 'val_loss': 0.17628896236419678}
Epoch 1756/4000

Epoch 01756: LearningRateScheduler reducing learning rate to 2.8798840332201355e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1789
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062098283>, 'val_loss': 0.17891676723957062}
Epoch 1757/4000

Epoch 01757: LearningRateScheduler reducing learning rate to 2.8674773755813143e-06.
24/24 - 2s - loss: 0.0624 - val_loss: 0.1672
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06241264>, 'val_loss': 0.16715852916240692}
Epoch 1758/4000

Epoch 01758: LearningRateScheduler reducing learning rate to 2.8551241663286058e-06.
24/24 - 2s - loss: 0.0626 - val_loss: 0.1719
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062589504>, 'val_loss': 0.17192095518112183}
Epoch 1759/4000

Epoch 01759: LearningRateScheduler reducing learning rate to 2.8428241752041864e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1755
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.0627171>, 'val_loss': 0.17548902332782745}
Epoch 1760/4000

Epoch 01760: LearningRateScheduler reducing learning rate to 2.8305771729421944e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1648
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062057342>, 'val_loss': 0.1647903323173523}
Epoch 1761/4000

Epoch 01761: LearningRateScheduler reducing learning rate to 2.818382931264452e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1805
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06269656>, 'val_loss': 0.18052928149700165}
Epoch 1762/4000

Epoch 01762: LearningRateScheduler reducing learning rate to 2.8062412228762168e-06.
24/24 - 2s - loss: 0.0621 - val_loss: 0.1766
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.062128425>, 'val_loss': 0.1766466349363327}
Epoch 1763/4000

Epoch 01763: LearningRateScheduler reducing learning rate to 2.794151821461937e-06.
24/24 - 2s - loss: 0.0620 - val_loss: 0.1754
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06202762>, 'val_loss': 0.17540477216243744}
Epoch 1764/4000

Epoch 01764: LearningRateScheduler reducing learning rate to 2.7821145016810416e-06.
24/24 - 2s - loss: 0.0634 - val_loss: 0.1658
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06341602>, 'val_loss': 0.1658364087343216}
Epoch 1765/4000

Epoch 01765: LearningRateScheduler reducing learning rate to 2.7701290391637323e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1655
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06274744>, 'val_loss': 0.16552333533763885}
Epoch 1766/4000

Epoch 01766: LearningRateScheduler reducing learning rate to 2.758195210506808e-06.
24/24 - 2s - loss: 0.0615 - val_loss: 0.1765
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.061533008>, 'val_loss': 0.17654384672641754}
Epoch 1767/4000

Epoch 01767: LearningRateScheduler reducing learning rate to 2.7463127932694962e-06.
24/24 - 2s - loss: 0.0627 - val_loss: 0.1745
{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.06268531>, 'val_loss': 0.1744878739118576}
Epoch 1768/4000

Epoch 01768: LearningRateScheduler reducing learning rate to 2.7344815659693083e-06.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             